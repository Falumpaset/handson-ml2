{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "attachementTypes = {'INCOME_STATEMENT', 'CREDIT_REPORT', 'SHARED_DOCUMENT', 'WB_CERTIFICATE'}\n",
    "\n",
    "def processAttachments(data):\n",
    "    for document in attachementTypes:\n",
    "        data[document] = False\n",
    "    for attachement in data['attachments']:\n",
    "            data[attachement['type']] = True  \n",
    "    data.pop('attachments', None)\n",
    "    \n",
    "def processBirthDate(data):\n",
    "    age = None\n",
    "    if data['dateOfBirth']:        \n",
    "        age = pd.datetime.today() - pd.to_datetime(data['dateOfBirth'], unit='ms')\n",
    "        age = int(age.days / 365)\n",
    "    data['age'] = age\n",
    "    data.pop('dateOfBirth', None)\n",
    "\n",
    "    \n",
    "def processProfession(data):\n",
    "    if data['profession']:\n",
    "        professionData = data['profession']\n",
    "        data['professionType'] = professionData['type']\n",
    "        data['income'] = professionData['income']\n",
    "    else:\n",
    "        data['professionType'] = None\n",
    "        data['income'] = None\n",
    "    data.pop('profession', None)\n",
    "    \n",
    "def processLaw(data):\n",
    "    if data['law']:\n",
    "        lawData = data['law']\n",
    "        data['allowSchufa'] = lawData['allowSchufa']\n",
    "        data['noRentArrears'] = lawData['noRentArrears']\n",
    "        data['noPoliceRecord'] = lawData['noPoliceRecord']\n",
    "        data['noTenancyLawConflicts'] = lawData['noTenancyLawConflicts']\n",
    "    data.pop('law', None)\n",
    "        \n",
    "def processAdditionalInformation(data):\n",
    "    if data['additionalInformation']:\n",
    "        additionalInformationData = data['additionalInformation']\n",
    "        data['wbs'] = additionalInformationData['wbs']\n",
    "        data['music'] = additionalInformationData['music']\n",
    "        data['animals'] = additionalInformationData['animals']\n",
    "        data['bailment'] = additionalInformationData['bailment']\n",
    "    else:\n",
    "        data['wbs'] = None\n",
    "        data['music'] = None\n",
    "        data['animals'] = None\n",
    "        data['bailment'] = None\n",
    "    data.pop('additionalInformation', None)\n",
    "    \n",
    "    \n",
    "def processAndFillDaysWaiting(data):\n",
    "    data['days_waiting'] = data['date_part']\n",
    "    data.pop('date_part', None)\n",
    "    \n",
    "def formatValues(data):\n",
    "    for p in data:\n",
    "        if p['smoker']:\n",
    "            p['smoker'] = p['smoker']['inhouse']\n",
    "        p['portrait'] = p['portrait'] != None\n",
    "        p.pop('firstName', None)\n",
    "        p.pop('moveInDate', None)\n",
    "        p.pop('phone', None)\n",
    "        p.pop('title', None)\n",
    "        p.pop('moveInDate', None)\n",
    "        p.pop('creditScreening', None)\n",
    "\n",
    "        processLaw(p)\n",
    "        processProfession(p)\n",
    "        processBirthDate(p)\n",
    "        processAttachments(p)\n",
    "        processAdditionalInformation(p)\n",
    "        processAndFillDaysWaiting(p)\n",
    "        \n",
    "\n",
    "datapath = os.path.join(\"datasets\", \"tenants\", \"\")\n",
    "\n",
    "with open(datapath + \"tenants.json\") as file:\n",
    "    data = json.load(file)\n",
    "    formatValues(data)\n",
    "    \n",
    "    \n",
    "with open(datapath + \"formattedTenants.json\", 'w', encoding='utf-8') as formattedFile:\n",
    "    json.dump(data, formattedFile, ensure_ascii=False,indent=4)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanData(dataFrame):\n",
    "    dataFrame = dataFrame.drop(columns=[\"name\", \"gender\", \"firstname\", \"smoker\", \"personalStatus\", \"allowSchufa\", \"noPoliceRecord\", \"music\", \"bailment\", \"SHARED_DOCUMENT\"])\n",
    "    dataFrame[\"portrait\"] = dataFrame[\"portrait\"].astype(int)\n",
    "    dataFrame[\"guarantorExist\"] = dataFrame[\"guarantorExist\"].astype(int)\n",
    "    dataFrame[\"INCOME_STATEMENT\"] = dataFrame[\"INCOME_STATEMENT\"].astype(int)\n",
    "    dataFrame[\"CREDIT_REPORT\"] = dataFrame[\"CREDIT_REPORT\"].astype(int)\n",
    "    dataFrame[\"WB_CERTIFICATE\"] = dataFrame[\"WB_CERTIFICATE\"].astype(int)\n",
    "    dataFrame[\"professionType\"] = dataFrame[\"professionType\"].astype('category')\n",
    "    dataFrame[\"householdType\"] = dataFrame[\"householdType\"].astype('category')\n",
    "    cleanIncome(dataFrame)\n",
    "    fillDaysWaiting(dataFrame)\n",
    "    return dataFrame\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def countWords(dataFrame):\n",
    "    allWords = []\n",
    "    counter = 0\n",
    "    vectorizer = TfidfVectorizer(max_df=0.15, min_df=0.05)\n",
    "    for words in dataFrame[\"furtherInformation\"]:\n",
    "        if words != None and not '':\n",
    "            allWords.append(words)\n",
    "            dataFrame.loc[counter, (\"furtherInformation\")] = len(words)\n",
    "        else:\n",
    "            dataFrame.loc[counter, (\"furtherInformation\")] = 0\n",
    "        counter+=1    \n",
    "    vectorizer.fit(allWords)\n",
    "    dataFrame[\"furtherInformation\"] = dataFrame[\"furtherInformation\"].astype(int)\n",
    "    return dataFrame\n",
    "\n",
    "import math\n",
    "def cleanIncome(dataFrame):\n",
    "    counter = 0\n",
    "    incomeMedian = dataFrame[\"income\"].median()\n",
    "    for income in dataFrame[\"income\"]:\n",
    "        if income > 40000.0:\n",
    "            dataFrame.loc[counter, (\"income\")] = 40000.0\n",
    "        counter += 1\n",
    "        \n",
    "from sklearn.impute import SimpleImputer\n",
    "def fillDaysWaiting(dataFrame): \n",
    "    median = dataFrame['days_waiting'].median()\n",
    "    dataFrame['days_waiting'].fillna(median, inplace=True)\n",
    "    dataFrame['days_waiting'] = dataFrame['days_waiting'].astype(int)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'frau': 23, 'wenn': 64, 'noch': 48, 'ihnen': 32, 'zur': 74, 'grüße': 25, 'beide': 8, 'paar': 51, 'schon': 54, 'können': 38, 'grüßen': 26, 'aber': 3, 'wird': 67, 'werde': 65, 'möchte': 43, 'besichtigungstermin': 11, 'freue': 24, 'ihre': 33, 'kinder': 37, 'ab': 2, '01': 0, '2020': 1, 'unbefristeten': 61, 'einkommen': 19, 'haustiere': 31, 'um': 60, 'rückmeldung': 53, 'name': 45, 'meiner': 41, 'den': 15, 'am': 5, 'möchten': 44, 'unsere': 62, 'daher': 12, 'aus': 7, 'es': 21, 'nicht': 46, 'das': 13, 'suchen': 57, 'derzeit': 16, 'wäre': 70, 'sich': 56, 'nichtraucher': 47, 'schufa': 55, 'besichtigung': 10, 'aktuell': 4, 'zum': 73, 'guten': 27, 'tag': 58, 'mir': 42, 'ruhige': 52, 'hallo': 28, 'jahren': 35, 'hamburg': 29, 'dem': 14, 'oder': 50, 'dringend': 18, 'interesse': 34, 'werden': 66, 'meinem': 39, 'zimmer': 72, 'familie': 22, 'tochter': 59, 'hat': 30, 'bereits': 9, 'wohnen': 69, 'diese': 17, 'arbeitet': 6, 'wohne': 68, 'zeit': 71, 'zwei': 75, 'meinen': 40, 'eltern': 20, 'kann': 36, 'nun': 49, 'vor': 63}\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 16 columns):\n",
      "portrait                 3168 non-null int64\n",
      "residents                3115 non-null float64\n",
      "householdType            3117 non-null category\n",
      "guarantorExist           3168 non-null int64\n",
      "furtherInformation       3168 non-null int64\n",
      "professionType           3064 non-null category\n",
      "income                   3104 non-null float64\n",
      "age                      2959 non-null float64\n",
      "WB_CERTIFICATE           3168 non-null int64\n",
      "CREDIT_REPORT            3168 non-null int64\n",
      "INCOME_STATEMENT         3168 non-null int64\n",
      "wbs                      3121 non-null float64\n",
      "animals                  3072 non-null float64\n",
      "days_waiting             3168 non-null int64\n",
      "noRentArrears            892 non-null float64\n",
      "noTenancyLawConflicts    883 non-null float64\n",
      "dtypes: category(2), float64(7), int64(7)\n",
      "memory usage: 353.4 KB\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as plt\n",
    "import pandas as pd\n",
    "\n",
    "dataFrame = pd.read_json(datapath + \"formattedTenants.json\")\n",
    "dataFrame = cleanData(dataFrame)\n",
    "\n",
    "countWords(dataFrame)\n",
    "dataFrame.info()\n",
    "sample_incomplete_rows = dataFrame[dataFrame.isnull().professionType & dataFrame.isnull().income & dataFrame.isnull().residents]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 46 entries, 0 to 2257\n",
      "Data columns (total 16 columns):\n",
      "portrait                 46 non-null int64\n",
      "residents                0 non-null float64\n",
      "householdType            0 non-null category\n",
      "guarantorExist           46 non-null int64\n",
      "furtherInformation       46 non-null int64\n",
      "professionType           0 non-null category\n",
      "income                   0 non-null float64\n",
      "age                      0 non-null float64\n",
      "WB_CERTIFICATE           46 non-null int64\n",
      "CREDIT_REPORT            46 non-null int64\n",
      "INCOME_STATEMENT         46 non-null int64\n",
      "wbs                      1 non-null float64\n",
      "animals                  1 non-null float64\n",
      "days_waiting             46 non-null int64\n",
      "noRentArrears            0 non-null float64\n",
      "noTenancyLawConflicts    0 non-null float64\n",
      "dtypes: category(2), float64(7), int64(7)\n",
      "memory usage: 6.1 KB\n",
      "Median Days Waiting 11.0\n",
      "{'name': None, 'gender': None, 'smoker': None, 'portrait': False, 'firstname': None, 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 9}\n",
      "{'name': 'Al sawah', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Ahmad', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 19}\n",
      "{'name': 'Arcangioli', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Bruna', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 18}\n",
      "{'name': 'Avrisia', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Ameen', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 14}\n",
      "{'name': 'Behrens', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Norbert', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 12}\n",
      "{'name': 'Betteto', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Brigitte', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 3}\n",
      "{'name': 'Böhm', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Christoph', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 3}\n",
      "{'name': 'Boldt', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Marco', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 29}\n",
      "{'name': 'Crentsil', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Cecilia', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 0}\n",
      "{'name': 'Ebaykleinanzeigen', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Anna', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 2}\n",
      "{'name': 'Eckard ', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Thomas ', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 11}\n",
      "{'name': 'Elhossiny', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Ahmed', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 16}\n",
      "{'name': 'Flesch', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Beate', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 21}\n",
      "{'name': 'Ginghina', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Oana', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 26}\n",
      "{'name': 'Girginer', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Efe', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 22}\n",
      "{'name': 'Golisz', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Brigitte', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 10}\n",
      "{'name': 'Henschel', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Siegfried', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 18}\n",
      "{'name': 'Herrmann', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Peter', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 19}\n",
      "{'name': 'Horan', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Tom', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 22}\n",
      "{'name': 'Hülsenbusch', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Michael', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 2}\n",
      "{'name': 'Hummins', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Bondolo', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 0}\n",
      "{'name': 'Jurakic', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Mario', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 15}\n",
      "{'name': 'Karaarslan', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Cenk', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 10}\n",
      "{'name': 'Kierznowski', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Kamil', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 11}\n",
      "{'name': 'Kieslich', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Martin', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 7}\n",
      "{'name': 'Lopez', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Jorge', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 10}\n",
      "{'name': 'Loydl', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Hannah', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 2}\n",
      "{'name': 'Mashido', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Raschido', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 5}\n",
      "{'name': 'Matzat', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Jörg', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 17}\n",
      "{'name': 'Mazohl', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Fabian', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 25}\n",
      "{'name': 'Mertens', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Constanze', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 8}\n",
      "{'name': 'Niemann', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Joline', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': '', 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 6}\n",
      "{'name': 'ocran', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Jennifer', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 12}\n",
      "{'name': 'Pinl', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Harald', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 2}\n",
      "{'name': 'Post', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Elisabeth', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 13}\n",
      "{'name': 'Rahimi', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Farahnaz', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 19}\n",
      "{'name': 'Sauter', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Melanie', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 6}\n",
      "{'name': 'Spahlinger', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Bastian', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 18}\n",
      "{'name': 'Thomsen ', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Jacqueline ', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 7}\n",
      "{'name': 'Vanina', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Katja', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 24}\n",
      "{'name': 'Wenig', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Jan', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 13}\n",
      "{'name': 'Winzler', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Sophie', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 1}\n",
      "{'name': 'Wucher', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Nina', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 0}\n",
      "{'name': 'Yunlu', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Esen', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 7}\n",
      "{'name': 'Zerafat', 'gender': None, 'smoker': None, 'portrait': False, 'firstname': 'Omid', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': None, 'music': None, 'animals': None, 'bailment': None, 'days_waiting': 22}\n",
      "{'name': 'Mieter', 'gender': None, 'smoker': False, 'portrait': False, 'firstname': 'Offline', 'residents': None, 'householdType': None, 'guarantorExist': False, 'personalStatus': None, 'furtherInformation': '', 'allowSchufa': None, 'noRentArrears': None, 'noPoliceRecord': None, 'noTenancyLawConflicts': None, 'professionType': None, 'income': None, 'age': None, 'WB_CERTIFICATE': False, 'CREDIT_REPORT': False, 'SHARED_DOCUMENT': False, 'INCOME_STATEMENT': False, 'wbs': False, 'music': False, 'animals': False, 'bailment': False, 'days_waiting': 8}\n"
     ]
    }
   ],
   "source": [
    "sample_incomplete_rows.info()\n",
    "\n",
    "sample_incomplete_rows.head(46)\n",
    "\n",
    "print(\"Median Days Waiting\", sample_incomplete_rows[\"days_waiting\"].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "days_waiting             1.000000\n",
      "portrait                 0.057997\n",
      "guarantorExist           0.045396\n",
      "CREDIT_REPORT            0.043974\n",
      "noRentArrears            0.042067\n",
      "INCOME_STATEMENT         0.036750\n",
      "noTenancyLawConflicts    0.036434\n",
      "WB_CERTIFICATE           0.034386\n",
      "animals                  0.030572\n",
      "furtherInformation       0.017750\n",
      "residents                0.013589\n",
      "wbs                      0.006812\n",
      "income                  -0.023731\n",
      "age                     -0.026312\n",
      "Name: days_waiting, dtype: float64\n",
      "furtherInformation       1.000000\n",
      "portrait                 0.297094\n",
      "CREDIT_REPORT            0.216506\n",
      "INCOME_STATEMENT         0.178928\n",
      "guarantorExist           0.175448\n",
      "income                   0.038535\n",
      "residents                0.028455\n",
      "noTenancyLawConflicts    0.021353\n",
      "days_waiting             0.017750\n",
      "noRentArrears            0.014489\n",
      "animals                 -0.000681\n",
      "WB_CERTIFICATE          -0.007797\n",
      "wbs                     -0.077393\n",
      "age                     -0.077925\n",
      "Name: furtherInformation, dtype: float64\n",
      "age                      1.000000\n",
      "wbs                      0.114237\n",
      "income                   0.080822\n",
      "WB_CERTIFICATE           0.075556\n",
      "animals                  0.046258\n",
      "residents                0.026480\n",
      "CREDIT_REPORT            0.000565\n",
      "INCOME_STATEMENT        -0.025937\n",
      "days_waiting            -0.026312\n",
      "noTenancyLawConflicts   -0.030570\n",
      "portrait                -0.063660\n",
      "furtherInformation      -0.077925\n",
      "noRentArrears           -0.079574\n",
      "guarantorExist          -0.180963\n",
      "Name: age, dtype: float64\n",
      "income                   1.000000\n",
      "residents                0.198040\n",
      "age                      0.080822\n",
      "portrait                 0.040270\n",
      "furtherInformation       0.038535\n",
      "noTenancyLawConflicts    0.006947\n",
      "CREDIT_REPORT           -0.004446\n",
      "animals                 -0.019949\n",
      "noRentArrears           -0.022058\n",
      "days_waiting            -0.023731\n",
      "INCOME_STATEMENT        -0.028349\n",
      "guarantorExist          -0.083795\n",
      "WB_CERTIFICATE          -0.129513\n",
      "wbs                     -0.141792\n",
      "Name: income, dtype: float64\n",
      "Days Waiting:  14.0\n",
      "Age:  31.0\n",
      "Income:  2500.0\n",
      "Residents:  2.0\n",
      "Further Information:  253.5\n"
     ]
    }
   ],
   "source": [
    "corr_maxtrix = dataFrame.corr()\n",
    "print(corr_maxtrix['days_waiting'].sort_values(ascending=False))\n",
    "print(corr_maxtrix['furtherInformation'].sort_values(ascending=False))\n",
    "print(corr_maxtrix['age'].sort_values(ascending=False))\n",
    "print(corr_maxtrix['income'].sort_values(ascending=False))\n",
    "print(\"Days Waiting: \", dataFrame['days_waiting'].median())\n",
    "print(\"Age: \", dataFrame['age'].median())\n",
    "print(\"Income: \", dataFrame['income'].median())\n",
    "print(\"Residents: \", dataFrame['residents'].median())\n",
    "print(\"Further Information: \", dataFrame['furtherInformation'].median())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>portrait</th>\n",
       "      <th>residents</th>\n",
       "      <th>householdType</th>\n",
       "      <th>guarantorExist</th>\n",
       "      <th>furtherInformation</th>\n",
       "      <th>professionType</th>\n",
       "      <th>income</th>\n",
       "      <th>age</th>\n",
       "      <th>WB_CERTIFICATE</th>\n",
       "      <th>CREDIT_REPORT</th>\n",
       "      <th>INCOME_STATEMENT</th>\n",
       "      <th>wbs</th>\n",
       "      <th>animals</th>\n",
       "      <th>days_waiting</th>\n",
       "      <th>noRentArrears</th>\n",
       "      <th>noTenancyLawConflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   portrait  residents householdType  guarantorExist  furtherInformation  \\\n",
       "0         0        NaN           NaN               0                   0   \n",
       "1         0        NaN           NaN               0                   0   \n",
       "2         0        NaN           NaN               0                   0   \n",
       "3         0        1.0        SINGLE               0                   0   \n",
       "4         0        NaN           NaN               0                   0   \n",
       "\n",
       "  professionType  income  age  WB_CERTIFICATE  CREDIT_REPORT  \\\n",
       "0            NaN     NaN  NaN               0              0   \n",
       "1            NaN     NaN  NaN               0              0   \n",
       "2            NaN     NaN  NaN               0              0   \n",
       "3            NaN     NaN  NaN               0              0   \n",
       "4            NaN     NaN  NaN               0              0   \n",
       "\n",
       "   INCOME_STATEMENT  wbs  animals  days_waiting  noRentArrears  \\\n",
       "0                 0  NaN      NaN             9            NaN   \n",
       "1                 0  NaN      NaN            19            NaN   \n",
       "2                 0  NaN      NaN            18            NaN   \n",
       "3                 0  0.0      0.0            26            NaN   \n",
       "4                 0  NaN      NaN            14            NaN   \n",
       "\n",
       "   noTenancyLawConflicts  \n",
       "0                    NaN  \n",
       "1                    NaN  \n",
       "2                    NaN  \n",
       "3                    NaN  \n",
       "4                    NaN  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1080 with 16 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fa2e0f99950>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEHCAYAAACk6V2yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3de3xc5X3n8c9vbrqNLrYl321k4RtYYBtkG2wMNiEkITQ0bDYpaRoIpEBDumSz3Ww2223TtNvN5rWbhiYQoECAkNBQAkkKCSEkNhg72JaNwTK+Ist3WZJlXUaXuT77x5mRNTMacWY0E1mH3/v18ks+j386z/Ocy1dH54xnxBiDUkop53GN9wCUUkoVhga8Uko5lAa8Uko5lAa8Uko5lAa8Uko5lGe8BzBcdXW1qa2tHe9hKKXUhLFjx44OY0zNSP92XgV8bW0tjY2N4z0MpZSaMETkSKZ/01s0SinlUBrwSinlUBrwSinlUBrwSinlUBrwSinlUAUNeBGpEpFnRWSfiOwVkSsL2Z9SSqlzCv0yyfuAl4wxnxARH1Ba4P6UIhYzRI3BLYLLJRO230gkRigWw+dy4fHoL9sqewULeBGpAK4GbgMwxoSAUKH6UwpgMByltXuQmDG4RJheWUyx1z3h+u3qD9F0optozOB2CfWzKqkq9eVxxOr9oJCXBXVAO/ADEXlTRB4RkbIC9qfe52IxQ2v3IF63UFbkwesWK3Rjhf3Mg3z3G4nEaDrRTbHHxRR/EcUeF00nuolEYnkeuXK6Qga8B7gM+L4xZjnQB3w1tUhE7hSRRhFpbG9vL+BwlNNFjSFmDB63dVh73C5ixrptMpH6DcViRGOGYp/1C3axz0M0ZgjFNOBVdgoZ8MeB48aYrfHlZ7ECP4kx5mFjTIMxpqGmZsS3U1DKFrcILhEiUSsII9EYLhHcUtj78Pnu1+dy4XYJg6EIAIOhCG6X4HPpfXiVnYIdMcaYVuCYiCyKN30AeKdQ/Snlcln3vsNRQ18wQjhqmF5ZXPAHrfnu1+NxUT+rksFIjDOBIIORGPWzKvVBq8paoV9F85fAj+KvoGkGPlfg/tT7XLHXzdzJpX/wV9Hku9+qUh9XzJuir6JRY1LQgDfG7AIaCtmHUqlcLsHFH+7lkYXq1+Nx4dH/i6jGQI8epZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKE8hVy4iLUAvEAUixpiGQvQTixmixuAWweWSjHWRSIxQLIbP5cLjyfyzze767NZlI99jtKsQczmf+82mbydtm1AoykA0Sonbjc/nHnPf47UNs1lfvvser3M0FwUN+Lj1xpiOQq18MByltXuQmDG4RJheWUyxN/3A7eoP0XSim2jM4HYJ9bMqqSr15bw+u3XZyPcY7SrEXM7nfrPp20nbprV7gM2HOghHY3jdLtbMr2Z6ZUnOfY/XNsxmffnue7zO0VxN6Fs0sZihtXsQr1soK/LgdYu1UWMmqS4SidF0optij4sp/iKKPS6aTnQTicRyWp/dumzke4x2FWIu53O/2fTtpG0TCkXZfKiDEq+bGZUllHjdbD7UQSgUzanv8dqG2awv332P1zk6FoUOeAO8LCI7ROTOkQpE5E4RaRSRxvb29qxWHjWGmDF43NY0PG4XMWP9WjRcKBYjGjMU+6xfWIp9HqIxQygWy2l9duuyke8x2lWIuZzP/WbTt5O2zUA0Sjgao6zIOr7KijyEozEGoskBn+9tM57Ha777Hq9zdCwKHfBrjDGXAR8B7hGRq1MLjDEPG2MajDENNTU1Wa3cLYJLhEjU2sCRaAyXCG5Jvt/lc7lwu4TBUASAwVAEt0vwuVw5rc9uXTbyPUa7CjGX87nfbPp20rYpcbvxul30Ba3jqy8Ywet2UeJOvm2Q720znsdrvvser3N0LAoa8MaYk/GvbcDzwMp8rt/lsu5thaOGvmCEcNQwvbI47YGGx+OiflYlg5EYZwJBBiMx6mdVpj0gsbs+u3XZyPcY7SrEXM7nfrPp20nbxudzs2Z+NQPhKKe6BxgIR1kzvzrtQWu+t814Hq/57nu8ztGxEFOgXxtEpAxwGWN643//DfANY8xLmb6noaHBNDY2Zt2XvopGX0VTyL6dtG30VTTOexWNiOzI9ArFQr6KZhrwvFi/lniAH48W7mPhcgku3nsDejwuPDZ+abG7Prt12cj3GO0qxFzO536z6dtJ28bnc+PjvV/Nke9tM57Ha777Hq9zNBcFC3hjTDOwtFDrV0opNboJ/TJJpZRSmWnAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQ2nAK6WUQxU84EXELSJvisgLheqjs2eAfSc66ewZGLVucDBCR2CQwcHIqHWhUJTugRChUDQvdYG+EMc7AwT6QqPWgf25RCIx+kMRIpHYqHVdvYMcau2iq3cwL2Ps7w/T2t1Pf384L3U9gSAt7T30BIKj1kH+52L3eGg9G6DxUCutZwN56ddund35ZlNrd3vbrbN7HNqts7tPsjmn8n3e2+07FjOEozFiMTNqnd1tkwtP3teY7l5gL1BRiJX/bu8pHnr1XYLhKEVeN3ddcyHXXjQjra6lI8Cv95wiFInh87j40JIZ1Fb70+pauwfYfKiDcDSG1+1izfxqpleW5Fz39rFOnt52dGh8t6ycy6VzJo9pLl39IZpOdBONGdwuoX5WJVWlvrS61w+e5tFNzQTDMYq8Lu5YW8dVC6blPMb9p7p5/s3jBCMxijwuPr58NotmVOZct/1wO09saRka362ra1kxr2bEbZPvudg9Hp7dfoT7NxwkFDH4PMI96xfwiRUX5Nyv3Tq7882m1u72tltn9zi0W2d3n2RzTuX7vLfb92A4Smv3IDFjcIkwvbKYYq87522Tq4JewYvIbOCjwCOFWH9nzwAPvfouZV4PdVMrKPN6eOjVd9OufgcHI/x6zylKvV7mTC6j1Ovl13tOpf1ED4WibD7UQYnXzYzKEkq8bjYf6kj7iW63LtAX4ultRynzeZk3tZwyn5entx0d8Se/3blEIjGaTnRT7HExxV9EscdF04nutJ/+Xb2DPLqpmTKvl7qp5ZR5vTy6qTntCs/uGPv7wzz/5nFKfV5qq/2U+rw8/+bxtCt0u3U9gSBPbGlJGt8TW1pGvGLM91zsHg+tZwPcv+EgpV43F9SUUep1c/+Gg2lX8nb7tVtnd77Z1Nrd3nbr7B6Hduvs7pNszql8n/d2+47FDK3dg3jdQlmRB69brLBPuZK3u23GwlbAi8i9IlIhlkdFZKeIXG/jW78DfAXIOGIRuVNEGkWksb293eawLW29AwTDUar8RQBU+YsIhqO09SaHYiASIRSJUV5i/cJSXuIhFIkRiCTv6IFolHA0RlmRVVdW5CEcjTEQjeZU1xUMEQxHqSzzAlBZ5iUYjtIVTD8Y7c4lFIsRjRmKfVbfxT4P0ZghFEvexB19gwTDMar8vvj6fATDMTr6kk98u2PsCYcJRmJUlsbrSr0EIzF6wuGc6joHgiOOr3MgPeDzPRe7x8PxMwFCEUNlfJ9U+osIRQzHzyQHvN1+7dbZnW82tXa3t906u8eh3Tq7+ySbcyrf573dvqPGEDMGj9uKV4/bRcwYoiY54O1um7GwewV/uzGmB7geqAE+B3xztG8QkRuBNmPMjtHqjDEPG2MajDENNTUj/3qeydTyEoq8brriVxddgSBFXjdTy5N/tfJ7PPg8LnoHrB3bOxDB53Hh9yTfoSpxu/G6XfQFrbq+YASv20WJ251TXVWRjyKvm+4+K9y6+8IUed1UFaX/CmZ3Lj6XC7dLGAxZfQ+GIrhdgs+VvCury4op8rroCoTi6wtR5HVRXVac0xgrvF6KPC6641fi3f1hijwuKrzenOomlxSNOL7JJUVp2ybfc7F7PMye4sfnEbrj+6Q7EMTnEWZPSf4V326/duvszjebWrvb226d3ePQbp3dfZLNOZXv895u324RXCJEolZQR6IxXCK4RXLaNmNhd02Jkd0A/MAY89awtkzWAB8TkRbgX4FrReSpnEaZweSKEu665kL6whGa23roC0e465oLmVyRHIrFxR4+tGQG/eEwxzr76A+H+dCSGRQXJ+9on8/NmvnVDISjnOoeYCAcZc38anw+d051/jIft6ycS18ozOG2XvpCYW5ZORd/WfrBaHcuHo+L+lmVDEZinAkEGYzEqJ9ViceTvCuryou5Y20dfeEwzW299IXD3LG2jqry5BPf7hhLS718fPls+kNhWjoC9IfCfHz5bEpLvTnVVfiLuHV1bdL4bl1dS4U/PeDzPRe7x8P0SX7uWb+A/nCUI+199Iej3LN+AdMnJQe83X7t1tmdbza1dre33Tq7x6HdOrv7JJtzKt/nvd2+XS7rnns4augLRghHDdMri3G5kiPT7rYZCzFm9Ce8ACLyA2AWMA9YCriBjcaYy211IrIO+CtjzI2j1TU0NJjGxkY7q0zS2TNAW+8AU8tL0gJxuMHBCIFIBL/Hk7aThwuFogxEo5S43Wk7OZe6QF+IrmCIqiLfiAdiLnOJRGKEYjF8LteoB0RX7yAdfYNUlxWPGBDZjrG/P0xPOEyF15sW2rnU9QSCdA4EmVxSNGK4F3Iudo+H1rMBjp8JMHuKPy3cc+nXbp3d+WZTa3d7262zexzarbO7T7I5p/J93tvtOxazbsu4RdLCfTi72yYTEdlhjGkY8d9sBrwLWAY0G2O6RGQKMMsY87bNAayjgAGvlFLvV6MFvN0fF78xxuw0xnQBGGPOAP9kdwDGmI3vFe5KKaXya9TXwYtIMVAKVIvIJM7dd68AZhZ4bEoppcbgvf6j013Al7DCfAfnAr4HuL+A41JKKTVGowa8MeY+4D4R+UtjzHf/QGNSSimVB7beqsAY810RWQ3UDv8eY8yTBRqXUkqpMbIV8CLyQ+BCYBeQ+O9dBtCAV0qp85TdNxtrAC42dl5TqZRS6rxg92WSTcD0Qg5EKaVUftm9gq8G3hGRbcDQuw4ZYz5WkFEppZQaM7sB//VCDkIppVT+2X0VzasicgGwwBjzioiUYr0fjVJKqfOU3feD/3PgWeCheNMs4GeFGpRSSqmxs/uQ9R6st//tATDGHASmFmpQSimlxs5uwAeNMUMfWyIiHqzXwSullDpP2Q34V0Xka0CJiHwQ+Dfg3ws3LKWUUmNlN+C/CrQDu7HegOyXwF8XalBKKaXGzu6raGLAv8T/KKWUmgDe6/3gdzPKvXZjzKV5H5FSSqm8eK8r+MSnMN0T//rD+Nc/BfoLMiKllFJ58V7vB38EQETWGGPWDPunr4rIZuAbhRycUkqp3Nl9yFomIlclFuLvDV9WmCEppZTKB7vvRXMH8JiIVMaXu4DbCzMkpZRS+WD3VTQ7gKUiUgGIMaa7sMNSSik1Vu/1KprPGGOeEpEvp7QDYIz5dgHHppRSagze6wo+cZ+9vNADUUoplV/v9Sqah+Jf/+4PMxyllFL5Yvftgr8lIhUi4hWR34pIh4h8ptCDU0oplTu7L5O83hjTg/Ufn44DC4H/WrBRKaWUGjO7Ae+Nf70BeNoY01mg8SillMoTu6+D/3cR2QcMAF8QkRpgsHDDUkopNVa2ruCNMV8FrgQajDFhrPehuamQA1NKKTU2dh+ylmK94dj3400zgYZCDUoppdTY2b0H/wMgBKyOLx8H/mG0bxCRYhHZJiJvicgeESnYSy1PdvbyxoFTnOzsHbXuaEc3G985wdGO0f8jbuvZAI2HWmk9Gxi1ricQpKW9h55AcNS6zp4B9p3opLNnYNQ6gEBfiOOdAQJ9oVHrunoHOdTaRVfv6HfKDrSe4Rc7j3Cg9Uxe6prbzvLS28dobjs7al1LexevNB2npb0rL3Vgf7+0dfWx63AbbV19o9bZncu+Ux0839jCvlMdeek33/MAOHS6kxd3HeXQ6dEfj9nt2+5xePxMD6/vO8nxMz2j1tk9B+yOz25dNmMcHIzQERhkcDAyal1Hdz9NRzvo6B79DXXtjtHu+nJh9x78hcaYT4nILQDGmAFJ/HfWzILAtcaYgIh4gddF5FfGmDfGMuBUT79xmPs3HCQUMfg8wj3rF3DLFfPS6h597SAPbDhIOGbwuoQvrF/AHVcvSKt7dvuRtPV9YsUFaXXbD7fzxJYWguEYRV4Xt66uZcW8mrS63+09xUOvvkswHKXI6+auay7k2otmjDiXt4918vS2o0O1t6ycy6VzJqfVvX7wNI9uah7q+461dVy1YFpa3bd+uZvHNh0lasAtcPvauXzlhktyrvvuK3t5+NVmIjHwuODOa+r4y+suSqt7cMN+Htx4iHAMvC64e9187l6/KOc6sL9ffvHmsbS6jy2fk/Nc/vHf3+LxzceJAm7gtjWz+dofLc2533zPA+Dbv97DI6+1EI2B2wWfv7qWL39oSc592z0On9z8LvdvOEg4avC6rfV9ds2FaXV2zwG747Nbl80YWzoC/HrPKUKRGD6Piw8tmUFttT+t7qXdJ/j+xkND595frJvPhy+ZlfMY7a4vV3av4EMiUkL8wz9E5EKsAM/IWBI/urzxP3n9oO6Tnb3cv+EgJR4Xc6vLKPG4uH/DwbQr+aMd3Tyw4SDFHhezJpVR7HHxwIaDaVfyrWcD3L/hIKVeNxfUlFHqdXP/hoNpP4F7AkGe2NJCmddL3dRyyrxentjSknYl39kzwEOvvkuZ10Pd1ArKvB4eevXdEa9iAn0hnt52lDKfl3lTyynzeXl629G0K6iu3kEe3dSc1Pejm5rTruQPtJ7hsU1H8bqgusKH1wWPbTqadoVut6657SwPv9qMzwXTKovxueDhV5vTrn5b2rt4cOMhitzCjKoSitzCgxsPpV2h263LZr+0dfVx/4aDlHk91Nb4KfN6uH/DwbQrYLtz2Xeqg8c3H8cjMMXvxSPw+ObjaVfydvvN9zzAunJ/5LUWfC6oqSzC54JHXmtJu5K327fd4/D4mZ6hc2/25HPnXupVst1zwO747NZlM8bBwQi/3nOKUq+XOZPLKPV6+fWeU2lX8h3d/Xx/4yFKvR7mTS2n1Ovh+xsPpV152x2j3fWNxXsGfPxK/UHgJWCOiPwI+C3wFRvf6xaRXUAb8BtjzNYRau4UkUYRaWxvb89q8Ec7AoQihkp/MQCV/mJCEcPRjuQN2dwWIBwzVJRZdRVlxYRjhua25LrjZxLrK4qvr4hQxHD8THJd50CQYDhGld8HQJXfRzAco3MgOeDbegcIhqNUxddX5S8iGI7S1pse8F3BEMFwlMoy6xWplWVeguEoXcHkE6ujb3DEvjv6kgN+38kAUQP+MqvOX+Yjaqz2XOoOtAaIxKA8vg3Ly4qJxKz24Q6dDhBOqQvHrPZc6sD+fjl5tm/EupNnk4PR7lz2nggQBfzxfeIv8xKNt+fSb77nAbD/VIBoDPxlRfExFhGNWe259G33OGxpDxCOppxTUUNLe8oPK5vngN3x2a3LZoyBSIRQJEZ5iXVDo7zEQygSIxBJDvjW7v74uTd8LjFaUwLZ7hjtrm8s3jPgjTEGuBe4GbgNeBrr1TQbbXxv1BizDJgNrBSR+hFqHjbGNBhjGmpq0m9xjGZutR+fR+gOWOHWHRjE5xHmpvxqVTfVj9cl9MRDsKdvEK9LqJuaXDd7SmJ9wfj6gvg8wuwpyXWTS4oo8rroClgHfVcgRJHXxeSSoqS6qeUlFHnddMXX1xUIUuR1M7W8JG0uVUU+irxuuvvCVt99YYq8bqqKfEl11WXFI/ZdHT+IExbP9OMWhq68An0h3GK151K3cLofjwt649uwt28Qj8tqH27+ND/elDqvy2rPpQ7s75eZk8pGrJs5KfmjC+zO5aJZftxAIL5PAn1h3PH2XPrN9zwAFs3w43ZBoC8YH2MQt8tqz6Vvu8dhbY0frzvlnHILtTXJ67N7Dtgdn926bMbo93jweVz0DliB3jsQwedx4fck38GeXlkaP/eGz8XF9MrSnMZod31jYfcWzRtAnTHmRWPMC8aY0Z82pTDGdAEbgQ9nOb5RzZxczj3rFzAQiXG0o4+BSIx71i9g5uTk90abW13JF9YvYDAS48TZPgYjMb6wfgFzqyuT6qZP8nPP+gX0h6Mcae+jPxzlnvULmD4pecdU+Iu4dXUtfeEwzW299IXD3Lq6lgp/csBPrijhrmsupC8cobmth75whLuuuZDJFekB7y/zccvKufSFwhxu66UvFOaWlXOHrqwTqsqLuWNtXVLfd6yto6o8OeAXTp/C7WvnEo5BR0+IcMy6t75w+pSc6uqmTuLOa+oIxeB09yChmHXfum7qpKS62poq7l43n2DUcKprgGDUcPe6+dTWVOVUl81+mVpVxj3rF9AXjtDSHqAvHOGe9QuYWpUcjHbnsnhGNbetmU3EwJlAmIix7sEvnlGdU7/5ngfA/GmT+fzVtYRi0N4dJBSz7sHPn5Z8z9xu33aPw9lTKobOveOd58692VMqkursngN2x2e3LpsxFhd7+NCSGfSHwxzr7KM/HOZDS2ZQXJwc8NWVpfzFuvn0hyMcbuulPxzhL9bNpzolkO2O0e76xkKsC/T3KBJ5B+vtCY4AfYBgXdxn/NDt+H+GChtjuuL3718G/o8x5oVM39PQ0GAaGxuznIJ1L/5oR4C51f60cB/uaEc3zW0B6qb608J9uNazAY6fCTB7in/EAyehJxCkcyDI5JKitHAfrrNngLbeAaaWl4wY7sMF+kJ0BUNUFfnSTqrhunoH6egbpLqsOC3chzvQeoZ9JwMsnulPC+1c6prbznKgNcDC6f60QByupb2LQ6cDzJ/mHzG0s60D+/ulrauPk2f7mDmpbMRQzHYu+051sPdEgItm+dPCPZd+8z0PsO7F7z8VYNEMf1q459K33ePw+JkeWtoD1Nb404JzOLvngN3x2a3LZoyDgxECkQh+jyct3Ifr6O6ntbuf6ZWlo4ax3THaXV8mIrLDGDPiy9btBvyIj6gTn9ma4XsuBZ7AevGBC3jGGDPqZ7jmGvBKKfV+NVrA2/1Ep4xBPsr3vA0sz/b7lFJK5Yfde/BKKaUmGA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKA14pZRyKE+hViwic4AngelADHjYGHNfIfr65TsH2doUYFW9nxsuXpCxbufRU7zdEuDSWj+XzZ2RsW7jwRa27w+wYpGfdQtqx1z30t5DbN0TYNUSPx++aP6oc3lhz4Ghudy4ZGHGulf2N7N1b4BVF/m5blFdxrqX973L1ncCrLrYz/WLL8xY9+xb7wz1+4mlF2ese2bXnqG6Ty5bMub12a0D+JffN7KlKcDqej9/fmVDxrrHtr05tM7bVy7/g83ltUNHaDwQoGGhn6vnX5CxbkvzMXYeCnDZfD+r6+aMuS6bvu0ei3bX92TjW0Pb5rMNSzPWvf7uUXYcDHD5Aj9XXTg3Y92uY63sPhLgkgv8LJszPWOd3XMP4HcHDrNtX4CVi/1cu3BexrrGIyd563CApfP8NFwwc8x9N51oY8+xAEvm+KmfNTVjXU8gSOdAkMklRVT4i0adS7bEGJPXFQ6tWGQGMMMYs1NEyoEdwB8bY97J9D0NDQ2msbExq34+/s8befNk39Dy8pllPP+f1qXVfflfG3lu1+mh5ZuXTePbf5IeEn/28GY2NXcNLa+tq+KHd67Jue4/fPdVdpwIDC1fPsvPT//ymhHnctN9G3jrVP/Q8tIZpfz83vVpdZ96YBNbj/YMLa+aW8FPvrA2re4/fu81th/vHVpeMbucf/vi1Wl1H/p/v2F/e2hoeVGNj1//lw+m1X3w/77MwY7w0PKCai+/+avrc16f3TqAVX//IqfP7WamlcHW//nRtLrV//giJ89tGmZWwJavpdfley63PbKFjYfODi2vmz+Jxz+/Oq3uzsff4OV9Z4aWr188hYdvuyLnumz6tnss2l3f2m/+kmNd5/JjTpWw6as3pNXd8djv+e2BzqHlDyyczKO3X5lW95VndvDMztah5U9eNp1vffLytDq75x7Apx98nS0t3UPLq2sr+fHdV6XV3fvj7fz87bah5Zsuncp9n16Rc99/89ybPLXtJDGs2ySfWTmTb9ycfrGx/XA7T2xpIRiOUeR1cevqWlbMqxlxLpmIyA5jzIhXPAW7RWOMOWWM2Rn/ey+wF5iVzz5++c7BpHAHePNkH79852BS286jp4bCvcxrtT236zQ7j55Kqtt4sGVo57njbZuau9h4sCWnupf2Hko6oQB2nAjw0t5DaXN5Yc+BpHAHeOtUPy/sOZDU9sr+5qFwl3jb1qM9vLK/Oanu5X3vJoU7wPbjvby8792ktmffeicpwAD2t4d49q3kn8PP7NqTFIgABzvCPLNrT07rs1sH1pX76eTdzOk+q324x7a9mRTuACd7rPZCzuW1Q0eGAjHxK/HGQ2d57dCRpLotzceGQtsX33kv7zvDluZjOdVl07fdY9Hu+p5sfCsp3AGOdRmebHwrqe31d48OhXv81OO3Bzp5/d2jSXW7jrXyzM5WBLkOji4AABNFSURBVCj3CQI8s7OVXcdak+rsnntgXbknwj0RdFtauvndgcNJdY1HTg6Fe0l80j9/u43GIydz6rvpRBtPbTuJG5hU7MYNPLXtJE0n2pLqegJBntjSQpnXS93Ucsq8Xp7Y0kJPIJg2l1z9Qe7Bi0gtsBzYOsK/3SkijSLS2N7entV6tzYFbLW/3WItJ8I98TXRnrB9v7Wc2HnulPZs67buyTC+EdrtzmXrXms5Ee6S0j5U906G9aW02+53nOoAtmSoTW0frzE2HrCWE4HoSWlP2HnIWk6EduJroj3bumz6tnss2l6fzW2z46C1nAh3b0p7wu4j1rI/PtnE10R7gt1zD2DbPqstEXKulPaEtw5by4lwT3xNtGfb955jAWKAv9iq8Be7icXbh+scCBIMx6jy+wCo8vsIhmN0DkyggBcRP/BT4EvGmJ7UfzfGPGyMaTDGNNTUZPeryap6v632S2ut5b74RVvia6I9YcUiazkaX46mtGdbt2pJhvGN0G53LqsuspYT104mpX2o7uIM60tpt93vONUBrM5Qm9o+XmNsWGgtR+LLkZT2hMvmW8uh+E5LfE20Z1uXTd92j0Xb67O5bS5fYC0nfl8Kp7QnXHKBtRyITzbxNdGeYPfcA1i52GqLxZdjKe0JS+dZywPxySa+Jtqz7XvJHD8uIDBoVQQGo7ji7cNNLimiyOuiK2D9ltgVCFHkdTG5JH/34Qsa8CLixQr3Hxljnsv3+m+4eAHLZ5YltS2fWZb2oPWyuTO4edk04Fy437xsWtqD1nULallbVwWc23lr66rSHqTYrfvwRfO5fFbKAT9r5IdbNy5ZyNIZpUltS2eUpj1ovW5RHavmVgDDwn1uRdqD1usXX8iK2eVJbStml6c9aP3E0otZVONLaltU40t7mPjJZUtYUO1NaltQ7U17OGl3fXbrAP78ygamJe9mppWR9qD19pXLmVmRXDezgrQHrfmey9XzL2Dd/EnAuUBcN39S2sPJ1XVzuH7xFOBcaF+/eEraA1S7ddn0bfdYtLu+zzYsZU6VJLXNqZK0B61XXTiXDyycDJwL9w8snJz2oHXZnOl88rLpGKA3ZDBY9+BTH7TaPfcArl04j9W1lcC5cF9dW5n2oLXhgpncdKn1EDQR7jddOjXtQavdvutnTeUzK2cSBc4ORoli3YNPfdBa4S/i1tW19IXDNLf10hcOc+vq2rw+aC3kQ1YBngA6jTFfsvM9uTxkBX0Vjb6KJpm+ikZfRTOc019FM9pD1kIG/FXAJmA3536Afs0Y88tM35NrwCul1PvVaAFfsNfBG2Ne59wzQKWUUn9g+j9ZlVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoTTglVLKoQoW8CLymIi0iUhTofpQSimVmaeA634c+B7wZAH7AOChzdt4vSnAVfV+7lqzMmPdluZj7DwU4LL5flbXzclY97Pd+9jaFGBVvZ8/vmTxmPt9fPuuofXdtmLZqHN5asfbQ7WfufzSjHX3/fY1NjQFWF/v594PXJ2x7uEt29ncFGBNvZ87V6/IWPfAa7/n1aYA19T7+cLVV2as+/bLG9jQ1M/6+lK+fP36MY/vexs3D9V9cd2ajHUAj217c2jb3L5yeca6B1/fyqamAGvr/dx91aqMdd955dWhvr903TVjrnt0607eaApwRb2fO1ZdlrHuxzt3D83j05ddMuY6gF807R+q/Vj9ojHP5ZE3dvD7pgBX1vv5/BWXZ6x7Yc+BoX5vXLIwY53dc+qV/c1s3Rtg1UV+rltUl7HudwcOs21fgJWL/Vy7cF7GOrC/HZ97e+9Q3c2XXpSxbuPBFrbvD7BikZ91C2oz1r1x+Dhvvhtg+YV+rpg3O2PdtpYT7GoOsKzOz8raWaPOJVtijMnrCpNWLlILvGCMqbdT39DQYBobG7PqY8XfvUj7wLnlmhLY/rcfTau78/E3eHnfmaHl6xdP4eHbrkir++g//ZY9pweHlpdMK+bF//yBnPtd879f5ET3ueVZlbD5v6fXAVzzf37FkbOxoeULJrl49b99JK3ukv/+Ir3Ddlu5wO7/nb7Old94kbb+c8tTS2Hb36TXXfY3L9IZOrc82Qc7v5Fed/FXX2TY6igF3vlmep3d8S376xfpipxbrvLArn8Yedus/scXOdlzbnlmBWz5Wnptw9dfpOPc7qO6GBq/nl5X/9UXCQxb9gNNI8zFbt2V/+tFTvWeW55RDr//H+l167/1Eoc7o0PL8ya72fCVD+dcB/BH3/kdu1vPHYyXTC/h3790bc5zueIfXqR1WOF0P7zx1+l1N923gbdOnTsils4o5ef3pv/Qt3tOfeqBTWw9em4nr5pbwU++sDat7tMPvs6WlnMn1eraSn5891VpdWB/O37k26+wty04tHzR1CJ+9eXr0ur+7OHNbGruGlpeW1fFD+9MvzD5iye38qt3Os6t/+Jqvv/Z9IuNLz61jRea2oeWb6yv4XufyXyxOBIR2WGMaRjp3yb0PfiHNm9LClmA9gGrfbgtzceGwt0nVtvL+86wpflYUt3Pdu9LOhAB9pwe5Ge79+XU7+PbdyWFO8CJbqs91VM73k4Kd4AjZ2M8tePtpLb7fvtaUngC9BqrfbiHt2xPCneAtn6rfbgHXvt9UrgDdIas9uG+/fIGUlZHf7w9l/F9b+PmpHAH6IpY7ake2/ZmUrgDnOyx2od78PWtSeEO0DFotQ/3nVdeTQo6gEC8PZe6R7fuTAp3gFO9VvtwP965OylsAA53Rvnxzt051YF15T483AF2tw7wi6b9Oc3lkTd2JIU7QGvAah/uhT0HksId4K1T/byw50BSm91z6pX9zUPhHj9F2Xq0h1f2NyfV/e7A4aFwT4TXlpZufnfgMKnsbsfn3t6bFO4Ae9uCPPf23qS2jQdbhsLdHW/b1NzFxoMtSXVvHD4+FO5F8UH+6p0O3jh8PKluW8uJoXAvjq/whaZ2trWcSJtLrsY94EXkThFpFJHG9vb29/6GYV5vSj1kR27fechaToR74muiPWFrhvWlttvt1+76sqndkKEutX1zhrrU9lcz1KW2b2hKjfeR2+2Oz24d2N82mzLUpbbne4xvZKhLbbc7j/E8bn6foS61Pd9z2brXWk6Eu6S0J2zbZy0ngsuV0l7IMW7fby0nwt2d0p7w5rvWciLcE18T7Qm7mq3lRLgnviba82HcA94Y87AxpsEY01BTU5PV915V77fVftl8azkUv7JMfE20J6zKsL7Udrv92l1fNrXrM9Sltq/JUJfafk2GutT29fWlGfotTVm2Nz67dWB/26zNUJfanu8xXpGhLrXd7jzG87i5MkNdanu+57LqIms58cufSWlPWLnYWk78rhtLaS/kGFcsspYTvxNEU9oTll9oLQfjg0t8TbQnLKuzlgfjK0p8TbTnw7gH/FjctWYlNSXJbTUlpD3wXF03h+sXTwHOhfv1i6ekPWj940sWs2RacVLbkmnFaQ+F7PZ724plzKpMrptVyYgPWj9z+aVcMCl5d1wwyZX2oPXeD1xNuSQ1US6kPci8c/UKpqZk8tRS0h60fuHqK5nsS66b7CPtQeuXr19PasSXxttzGd8X162hKuURf5WHER+03r5yOTMrkttmVpD2oPXuq1ZRnbz7qC4m7UHrl667htRTyB9vz6XujlWXMaM8uW5GOWkPWj992SXMm+xOaps32Z324M9uHcDH6hdxyfTkg/GS6SVpD1rtzuXzV1zO9JTC6X7SHrTeuGQhS2ckHxFLZ5SmPWi1e05dt6iOVXOtnTwU7nMr0h60XrtwHqtrrZMqEe6raytHfNBqdzvefOlFXDS1KKntoqlFaQ9a1y2oZW1dFXAu3NfWVaU9aL1i3mw+cnE1cC7cP3JxddqD1pW1s7ix3rqoTYT7jfU1eX3QWrCHrCLyNLAOqAZOA39rjHl0tO/J5SEr6Kto9FU0yfRVNPoqmuGc/iqa0R6yFvRVNNnKNeCVUur9yrGvolFKKZWZBrxSSjmUBrxSSjmUBrxSSjmUBrxSSjnUefUqGhFpB47k+O3VQMd7Vk0MTpmLU+YBOpfzkVPmAWObywXGmBH/l+h5FfBjISKNmV4qNNE4ZS5OmQfoXM5HTpkHFG4ueotGKaUcSgNeKaUcykkB//B4DyCPnDIXp8wDdC7nI6fMAwo0F8fcg1dKKZXMSVfwSimlhtGAV0oph5rwAS8iHxaR/SJySES+Ot7jGQsRaRGR3SKyS0Qm1NtqishjItImIk3D2iaLyG9E5GD866TxHKNdGebydRE5Ed83u0TkhvEcox0iMkdENojIXhHZIyL3xtsn3H4ZZS4Tar+ISLGIbBORt+Lz+Lt4e0H2yYS+By8ibuAA8EHgOLAduMUY8864DixHItICNBhjJtx/3hCRq7E+5vPJxIesi8i3gE5jzDfjP3wnGWP+23iO044Mc/k6EDDG/N/xHFs2RGQGMMMYs1NEyoEdwB8DtzHB9ssoc/kkE2i/iIgAZcaYgIh4gdeBe4GbKcA+mehX8CuBQ8aYZmNMCPhX4KZxHtP7kjHmNaAzpfkm4In435/AOiHPexnmMuEYY04ZY3bG/94L7AVmMQH3yyhzmVCMJfGhq974H0OB9slED/hZwLFhy8eZgDt9GAO8LCI7ROTO8R5MHkwzxpwC6wQFpo7zeMbqiyLydvwWznl/W2M4EakFlgNbmeD7JWUuMMH2i4i4RWQX0Ab8xhhTsH0y0QNeRmibuPecYI0x5jLgI8A98VsF6vzwfeBCYBlwCvh/4zsc+0TED/wU+JIxpme8xzMWI8xlwu0XY0zUGLMMmA2sFJH6QvU10QP+ODD8w1VnAyfHaSxjZow5Gf/aBjyPdQtqIjsdv3eauIfaNs7jyZkx5nT8xIwB/8IE2Tfx+7w/BX5kjHku3jwh98tIc5mo+wXAGNMFbAQ+TIH2yUQP+O3AAhGZJyI+4E+AX4zzmHIiImXxh0eISBlwPdA0+ned934B3Br/+63Az8dxLGOSOPniPs4E2DfxB3qPAnuNMd8e9k8Tbr9kmstE2y8iUiMiVfG/lwDXAfso0D6Z0K+iAYi/LOo7gBt4zBjzv8Z5SDkRkTqsq3YAD/DjiTQXEXkaWIf1tqengb8FfgY8A8wFjgL/0Rhz3j+8zDCXdVi3AQzQAtyVuGd6vhKRq4BNwG4gFm/+Gta96wm1X0aZyy1MoP0iIpdiPUR1Y11gP2OM+YaITKEA+2TCB7xSSqmRTfRbNEoppTLQgFdKKYfSgFdKKYfSgFdKKYfSgFdKKYfSgFdKKYfSgFcTUvxtYv9qvMeRSkRmisiz8b8vG/72tSLysYn+ltZqYtGAVyqPjDEnjTGfiC8uA24Y9m+/MMZ8c3xGpt6PNODVhCEi/yP+4S6vAIvibX8uItvjH6DwUxEpFZFyETkcf+8SRKRCrA9T8YrIfxKRd+LvPvivo/S1W0SqxHJGRD4bb/+hiFwnIrUisklEdsb/rI7/e62INMXfOuMbwKfiH0TxKRG5TUS+F697XET+WUS2iEiziHwi3u4SkQfiHwbxgoj8MvFvSmVLA15NCCJyOdZ7DS3H+nCEFfF/es4Ys8IYsxTrPcLviL9f+Ebgo/GaPwF+aowJA18FlhtjLgXuHqXLzcAaYAnQDKyNt18BvIH1ZlAfjL/756eAfx7+zfHPJ/gb4CfGmGXGmJ+M0McM4CrgRiBxZX8zUAtcAnweuHKUMSo1Kg14NVGsBZ43xvTH3yY28aZy9fEr6d3An2IFMsAjwOfif/8c8IP4398GfiQinwEio/S3Cbg6/uf7wCUiMgvrU3cCWB/U8C/xfv8NuDiHOf3MGBOLfwLZtHjbVcC/xdtbgQ05rFcpQANeTSwjvXHS48AXjTGXAH8HFAMYYzYDtSJyDeA2xiTeZfCjwP3A5cAOEfFk6Os1rB8qa7F+G2gHPoEV/AD/GeuNyJYCDYAvh/kEh/1dUr4qNWYa8GqieA34uIiUxN9W+Y/i7eXAqfj99j9N+Z4ngaeJX72LiAuYY4zZAHwFqAL8I3VmjDmG9W6SC4wxzVifnflXnAv4SuBU/H3I/wzr3QFT9cbHl43Xgf8Qvxc/DetdLJXKiQa8mhDin8f5E2AX1oc+JIL2f2K9/e1vsN5Xe7gfAZOwQh6sEH4qflvlTeCf4h+6kMlWrA91J97fLKwABngAuFVE3gAWAn0jfP8G4OLEQ1Y784zP7TjW+5o/FB9Dt83vVSqJvl2wcqz4q09uMsb82XiPJRsi4jfGBOLvEb4N66McW8d7XGriyXT/UakJTUS+i/XZtje8V+156IX4p/74gL/XcFe50it49b4mIp8D7k1p3myMuWc8xqNUPmnAK6WUQ+lDVqWUcigNeKWUcigNeKWUcigNeKWUcqj/D1qXfgnoYK8YAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "dataFrame.hist(bins=50, figsize=(20,15))\n",
    "plt.show()\n",
    "\n",
    "dataFrame.plot(kind=\"scatter\", x=\"days_waiting\", y=\"income\",\n",
    "             alpha=0.1)\n",
    "\n",
    "dataFrame.plot(kind=\"scatter\", x=\"days_waiting\", y=\"residents\",\n",
    "             alpha=0.1)\n",
    "\n",
    "dataFrame.plot(kind=\"scatter\", x=\"days_waiting\", y=\"age\",\n",
    "             alpha=0.1)\n",
    "\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3168 entries, 0 to 3167\n",
      "Data columns (total 16 columns):\n",
      "portrait                 3168 non-null int64\n",
      "residents                3115 non-null float64\n",
      "householdType            3117 non-null category\n",
      "guarantorExist           3168 non-null int64\n",
      "furtherInformation       3168 non-null int64\n",
      "professionType           3064 non-null category\n",
      "income                   3104 non-null float64\n",
      "age                      2959 non-null float64\n",
      "WB_CERTIFICATE           3168 non-null int64\n",
      "CREDIT_REPORT            3168 non-null int64\n",
      "INCOME_STATEMENT         3168 non-null int64\n",
      "wbs                      3121 non-null float64\n",
      "animals                  3072 non-null float64\n",
      "days_waiting             3168 non-null int64\n",
      "noRentArrears            892 non-null float64\n",
      "noTenancyLawConflicts    883 non-null float64\n",
      "dtypes: category(2), float64(7), int64(7)\n",
      "memory usage: 353.4 KB\n"
     ]
    }
   ],
   "source": [
    "dataFrame.info()\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "tenantData = dataFrame.drop(\"days_waiting\", axis = 1)\n",
    "\n",
    "days_labels = dataFrame[\"days_waiting\"].copy()\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, text_index in split.split(dataFrame, dataFrame[\"days_waiting\"]):\n",
    "    strat_train_set = dataFrame.loc[train_index]\n",
    "    strat_test_set = dataFrame.loc[text_index]\n",
    "    \n",
    "dataFrame = strat_train_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.83150716, -0.61432182, -1.1905349 , ..., -0.30831321,\n",
       "         0.03078745,  0.04356068],\n",
       "       [-0.83150716, -0.61432182, -1.1905349 , ..., -0.30831321,\n",
       "         0.03078745,  0.04356068],\n",
       "       [-0.83150716, -0.61432182, -1.1905349 , ..., -0.30831321,\n",
       "         0.03078745,  0.04356068],\n",
       "       ...,\n",
       "       [ 1.20263546, -0.61432182, -0.88933144, ..., -0.30831321,\n",
       "         0.03078745,  0.04356068],\n",
       "       [ 1.20263546, -0.61432182,  0.60395895, ..., -0.30831321,\n",
       "         0.03078745,  0.04356068],\n",
       "       [ 1.20263546,  1.62781129, -0.50752424, ..., -0.30831321,\n",
       "         0.03078745,  0.04356068]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer_features = list(tenantData.columns[tenantData.dtypes == np.int64])\n",
    "\n",
    "continuous_features = list(tenantData.columns[tenantData.dtypes == np.float64])\n",
    "\n",
    "integer_features.extend(continuous_features)\n",
    "\n",
    "tenantData_num = integer_features\n",
    "\n",
    "tenantData_categorial = list(tenantData.columns[tenantData.dtypes == np.object])\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "    ('std_scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "     ('cat', OneHotEncoder()),\n",
    "])\n",
    "full_pipeline = ColumnTransformer([\n",
    "    (\"num\", num_pipeline, tenantData_num),\n",
    "    ('cat', cat_pipeline, tenantData_categorial)    \n",
    "])\n",
    "\n",
    "tenantData_prepared = full_pipeline.fit_transform(tenantData)    \n",
    "\n",
    "tenantData_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(tenantData_prepared, days_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.268920627880684"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "waiting_predictions = lin_reg.predict(tenantData_prepared)\n",
    "lin_mse = mean_squared_error(days_labels, waiting_predictions)\n",
    "lin_rmse = np.sqrt(lin_mse)\n",
    "lin_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.005960606177498"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "lin_mae = mean_absolute_error(days_labels, waiting_predictions)\n",
    "lin_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [8.40243717 8.67111682 8.22821481 8.07884564 8.72814525 7.88806523\n",
      " 8.5454103  8.15302819 8.24440079 8.14113404]\n",
      "Mean: 8.308079822978707\n",
      "Standard deviation: 0.2578344041869049\n"
     ]
    }
   ],
   "source": [
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "\n",
    "lin_scores = cross_val_score(lin_reg, tenantData_prepared, days_labels,\n",
    "                             scoring=\"neg_mean_squared_error\", cv=10)\n",
    "lin_rmse_scores = np.sqrt(-lin_scores)\n",
    "display_scores(lin_rmse_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators='warn',\n",
       "                                                   n_jobs=None, oob_score=False,\n",
       "                                                   random_sta...\n",
       "                                                   warm_start=False),\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa2d41fe7d0>,\n",
       "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa2d41fe950>},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=False, scoring='neg_mean_squared_error',\n",
       "                   verbose=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_distribs = {\n",
    "        'n_estimators': randint(low=1, high=200),\n",
    "        'max_features': randint(low=1, high=8),\n",
    "    }\n",
    "\n",
    "forest_reg = RandomForestRegressor(random_state=42)\n",
    "rnd_search = RandomizedSearchCV(forest_reg, param_distributions=param_distribs,\n",
    "                                n_iter=10, cv=5, scoring='neg_mean_squared_error', random_state=42)\n",
    "rnd_search.fit(tenantData_prepared, days_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.647752618256442 {'max_features': 7, 'n_estimators': 180}\n",
      "8.82893430565985 {'max_features': 5, 'n_estimators': 15}\n",
      "8.643788064112805 {'max_features': 3, 'n_estimators': 72}\n",
      "8.786301862205711 {'max_features': 5, 'n_estimators': 21}\n",
      "8.654999643024485 {'max_features': 7, 'n_estimators': 122}\n",
      "8.649171582112116 {'max_features': 3, 'n_estimators': 75}\n",
      "8.649902326018465 {'max_features': 3, 'n_estimators': 88}\n",
      "8.644299785317333 {'max_features': 5, 'n_estimators': 100}\n",
      "8.622326834293007 {'max_features': 3, 'n_estimators': 150}\n",
      "10.298453833553557 {'max_features': 5, 'n_estimators': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.02136596, 0.0218904 , 0.27058615, 0.01025333, 0.02241599,\n",
       "       0.02289167, 0.06665835, 0.26872855, 0.25805565, 0.01773842,\n",
       "       0.01797926, 0.00060345, 0.00083282])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvres = rnd_search.cv_results_\n",
    "for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(np.sqrt(-mean_score), params)\n",
    "\n",
    "\n",
    "feature_importances = rnd_search.best_estimator_.feature_importances_\n",
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.2705861495719112, 'furtherInformation'),\n",
       " (0.2687285546713486, 'income'),\n",
       " (0.25805565208144693, 'age'),\n",
       " (0.06665835173619941, 'residents'),\n",
       " (0.02289166660035347, 'INCOME_STATEMENT'),\n",
       " (0.022415991503590773, 'CREDIT_REPORT'),\n",
       " (0.02189039751174698, 'guarantorExist'),\n",
       " (0.021365963132335426, 'portrait'),\n",
       " (0.017979262806207326, 'animals'),\n",
       " (0.017738418012486653, 'wbs'),\n",
       " (0.01025332565772959, 'WB_CERTIFICATE'),\n",
       " (0.0008328179185037831, 'noTenancyLawConflicts'),\n",
       " (0.0006034487961400831, 'noRentArrears')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_encoder = full_pipeline.named_transformers_['cat']\n",
    "attributes = tenantData_num + tenantData_categorial\n",
    "sorted(zip(feature_importances, attributes), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.594100786422778"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model = rnd_search.best_estimator_\n",
    "\n",
    "X_test = strat_test_set.drop(\"days_waiting\", axis=1)\n",
    "y_test = strat_test_set[\"days_waiting\"].copy()\n",
    "\n",
    "X_test_prepared = full_pipeline.transform(X_test)\n",
    "final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "final_rmse = np.sqrt(final_mse)\n",
    "final_rmse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.92777778, 12.14474032, 12.14474032])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testTenant = tenantData.iloc[17:20]\n",
    "\n",
    "final_model.predict(full_pipeline.transform(testTenant))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3168, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=100, cache_size=200, coef0=0.0, degree=2, epsilon=0.1, gamma='scale',\n",
       "    kernel='poly', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "svm_poly_reg = SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1, gamma=\"scale\")\n",
    "print(tenantData_prepared.shape)\n",
    "\n",
    "svm_poly_reg.fit(tenantData_prepared, days_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.63757392070404"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_final_predictions = svm_poly_reg.predict(X_test_prepared)\n",
    "svm_final_mse = mean_squared_error(y_test, svm_final_predictions)\n",
    "\n",
    "svm_final_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(tenantData, days_labels, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "X_train = full_pipeline.transform(X_train)\n",
    "X_valid = full_pipeline.transform(X_valid)\n",
    "X_test = full_pipeline.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_logdir = os.path.join(os.curdir, \"my_logs\")\n",
    "\n",
    "def get_run_logdir():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(root_logdir, run_id)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./my_logs/run_2020_11_04-12_16_44'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_logdir = get_run_logdir()\n",
    "\n",
    "run_logdir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1782 samples, validate on 594 samples\n",
      "Epoch 1/200\n",
      "1782/1782 [==============================] - 1s 366us/sample - loss: 177.4949 - val_loss: 106.5041\n",
      "Epoch 2/200\n",
      "1782/1782 [==============================] - 0s 98us/sample - loss: 86.5540 - val_loss: 72.1293\n",
      "Epoch 3/200\n",
      "1782/1782 [==============================] - 0s 80us/sample - loss: 72.1983 - val_loss: 70.8769\n",
      "Epoch 4/200\n",
      "1782/1782 [==============================] - 0s 80us/sample - loss: 70.8226 - val_loss: 70.3578\n",
      "Epoch 5/200\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 70.3132 - val_loss: 69.8518\n",
      "Epoch 6/200\n",
      "1782/1782 [==============================] - 0s 80us/sample - loss: 70.0014 - val_loss: 69.5633\n",
      "Epoch 7/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 69.8469 - val_loss: 69.6817\n",
      "Epoch 8/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 69.6188 - val_loss: 69.5715\n",
      "Epoch 9/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 69.4061 - val_loss: 69.8221\n",
      "Epoch 10/200\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 69.3384 - val_loss: 69.3881\n",
      "Epoch 11/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 69.1850 - val_loss: 69.3996\n",
      "Epoch 12/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 69.0150 - val_loss: 69.4392\n",
      "Epoch 13/200\n",
      "1782/1782 [==============================] - 0s 87us/sample - loss: 69.0266 - val_loss: 69.0425\n",
      "Epoch 14/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 68.8775 - val_loss: 69.0664\n",
      "Epoch 15/200\n",
      "1782/1782 [==============================] - 0s 86us/sample - loss: 68.7484 - val_loss: 68.8475\n",
      "Epoch 16/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 68.7054 - val_loss: 69.2475\n",
      "Epoch 17/200\n",
      "1782/1782 [==============================] - 0s 84us/sample - loss: 68.6908 - val_loss: 69.0333\n",
      "Epoch 18/200\n",
      "1782/1782 [==============================] - 0s 102us/sample - loss: 68.5245 - val_loss: 68.8005\n",
      "Epoch 19/200\n",
      "1782/1782 [==============================] - 0s 151us/sample - loss: 68.5004 - val_loss: 68.6969\n",
      "Epoch 20/200\n",
      "1782/1782 [==============================] - 0s 120us/sample - loss: 68.3712 - val_loss: 68.9382\n",
      "Epoch 21/200\n",
      "1782/1782 [==============================] - 0s 144us/sample - loss: 68.4321 - val_loss: 68.7937\n",
      "Epoch 22/200\n",
      "1782/1782 [==============================] - 0s 174us/sample - loss: 68.2663 - val_loss: 68.6562\n",
      "Epoch 23/200\n",
      "1782/1782 [==============================] - 0s 163us/sample - loss: 68.3000 - val_loss: 68.8430\n",
      "Epoch 24/200\n",
      "1782/1782 [==============================] - 0s 137us/sample - loss: 68.1803 - val_loss: 68.6304\n",
      "Epoch 25/200\n",
      "1782/1782 [==============================] - 0s 129us/sample - loss: 68.1553 - val_loss: 68.7467\n",
      "Epoch 26/200\n",
      "1782/1782 [==============================] - 0s 89us/sample - loss: 68.1115 - val_loss: 68.9366\n",
      "Epoch 27/200\n",
      "1782/1782 [==============================] - 0s 79us/sample - loss: 67.9817 - val_loss: 69.2423\n",
      "Epoch 28/200\n",
      "1782/1782 [==============================] - 0s 69us/sample - loss: 68.0823 - val_loss: 68.7944\n",
      "Epoch 29/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 67.9702 - val_loss: 68.8181\n",
      "Epoch 30/200\n",
      "1782/1782 [==============================] - 0s 94us/sample - loss: 67.9799 - val_loss: 68.5776\n",
      "Epoch 31/200\n",
      "1782/1782 [==============================] - 0s 82us/sample - loss: 67.7803 - val_loss: 68.7889\n",
      "Epoch 32/200\n",
      "1782/1782 [==============================] - 0s 83us/sample - loss: 67.8667 - val_loss: 68.7389\n",
      "Epoch 33/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 67.7890 - val_loss: 68.6723\n",
      "Epoch 34/200\n",
      "1782/1782 [==============================] - 0s 82us/sample - loss: 67.7092 - val_loss: 69.0700\n",
      "Epoch 35/200\n",
      "1782/1782 [==============================] - 0s 79us/sample - loss: 67.6511 - val_loss: 68.6217\n",
      "Epoch 36/200\n",
      "1782/1782 [==============================] - 0s 89us/sample - loss: 67.6663 - val_loss: 68.3031\n",
      "Epoch 37/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 67.5905 - val_loss: 68.5686\n",
      "Epoch 38/200\n",
      "1782/1782 [==============================] - 0s 88us/sample - loss: 67.5570 - val_loss: 68.6663\n",
      "Epoch 39/200\n",
      "1782/1782 [==============================] - 0s 98us/sample - loss: 67.5860 - val_loss: 68.2390\n",
      "Epoch 40/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 67.5611 - val_loss: 68.7179\n",
      "Epoch 41/200\n",
      "1782/1782 [==============================] - 0s 85us/sample - loss: 67.5374 - val_loss: 68.1423\n",
      "Epoch 42/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 67.4693 - val_loss: 68.1854\n",
      "Epoch 43/200\n",
      "1782/1782 [==============================] - 0s 79us/sample - loss: 67.4323 - val_loss: 68.8594\n",
      "Epoch 44/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 67.5024 - val_loss: 68.3206\n",
      "Epoch 45/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 67.4714 - val_loss: 68.5777\n",
      "Epoch 46/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 67.3906 - val_loss: 68.4834\n",
      "Epoch 47/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 67.3855 - val_loss: 68.6400\n",
      "Epoch 48/200\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 67.3493 - val_loss: 68.4869\n",
      "Epoch 49/200\n",
      "1782/1782 [==============================] - 0s 111us/sample - loss: 67.3142 - val_loss: 68.4935\n",
      "Epoch 50/200\n",
      "1782/1782 [==============================] - 0s 160us/sample - loss: 67.2834 - val_loss: 68.5658\n",
      "Epoch 51/200\n",
      "1782/1782 [==============================] - 0s 106us/sample - loss: 67.3073 - val_loss: 68.5802\n",
      "Epoch 52/200\n",
      "1782/1782 [==============================] - 0s 94us/sample - loss: 67.2495 - val_loss: 68.3241\n",
      "Epoch 53/200\n",
      "1782/1782 [==============================] - 0s 87us/sample - loss: 67.2599 - val_loss: 68.5703\n",
      "Epoch 54/200\n",
      "1782/1782 [==============================] - 0s 83us/sample - loss: 67.2758 - val_loss: 68.8671\n",
      "Epoch 55/200\n",
      "1782/1782 [==============================] - 0s 82us/sample - loss: 67.2229 - val_loss: 68.1663\n",
      "Epoch 56/200\n",
      "1782/1782 [==============================] - 0s 83us/sample - loss: 67.2102 - val_loss: 68.2601\n",
      "Epoch 57/200\n",
      "1782/1782 [==============================] - 0s 81us/sample - loss: 67.1920 - val_loss: 68.7477\n",
      "Epoch 58/200\n",
      "1782/1782 [==============================] - 0s 79us/sample - loss: 67.1643 - val_loss: 68.2204\n",
      "Epoch 59/200\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 67.2619 - val_loss: 68.3899\n",
      "Epoch 60/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 67.1226 - val_loss: 68.4305\n",
      "Epoch 61/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 67.1244 - val_loss: 68.5665\n",
      "Epoch 62/200\n",
      "1782/1782 [==============================] - 0s 79us/sample - loss: 67.1058 - val_loss: 68.5378\n",
      "Epoch 63/200\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 67.0866 - val_loss: 68.8010\n",
      "Epoch 64/200\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 67.1359 - val_loss: 68.4891\n",
      "Epoch 65/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 67.0738 - val_loss: 68.4380\n",
      "Epoch 66/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 67.0680 - val_loss: 68.2137\n",
      "Epoch 67/200\n",
      "1782/1782 [==============================] - 0s 79us/sample - loss: 67.0375 - val_loss: 68.1952\n",
      "Epoch 68/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 67.0575 - val_loss: 68.3471\n",
      "Epoch 69/200\n",
      "1782/1782 [==============================] - 0s 122us/sample - loss: 66.9781 - val_loss: 68.5633\n",
      "Epoch 70/200\n",
      "1782/1782 [==============================] - 0s 90us/sample - loss: 66.9343 - val_loss: 68.5444\n",
      "Epoch 71/200\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 67.0381 - val_loss: 68.4035\n",
      "Epoch 72/200\n",
      "1782/1782 [==============================] - 0s 84us/sample - loss: 66.9767 - val_loss: 68.3711\n",
      "Epoch 73/200\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 67.0005 - val_loss: 68.6343\n",
      "Epoch 74/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 66.9330 - val_loss: 68.8873\n",
      "Epoch 75/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782/1782 [==============================] - 0s 75us/sample - loss: 66.8774 - val_loss: 68.5084\n",
      "Epoch 76/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.9481 - val_loss: 68.3563\n",
      "Epoch 77/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.9166 - val_loss: 68.5806\n",
      "Epoch 78/200\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 66.8453 - val_loss: 68.6957\n",
      "Epoch 79/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 66.8865 - val_loss: 68.7604\n",
      "Epoch 80/200\n",
      "1782/1782 [==============================] - ETA: 0s - loss: 64.36 - 0s 71us/sample - loss: 66.8300 - val_loss: 68.3944\n",
      "Epoch 81/200\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 66.8102 - val_loss: 68.1983\n",
      "Epoch 82/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 66.9211 - val_loss: 68.3261\n",
      "Epoch 83/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 66.7872 - val_loss: 68.4633\n",
      "Epoch 84/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 66.8041 - val_loss: 68.6224\n",
      "Epoch 85/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 66.7816 - val_loss: 68.3517\n",
      "Epoch 86/200\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 66.8115 - val_loss: 68.6436\n",
      "Epoch 87/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.7417 - val_loss: 68.3836\n",
      "Epoch 88/200\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 66.6821 - val_loss: 68.6551\n",
      "Epoch 89/200\n",
      "1782/1782 [==============================] - 0s 85us/sample - loss: 66.7329 - val_loss: 68.0975\n",
      "Epoch 90/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 66.7194 - val_loss: 68.7354\n",
      "Epoch 91/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 66.7384 - val_loss: 68.4596\n",
      "Epoch 92/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 66.6795 - val_loss: 68.4836\n",
      "Epoch 93/200\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 66.6637 - val_loss: 69.0284\n",
      "Epoch 94/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.6536 - val_loss: 68.3999\n",
      "Epoch 95/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 66.7004 - val_loss: 68.4169\n",
      "Epoch 96/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 66.6096 - val_loss: 68.5355\n",
      "Epoch 97/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 66.5496 - val_loss: 68.5549\n",
      "Epoch 98/200\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 66.6467 - val_loss: 68.4638\n",
      "Epoch 99/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 66.6790 - val_loss: 68.5126\n",
      "Epoch 100/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.4920 - val_loss: 68.6039\n",
      "Epoch 101/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 66.6346 - val_loss: 68.6696\n",
      "Epoch 102/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.5368 - val_loss: 68.6054\n",
      "Epoch 103/200\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 66.5617 - val_loss: 69.0338\n",
      "Epoch 104/200\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 66.5159 - val_loss: 68.8016\n",
      "Epoch 105/200\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 66.5341 - val_loss: 68.6517\n",
      "Epoch 106/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 66.4587 - val_loss: 68.8234\n",
      "Epoch 107/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.3526 - val_loss: 68.9278\n",
      "Epoch 108/200\n",
      "1782/1782 [==============================] - 0s 68us/sample - loss: 66.4730 - val_loss: 69.0448\n",
      "Epoch 109/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 66.4818 - val_loss: 68.5261\n",
      "Epoch 110/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.4350 - val_loss: 68.6832\n",
      "Epoch 111/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 66.4317 - val_loss: 68.6921\n",
      "Epoch 112/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 66.3527 - val_loss: 68.5724\n",
      "Epoch 113/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 66.4008 - val_loss: 68.5520\n",
      "Epoch 114/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.3752 - val_loss: 68.7036\n",
      "Epoch 115/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.3524 - val_loss: 68.7523\n",
      "Epoch 116/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 66.3326 - val_loss: 68.8514\n",
      "Epoch 117/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.2529 - val_loss: 68.8462\n",
      "Epoch 118/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 66.3492 - val_loss: 68.7695\n",
      "Epoch 119/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 66.3079 - val_loss: 68.5638\n",
      "Epoch 120/200\n",
      "1782/1782 [==============================] - 0s 79us/sample - loss: 66.2549 - val_loss: 68.9683\n",
      "Epoch 121/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 66.1818 - val_loss: 69.1013\n",
      "Epoch 122/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 66.3443 - val_loss: 69.3246\n",
      "Epoch 123/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 66.1776 - val_loss: 68.7532\n",
      "Epoch 124/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 66.1720 - val_loss: 68.9019\n",
      "Epoch 125/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 66.1354 - val_loss: 69.3178\n",
      "Epoch 126/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 66.2324 - val_loss: 69.0616\n",
      "Epoch 127/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 66.1942 - val_loss: 69.1475\n",
      "Epoch 128/200\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 66.1367 - val_loss: 68.8666\n",
      "Epoch 129/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.1381 - val_loss: 68.9839\n",
      "Epoch 130/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 66.0631 - val_loss: 69.3418\n",
      "Epoch 131/200\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 66.0531 - val_loss: 69.2660\n",
      "Epoch 132/200\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 66.1078 - val_loss: 68.8882\n",
      "Epoch 133/200\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 66.1013 - val_loss: 68.9986\n",
      "Epoch 134/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 66.0175 - val_loss: 69.0141\n",
      "Epoch 135/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 66.0879 - val_loss: 68.7560\n",
      "Epoch 136/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 66.0984 - val_loss: 69.1313\n",
      "Epoch 137/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.9771 - val_loss: 69.1162\n",
      "Epoch 138/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 66.0039 - val_loss: 68.7806\n",
      "Epoch 139/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.9877 - val_loss: 69.0691\n",
      "Epoch 140/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.9438 - val_loss: 69.1615\n",
      "Epoch 141/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 66.0011 - val_loss: 69.0537\n",
      "Epoch 142/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 65.9152 - val_loss: 69.2182\n",
      "Epoch 143/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.9352 - val_loss: 68.8047\n",
      "Epoch 144/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.9234 - val_loss: 69.0519\n",
      "Epoch 145/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.9821 - val_loss: 69.0637\n",
      "Epoch 146/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.9293 - val_loss: 69.0847\n",
      "Epoch 147/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.8203 - val_loss: 69.4932\n",
      "Epoch 148/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.8738 - val_loss: 69.5303\n",
      "Epoch 149/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.8924 - val_loss: 69.2487\n",
      "Epoch 150/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.8606 - val_loss: 69.2226\n",
      "Epoch 151/200\n",
      "1782/1782 [==============================] - 0s 79us/sample - loss: 65.8738 - val_loss: 69.3038\n",
      "Epoch 152/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 65.7893 - val_loss: 69.0350\n",
      "Epoch 153/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.8767 - val_loss: 69.1105\n",
      "Epoch 154/200\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 65.7195 - val_loss: 69.2728\n",
      "Epoch 155/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.8058 - val_loss: 68.9622\n",
      "Epoch 156/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 65.7253 - val_loss: 69.1940\n",
      "Epoch 157/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.7575 - val_loss: 68.9379\n",
      "Epoch 158/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.7064 - val_loss: 68.7757\n",
      "Epoch 159/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.7467 - val_loss: 69.1400\n",
      "Epoch 160/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.7371 - val_loss: 69.1740\n",
      "Epoch 161/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.7040 - val_loss: 69.1226\n",
      "Epoch 162/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.6873 - val_loss: 68.9446\n",
      "Epoch 163/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.7478 - val_loss: 69.6946\n",
      "Epoch 164/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.6471 - val_loss: 69.6674\n",
      "Epoch 165/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 65.7370 - val_loss: 69.2770\n",
      "Epoch 166/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 65.6788 - val_loss: 69.2476\n",
      "Epoch 167/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.6842 - val_loss: 69.1783\n",
      "Epoch 168/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 65.6179 - val_loss: 69.6316\n",
      "Epoch 169/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.6117 - val_loss: 69.2334\n",
      "Epoch 170/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.5748 - val_loss: 69.3445\n",
      "Epoch 171/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 65.5265 - val_loss: 69.3194\n",
      "Epoch 172/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.5836 - val_loss: 69.0975\n",
      "Epoch 173/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.5398 - val_loss: 69.5567\n",
      "Epoch 174/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.5666 - val_loss: 69.4921\n",
      "Epoch 175/200\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 65.5106 - val_loss: 69.2066\n",
      "Epoch 176/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.4249 - val_loss: 68.9731\n",
      "Epoch 177/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.5527 - val_loss: 69.2510\n",
      "Epoch 178/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.3945 - val_loss: 69.3523\n",
      "Epoch 179/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 65.4089 - val_loss: 68.8234\n",
      "Epoch 180/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.4464 - val_loss: 69.3336\n",
      "Epoch 181/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.3995 - val_loss: 69.5956\n",
      "Epoch 182/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.4335 - val_loss: 69.3889\n",
      "Epoch 183/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.3990 - val_loss: 68.9807\n",
      "Epoch 184/200\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 65.2863 - val_loss: 69.4956\n",
      "Epoch 185/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.3760 - val_loss: 69.4365\n",
      "Epoch 186/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.3322 - val_loss: 69.2529\n",
      "Epoch 187/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 65.3393 - val_loss: 69.6396\n",
      "Epoch 188/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 65.2853 - val_loss: 69.5155\n",
      "Epoch 189/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 65.3339 - val_loss: 69.3074\n",
      "Epoch 190/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.2407 - val_loss: 69.3712\n",
      "Epoch 191/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 65.2430 - val_loss: 69.3481\n",
      "Epoch 192/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.2879 - val_loss: 69.3129\n",
      "Epoch 193/200\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 65.3662 - val_loss: 69.3133\n",
      "Epoch 194/200\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 65.2988 - val_loss: 69.3979\n",
      "Epoch 195/200\n",
      "1782/1782 [==============================] - 0s 76us/sample - loss: 65.2197 - val_loss: 69.3077\n",
      "Epoch 196/200\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 65.2152 - val_loss: 69.3959\n",
      "Epoch 197/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.0529 - val_loss: 70.0783\n",
      "Epoch 198/200\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 65.2280 - val_loss: 69.2480\n",
      "Epoch 199/200\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 65.1946 - val_loss: 69.7090\n",
      "Epoch 200/200\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 65.1521 - val_loss: 69.5200\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=keras.optimizers.SGD(lr=1e-3))\n",
    "history = model.fit(X_train, y_train, epochs=200, validation_data=(X_valid, y_valid), callbacks=[checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 80)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18555), started 1 day, 19:41:01 ago. (Use '!kill 18555' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-701c00b8c6a145be\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-701c00b8c6a145be\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./my_logs --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=271 ...\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 303us/sample - loss: 14.1005 - val_loss: 13.7530\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 14.0413 - val_loss: 13.6951\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.9822 - val_loss: 13.6378\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.9235 - val_loss: 13.5813\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 13.8657 - val_loss: 13.5245\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.8072 - val_loss: 13.4678\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.7489 - val_loss: 13.4114\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.6907 - val_loss: 13.3552\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.6330 - val_loss: 13.2995\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.5757 - val_loss: 13.2441\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.5193 - val_loss: 13.1893\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.4633 - val_loss: 13.1341\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.4076 - val_loss: 13.0803\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.3534 - val_loss: 13.0262\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.2989 - val_loss: 12.9730\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.2449 - val_loss: 12.9198\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.1911 - val_loss: 12.8668\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.1376 - val_loss: 12.8135\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 13.0841 - val_loss: 12.7617\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.0316 - val_loss: 12.7096\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.9790 - val_loss: 12.6574\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.9266 - val_loss: 12.6055\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.8744 - val_loss: 12.5538\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.8224 - val_loss: 12.5026\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.7707 - val_loss: 12.4516\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.7191 - val_loss: 12.4005\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.6679 - val_loss: 12.3511\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.6178 - val_loss: 12.3021\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.5681 - val_loss: 12.2523\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.5181 - val_loss: 12.2031\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.4685 - val_loss: 12.1548\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.4194 - val_loss: 12.1078\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.3717 - val_loss: 12.0611\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 12.3241 - val_loss: 12.0154\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.2772 - val_loss: 11.9699\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.2304 - val_loss: 11.9252\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.1850 - val_loss: 11.8804\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.1393 - val_loss: 11.8365\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.0943 - val_loss: 11.7934\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.0499 - val_loss: 11.7502\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 12.0057 - val_loss: 11.7069\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.9615 - val_loss: 11.6640\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.9176 - val_loss: 11.6220\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.8746 - val_loss: 11.5798\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.8318 - val_loss: 11.5391\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.7901 - val_loss: 11.4987\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.7485 - val_loss: 11.4583\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.7068 - val_loss: 11.4186\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.6659 - val_loss: 11.3783\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.6247 - val_loss: 11.3384\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.5844 - val_loss: 11.2999\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.5448 - val_loss: 11.2611\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.5048 - val_loss: 11.2222\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.4653 - val_loss: 11.1835\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.4257 - val_loss: 11.1463\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.3870 - val_loss: 11.1090\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.3485 - val_loss: 11.0716\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.3098 - val_loss: 11.0343\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.2719 - val_loss: 10.9974\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.2336 - val_loss: 10.9601\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 11.1954 - val_loss: 10.9232\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.1572 - val_loss: 10.8871\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.1200 - val_loss: 10.8503\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.0824 - val_loss: 10.8142\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.0451 - val_loss: 10.7788\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.0086 - val_loss: 10.7434\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.9716 - val_loss: 10.7076\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.9349 - val_loss: 10.6728\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.8992 - val_loss: 10.6384\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.8635 - val_loss: 10.6044\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.8283 - val_loss: 10.5710\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.7930 - val_loss: 10.5378\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.7585 - val_loss: 10.5052\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.7241 - val_loss: 10.4723\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.6904 - val_loss: 10.4405\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.6567 - val_loss: 10.4092\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.6238 - val_loss: 10.3774\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.5904 - val_loss: 10.3462\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.5572 - val_loss: 10.3155\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.5248 - val_loss: 10.2843\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4920 - val_loss: 10.2539\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.4597 - val_loss: 10.2239\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.4279 - val_loss: 10.1947\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.3965 - val_loss: 10.1653\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.3650 - val_loss: 10.1364\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.3338 - val_loss: 10.1072\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.3029 - val_loss: 10.0787\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.2721 - val_loss: 10.0498\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.2411 - val_loss: 10.0218\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.2113 - val_loss: 9.9933\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.1808 - val_loss: 9.9657\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.1514 - val_loss: 9.9378\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.1218 - val_loss: 9.9101\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.0924 - val_loss: 9.8822\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.0626 - val_loss: 9.8538\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.0329 - val_loss: 9.8265\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.0043 - val_loss: 9.7990\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.9754 - val_loss: 9.7716\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.9466 - val_loss: 9.7457\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.9189 - val_loss: 9.7187\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.8902 - val_loss: 9.6921\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.8620 - val_loss: 9.6660\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8342 - val_loss: 9.6393\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.8062 - val_loss: 9.6135\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.7793 - val_loss: 9.5877\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.7524 - val_loss: 9.5630\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.7265 - val_loss: 9.5375\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.7003 - val_loss: 9.5130\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.6747 - val_loss: 9.4888\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.6492 - val_loss: 9.4640\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.6236 - val_loss: 9.4400\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.5981 - val_loss: 9.4159\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.5731 - val_loss: 9.3920\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.5480 - val_loss: 9.3692\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.5248 - val_loss: 9.3451\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.5002 - val_loss: 9.3221\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.4766 - val_loss: 9.2992\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.4531 - val_loss: 9.2765\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.4299 - val_loss: 9.2541\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.4071 - val_loss: 9.2315\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.3841 - val_loss: 9.2092\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.3612 - val_loss: 9.1870\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.3383 - val_loss: 9.1656\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.3164 - val_loss: 9.1436\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.2941 - val_loss: 9.1223\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.2725 - val_loss: 9.1010\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.2504 - val_loss: 9.0796\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 53us/sample - loss: 9.2287 - val_loss: 9.0596\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.2085 - val_loss: 9.0388\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.1875 - val_loss: 9.0189\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.1672 - val_loss: 8.9988\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.1473 - val_loss: 8.9784\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.1268 - val_loss: 8.9587\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.1067 - val_loss: 8.9395\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0871 - val_loss: 8.9197\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.0672 - val_loss: 8.9005\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.0477 - val_loss: 8.8806\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.0277 - val_loss: 8.8611\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.0079 - val_loss: 8.8417\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.9886 - val_loss: 8.8224\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9690 - val_loss: 8.8038\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.9506 - val_loss: 8.7851\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9319 - val_loss: 8.7670\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.9135 - val_loss: 8.7488\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.8948 - val_loss: 8.7311\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8770 - val_loss: 8.7131\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.8589 - val_loss: 8.6951\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.8409 - val_loss: 8.6776\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.8233 - val_loss: 8.6602\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8059 - val_loss: 8.6427\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7884 - val_loss: 8.6255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.7711 - val_loss: 8.6084\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.7542 - val_loss: 8.5915\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.7373 - val_loss: 8.5748\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.7208 - val_loss: 8.5583\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.7048 - val_loss: 8.5423\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.6892 - val_loss: 8.5255\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.6729 - val_loss: 8.5094\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6570 - val_loss: 8.4934\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.6413 - val_loss: 8.4778\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.6256 - val_loss: 8.4622\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.6098 - val_loss: 8.4458\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.5938 - val_loss: 8.4306\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.5787 - val_loss: 8.4152\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.5634 - val_loss: 8.4007\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.5493 - val_loss: 8.3863\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.5352 - val_loss: 8.3718\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.5210 - val_loss: 8.3568\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.5066 - val_loss: 8.3418\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.4920 - val_loss: 8.3276\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.4783 - val_loss: 8.3133\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.4643 - val_loss: 8.2993\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.4511 - val_loss: 8.2854\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.4377 - val_loss: 8.2715\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4240 - val_loss: 8.2572\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.4102 - val_loss: 8.2441\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.3977 - val_loss: 8.2311\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3850 - val_loss: 8.2184\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.3724 - val_loss: 8.2052\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.3595 - val_loss: 8.1924\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.3468 - val_loss: 8.1793\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.3339 - val_loss: 8.1667\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.3215 - val_loss: 8.1543\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.3095 - val_loss: 8.1422\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2979 - val_loss: 8.1301\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.2861 - val_loss: 8.1181\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.2746 - val_loss: 8.1064\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2634 - val_loss: 8.0947\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2522 - val_loss: 8.0830\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.2412 - val_loss: 8.0716\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2303 - val_loss: 8.0603\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.2193 - val_loss: 8.0492\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2083 - val_loss: 8.0383\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1974 - val_loss: 8.0272\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.1865 - val_loss: 8.0159\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.1757 - val_loss: 8.0056\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.1657 - val_loss: 7.9951\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1551 - val_loss: 7.9840\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.1443 - val_loss: 7.9737\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.1340 - val_loss: 7.9631\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.1238 - val_loss: 7.9524\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.1132 - val_loss: 7.9419\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.1028 - val_loss: 7.9320\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.0930 - val_loss: 7.9219\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.0831 - val_loss: 7.9123\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.0736 - val_loss: 7.9029\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.0641 - val_loss: 7.8933\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.0547 - val_loss: 7.8839\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0454 - val_loss: 7.8752\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.0365 - val_loss: 7.8664\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.0276 - val_loss: 7.8570\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.0186 - val_loss: 7.8478\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.0094 - val_loss: 7.8387\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.0007 - val_loss: 7.8294\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.9916 - val_loss: 7.8197\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.9825 - val_loss: 7.8103\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.9734 - val_loss: 7.8008\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.9644 - val_loss: 7.7915\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.9557 - val_loss: 7.7829\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.9476 - val_loss: 7.7740\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9390 - val_loss: 7.7658\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.9311 - val_loss: 7.7574\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.9232 - val_loss: 7.7492\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.9155 - val_loss: 7.7410\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.9077 - val_loss: 7.7324\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.8995 - val_loss: 7.7239\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8915 - val_loss: 7.7157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.8838 - val_loss: 7.7079\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.8765 - val_loss: 7.6994\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.8687 - val_loss: 7.6916\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.8613 - val_loss: 7.6839\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.8539 - val_loss: 7.6764\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.8469 - val_loss: 7.6687\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.8394 - val_loss: 7.6614\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.8324 - val_loss: 7.6542\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.8255 - val_loss: 7.6473\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.8186 - val_loss: 7.6398\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.8114 - val_loss: 7.6321\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.8042 - val_loss: 7.6252\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.7976 - val_loss: 7.6179\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.7907 - val_loss: 7.6108\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.7842 - val_loss: 7.6042\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7782 - val_loss: 7.5972\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.7717 - val_loss: 7.5902\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.7652 - val_loss: 7.5835\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.7590 - val_loss: 7.5770\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.7528 - val_loss: 7.5702\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.7462 - val_loss: 7.5636\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.7401 - val_loss: 7.5571\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.7339 - val_loss: 7.5508\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.7280 - val_loss: 7.5444\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.7219 - val_loss: 7.5383\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7162 - val_loss: 7.5319\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.7101 - val_loss: 7.5260\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.7043 - val_loss: 7.5204\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.6988 - val_loss: 7.5148\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6934 - val_loss: 7.5091\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6878 - val_loss: 7.5035\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.6824 - val_loss: 7.4979\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6769 - val_loss: 7.4925\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6715 - val_loss: 7.4873\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.6663 - val_loss: 7.4818\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.6607 - val_loss: 7.4766\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6557 - val_loss: 7.4718\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.6510 - val_loss: 7.4667\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6460 - val_loss: 7.4619\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6414 - val_loss: 7.4571\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.6367 - val_loss: 7.4519\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6317 - val_loss: 7.4469\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6270 - val_loss: 7.4419\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6222 - val_loss: 7.4373\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.6178 - val_loss: 7.4328\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.6134 - val_loss: 7.4286\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.6090 - val_loss: 7.4236\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.6042 - val_loss: 7.4191\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.5999 - val_loss: 7.4148\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5956 - val_loss: 7.4105\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5914 - val_loss: 7.4062\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5872 - val_loss: 7.4017\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.5828 - val_loss: 7.3975\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5787 - val_loss: 7.3934\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.5747 - val_loss: 7.3890\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.5706 - val_loss: 7.3846\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5666 - val_loss: 7.3807\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.5628 - val_loss: 7.3763\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5588 - val_loss: 7.3724\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.5552 - val_loss: 7.3685\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.5515 - val_loss: 7.3645\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.5478 - val_loss: 7.3604\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5441 - val_loss: 7.3563\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5401 - val_loss: 7.3522\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5363 - val_loss: 7.3480\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5325 - val_loss: 7.3443\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.5290 - val_loss: 7.3407\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.5256 - val_loss: 7.3369\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5222 - val_loss: 7.3332\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.5187 - val_loss: 7.3297\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5155 - val_loss: 7.3260\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.5119 - val_loss: 7.3225\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5086 - val_loss: 7.3188\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.5051 - val_loss: 7.3154\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5018 - val_loss: 7.3119\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4984 - val_loss: 7.3081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4950 - val_loss: 7.3045\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.4916 - val_loss: 7.3010\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4882 - val_loss: 7.2972\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4847 - val_loss: 7.2939\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4816 - val_loss: 7.2904\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.4782 - val_loss: 7.2870\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4752 - val_loss: 7.2836\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.4721 - val_loss: 7.2802\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.4690 - val_loss: 7.2768\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4660 - val_loss: 7.2736\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4629 - val_loss: 7.2702\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4598 - val_loss: 7.2669\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.4568 - val_loss: 7.2637\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.4540 - val_loss: 7.2606\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.4511 - val_loss: 7.2572\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.4481 - val_loss: 7.2540\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4452 - val_loss: 7.2509\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4423 - val_loss: 7.2479\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.4395 - val_loss: 7.2447\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4365 - val_loss: 7.2418\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.4337 - val_loss: 7.2383\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4304 - val_loss: 7.2352\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.4274 - val_loss: 7.2323\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4246 - val_loss: 7.2291\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.4217 - val_loss: 7.2261\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4189 - val_loss: 7.2230\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4160 - val_loss: 7.2197\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4130 - val_loss: 7.2167\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.4102 - val_loss: 7.2136\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4073 - val_loss: 7.2105\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.4046 - val_loss: 7.2073\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4018 - val_loss: 7.2042\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.3991 - val_loss: 7.2012\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3964 - val_loss: 7.1985\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3940 - val_loss: 7.1953\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3912 - val_loss: 7.1923\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3886 - val_loss: 7.1892\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3860 - val_loss: 7.1865\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3836 - val_loss: 7.1835\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3810 - val_loss: 7.1808\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.3786 - val_loss: 7.1780\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3761 - val_loss: 7.1756\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3738 - val_loss: 7.1730\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3714 - val_loss: 7.1706\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3692 - val_loss: 7.1677\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3667 - val_loss: 7.1653\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3644 - val_loss: 7.1628\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3621 - val_loss: 7.1602\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3598 - val_loss: 7.1581\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3578 - val_loss: 7.1559\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3557 - val_loss: 7.1535\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.3536 - val_loss: 7.1510\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3513 - val_loss: 7.1486\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.3491 - val_loss: 7.1465\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3472 - val_loss: 7.1441\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3450 - val_loss: 7.1418\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3428 - val_loss: 7.1394\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3404 - val_loss: 7.1368\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3382 - val_loss: 7.1348\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3363 - val_loss: 7.1328\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3345 - val_loss: 7.1306\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3324 - val_loss: 7.1286\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3304 - val_loss: 7.1263\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3283 - val_loss: 7.1243\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3265 - val_loss: 7.1221\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3244 - val_loss: 7.1199\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3225 - val_loss: 7.1177\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3204 - val_loss: 7.1157\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3185 - val_loss: 7.1137\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3167 - val_loss: 7.1114\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3145 - val_loss: 7.1094\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3127 - val_loss: 7.1074\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3109 - val_loss: 7.1053\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3091 - val_loss: 7.1034\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3074 - val_loss: 7.1015\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3055 - val_loss: 7.0996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3038 - val_loss: 7.0976\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3020 - val_loss: 7.0960\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3004 - val_loss: 7.0941\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2987 - val_loss: 7.0922\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2969 - val_loss: 7.0905\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2952 - val_loss: 7.0886\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2935 - val_loss: 7.0869\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2919 - val_loss: 7.0853\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2904 - val_loss: 7.0835\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2887 - val_loss: 7.0817\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2872 - val_loss: 7.0802\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2856 - val_loss: 7.0784\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2840 - val_loss: 7.0767\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2826 - val_loss: 7.0752\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2812 - val_loss: 7.0739\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2799 - val_loss: 7.0723\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2783 - val_loss: 7.0709\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2770 - val_loss: 7.0696\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2753 - val_loss: 7.0682\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2741 - val_loss: 7.0668\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2726 - val_loss: 7.0655\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2711 - val_loss: 7.0643\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2699 - val_loss: 7.0630\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2685 - val_loss: 7.0614\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2670 - val_loss: 7.0600\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2657 - val_loss: 7.0588\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2643 - val_loss: 7.0575\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2631 - val_loss: 7.0563\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2617 - val_loss: 7.0554\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2607 - val_loss: 7.0543\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2594 - val_loss: 7.0532\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.2581 - val_loss: 7.0520\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2569 - val_loss: 7.0507\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2556 - val_loss: 7.0497\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2546 - val_loss: 7.0486\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2534 - val_loss: 7.0476\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2525 - val_loss: 7.0464\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2514 - val_loss: 7.0453\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2503 - val_loss: 7.0445\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2492 - val_loss: 7.0432\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2480 - val_loss: 7.0420\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2468 - val_loss: 7.0406\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2457 - val_loss: 7.0394\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2446 - val_loss: 7.0384\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2436 - val_loss: 7.0372\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2423 - val_loss: 7.0361\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2413 - val_loss: 7.0348\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2402 - val_loss: 7.0339\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2391 - val_loss: 7.0329\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.2381 - val_loss: 7.0320\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2371 - val_loss: 7.0310\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2359 - val_loss: 7.0301\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2348 - val_loss: 7.0293\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2338 - val_loss: 7.0283\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2327 - val_loss: 7.0273\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2317 - val_loss: 7.0261\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2305 - val_loss: 7.0253\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2294 - val_loss: 7.0244\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2285 - val_loss: 7.0235\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2275 - val_loss: 7.0224\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2264 - val_loss: 7.0215\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2255 - val_loss: 7.0207\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2244 - val_loss: 7.0200\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2235 - val_loss: 7.0192\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2226 - val_loss: 7.0184\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2218 - val_loss: 7.0176\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2209 - val_loss: 7.0167\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 7.2199 - val_loss: 7.0158\n",
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.2188 - val_loss: 7.0149\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2180 - val_loss: 7.0142\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2171 - val_loss: 7.0134\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2162 - val_loss: 7.0126\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.2154 - val_loss: 7.0119\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 7.2147 - val_loss: 7.0112\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.2139 - val_loss: 7.0104\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2131 - val_loss: 7.0099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2124 - val_loss: 7.0090\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2116 - val_loss: 7.0085\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2109 - val_loss: 7.0079\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2101 - val_loss: 7.0074\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2095 - val_loss: 7.0069\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2088 - val_loss: 7.0063\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2080 - val_loss: 7.0057\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2072 - val_loss: 7.0050\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2064 - val_loss: 7.0042\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2057 - val_loss: 7.0037\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2049 - val_loss: 7.0031\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2042 - val_loss: 7.0026\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2035 - val_loss: 7.0018\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2027 - val_loss: 7.0013\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2019 - val_loss: 7.0006\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2013 - val_loss: 6.9999\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2005 - val_loss: 6.9993\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2000 - val_loss: 6.9986\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.1993 - val_loss: 6.9980\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1986 - val_loss: 6.9976\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 57us/sample - loss: 7.1981 - val_loss: 6.9968\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1974 - val_loss: 6.9961\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1966 - val_loss: 6.9954\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1959 - val_loss: 6.9947\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1953 - val_loss: 6.9942\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1948 - val_loss: 6.9936\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1942 - val_loss: 6.9929\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1936 - val_loss: 6.9924\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1930 - val_loss: 6.9918\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1924 - val_loss: 6.9913\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1918 - val_loss: 6.9909\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1913 - val_loss: 6.9903\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1908 - val_loss: 6.9899\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1903 - val_loss: 6.9892\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1897 - val_loss: 6.9887\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1890 - val_loss: 6.9883\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1885 - val_loss: 6.9879\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1880 - val_loss: 6.9873\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1874 - val_loss: 6.9868\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1868 - val_loss: 6.9863\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1862 - val_loss: 6.9859\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1856 - val_loss: 6.9856\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1852 - val_loss: 6.9852\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1846 - val_loss: 6.9848\n",
      "Epoch 500/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1842 - val_loss: 6.9843\n",
      "594/594 [==============================] - 0s 36us/sample - loss: 7.0004\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=271, total=  43.4s\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=271 ...\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   43.4s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 294us/sample - loss: 14.0414 - val_loss: 13.7493\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.9853 - val_loss: 13.6913\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.9288 - val_loss: 13.6336\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.8726 - val_loss: 13.5763\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.8166 - val_loss: 13.5192\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 13.7607 - val_loss: 13.4621\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.7052 - val_loss: 13.4057\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.6501 - val_loss: 13.3496\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.5953 - val_loss: 13.2939\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.5410 - val_loss: 13.2387\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.4876 - val_loss: 13.1840\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.4344 - val_loss: 13.1296\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.3820 - val_loss: 13.0762\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 13.3302 - val_loss: 13.0235\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.2792 - val_loss: 12.9705\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.2279 - val_loss: 12.9180\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.1771 - val_loss: 12.8660\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.1264 - val_loss: 12.8143\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.0760 - val_loss: 12.7631\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.0257 - val_loss: 12.7119\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.9756 - val_loss: 12.6607\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.9258 - val_loss: 12.6103\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.8760 - val_loss: 12.5612\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 12.8270 - val_loss: 12.5126\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.7790 - val_loss: 12.4637\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.7303 - val_loss: 12.4148\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.6820 - val_loss: 12.3667\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.6338 - val_loss: 12.3190\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.5860 - val_loss: 12.2727\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.5389 - val_loss: 12.2257\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.4920 - val_loss: 12.1797\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.4458 - val_loss: 12.1331\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.3990 - val_loss: 12.0869\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.3526 - val_loss: 12.0414\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 12.3069 - val_loss: 11.9952\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.2607 - val_loss: 11.9501\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.2153 - val_loss: 11.9049\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.1697 - val_loss: 11.8603\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.1247 - val_loss: 11.8155\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.0793 - val_loss: 11.7715\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.0348 - val_loss: 11.7271\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.9901 - val_loss: 11.6827\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.9456 - val_loss: 11.6389\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.9011 - val_loss: 11.5955\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 11.8565 - val_loss: 11.5526\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 11.8120 - val_loss: 11.5108\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.7683 - val_loss: 11.4686\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.7242 - val_loss: 11.4266\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 11.6804 - val_loss: 11.3846\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 11.6370 - val_loss: 11.3431\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.5940 - val_loss: 11.3020\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 114us/sample - loss: 11.5511 - val_loss: 11.2609\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.5087 - val_loss: 11.2210\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.4668 - val_loss: 11.1813\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.4243 - val_loss: 11.1424\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 11.3828 - val_loss: 11.1034\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 11.3410 - val_loss: 11.0647\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.2995 - val_loss: 11.0264\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.2586 - val_loss: 10.9880\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.2181 - val_loss: 10.9498\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.1783 - val_loss: 10.9118\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 11.1387 - val_loss: 10.8750\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.0999 - val_loss: 10.8375\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 11.0607 - val_loss: 10.8003\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 11.0217 - val_loss: 10.7634\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 10.9829 - val_loss: 10.7275\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 10.9451 - val_loss: 10.6923\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 10.9072 - val_loss: 10.6570\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 10.8698 - val_loss: 10.6216\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.8319 - val_loss: 10.5862\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 10.7942 - val_loss: 10.5516\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 10.7568 - val_loss: 10.5173\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 10.7194 - val_loss: 10.4837\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 10.6818 - val_loss: 10.4505\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 10.6451 - val_loss: 10.4170\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 100us/sample - loss: 10.6078 - val_loss: 10.3835\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 10.5711 - val_loss: 10.3510\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.5352 - val_loss: 10.3182\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.4991 - val_loss: 10.2856\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4633 - val_loss: 10.2541\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 10.4289 - val_loss: 10.2220\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 10.3938 - val_loss: 10.1906\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 10.3598 - val_loss: 10.1588\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.3249 - val_loss: 10.1275\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.2908 - val_loss: 10.0969\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2568 - val_loss: 10.0674\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.2238 - val_loss: 10.0381\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.1905 - val_loss: 10.0088\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1574 - val_loss: 9.9798\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.1251 - val_loss: 9.9505\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 10.0923 - val_loss: 9.9209\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 10.0598 - val_loss: 9.8922\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 10.0283 - val_loss: 9.8634\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.9963 - val_loss: 9.8347\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.9646 - val_loss: 9.8067\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.9336 - val_loss: 9.7781\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.9022 - val_loss: 9.7498\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.8711 - val_loss: 9.7215\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8402 - val_loss: 9.6945\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.8100 - val_loss: 9.6675\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.7800 - val_loss: 9.6407\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.7503 - val_loss: 9.6141\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.7210 - val_loss: 9.5878\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6918 - val_loss: 9.5622\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.6633 - val_loss: 9.5367\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 9.6348 - val_loss: 9.5115\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 9.6068 - val_loss: 9.4863\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.5787 - val_loss: 9.4619\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.5516 - val_loss: 9.4372\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5243 - val_loss: 9.4126\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.4971 - val_loss: 9.3887\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.4702 - val_loss: 9.3650\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.4436 - val_loss: 9.3408\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.4175 - val_loss: 9.3175\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.3918 - val_loss: 9.2939\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3660 - val_loss: 9.2711\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3405 - val_loss: 9.2480\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.3148 - val_loss: 9.2255\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.2895 - val_loss: 9.2023\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.2641 - val_loss: 9.1793\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.2390 - val_loss: 9.1565\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2139 - val_loss: 9.1340\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.1892 - val_loss: 9.1115\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.1648 - val_loss: 9.0891\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.1399 - val_loss: 9.0666\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.1155 - val_loss: 9.0443\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0913 - val_loss: 9.0227\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.0677 - val_loss: 9.0005\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.0442 - val_loss: 8.9790\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0216 - val_loss: 8.9585\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.9997 - val_loss: 8.9389\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.9789 - val_loss: 8.9181\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9569 - val_loss: 8.8977\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9353 - val_loss: 8.8784\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9144 - val_loss: 8.8582\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.8927 - val_loss: 8.8392\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8719 - val_loss: 8.8194\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.8513 - val_loss: 8.8003\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 8.8306 - val_loss: 8.7816\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.8104 - val_loss: 8.7627\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.7897 - val_loss: 8.7435\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.7693 - val_loss: 8.7244\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 8.7487 - val_loss: 8.7054\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.7283 - val_loss: 8.6865\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7079 - val_loss: 8.6677\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.6875 - val_loss: 8.6485\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.6667 - val_loss: 8.6289\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.6461 - val_loss: 8.6105\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6263 - val_loss: 8.5926\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6067 - val_loss: 8.5743\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5869 - val_loss: 8.5568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5679 - val_loss: 8.5388\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5485 - val_loss: 8.5216\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.5302 - val_loss: 8.5054\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.5124 - val_loss: 8.4884\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 8.4941 - val_loss: 8.4716\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.4759 - val_loss: 8.4550\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4577 - val_loss: 8.4396\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.4408 - val_loss: 8.4235\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4235 - val_loss: 8.4078\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.4066 - val_loss: 8.3924\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.3900 - val_loss: 8.3766\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.3729 - val_loss: 8.3618\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.3567 - val_loss: 8.3463\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3397 - val_loss: 8.3318\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.3237 - val_loss: 8.3174\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.3076 - val_loss: 8.3025\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.2913 - val_loss: 8.2877\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.2750 - val_loss: 8.2726\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.2587 - val_loss: 8.2585\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.2434 - val_loss: 8.2439\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.2276 - val_loss: 8.2295\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.2122 - val_loss: 8.2153\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.1968 - val_loss: 8.2012\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.1811 - val_loss: 8.1870\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.1658 - val_loss: 8.1736\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 8.1512 - val_loss: 8.1596\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.1358 - val_loss: 8.1460\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1209 - val_loss: 8.1323\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1059 - val_loss: 8.1184\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.0909 - val_loss: 8.1053\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.0767 - val_loss: 8.0916\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.0621 - val_loss: 8.0787\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.0481 - val_loss: 8.0655\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.0339 - val_loss: 8.0527\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.0199 - val_loss: 8.0397\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.0062 - val_loss: 8.0273\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9930 - val_loss: 8.0146\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.9794 - val_loss: 8.0025\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.9664 - val_loss: 7.9902\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.9533 - val_loss: 7.9779\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9405 - val_loss: 7.9659\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.9278 - val_loss: 7.9546\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9157 - val_loss: 7.9434\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.9040 - val_loss: 7.9320\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.8921 - val_loss: 7.9214\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.8808 - val_loss: 7.9105\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8691 - val_loss: 7.8992\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.8569 - val_loss: 7.8883\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.8453 - val_loss: 7.8771\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.8336 - val_loss: 7.8661\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.8219 - val_loss: 7.8553\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.8105 - val_loss: 7.8453\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.8002 - val_loss: 7.8349\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.7897 - val_loss: 7.8251\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.7797 - val_loss: 7.8154\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7698 - val_loss: 7.8051\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.7593 - val_loss: 7.7957\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.7499 - val_loss: 7.7869\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7409 - val_loss: 7.7776\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.7315 - val_loss: 7.7687\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.7226 - val_loss: 7.7597\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.7135 - val_loss: 7.7506\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.7044 - val_loss: 7.7416\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.6954 - val_loss: 7.7321\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.6861 - val_loss: 7.7228\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.6769 - val_loss: 7.7138\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 7.6679 - val_loss: 7.7056\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.6596 - val_loss: 7.6972\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6514 - val_loss: 7.6884\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6426 - val_loss: 7.6800\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6345 - val_loss: 7.6714\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.6259 - val_loss: 7.6633\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.6178 - val_loss: 7.6552\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.6099 - val_loss: 7.6474\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6021 - val_loss: 7.6391\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.5939 - val_loss: 7.6311\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.5859 - val_loss: 7.6235\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5783 - val_loss: 7.6154\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.5702 - val_loss: 7.6084\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.5629 - val_loss: 7.6011\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.5558 - val_loss: 7.5938\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.5482 - val_loss: 7.5863\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5406 - val_loss: 7.5788\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5330 - val_loss: 7.5717\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5259 - val_loss: 7.5649\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5188 - val_loss: 7.5576\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5113 - val_loss: 7.5507\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.5041 - val_loss: 7.5440\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.4970 - val_loss: 7.5376\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4901 - val_loss: 7.5313\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.4832 - val_loss: 7.5248\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4765 - val_loss: 7.5183\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.4693 - val_loss: 7.5123\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.4628 - val_loss: 7.5063\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.4564 - val_loss: 7.5000\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4496 - val_loss: 7.4944\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4433 - val_loss: 7.4885\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4370 - val_loss: 7.4829\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4308 - val_loss: 7.4772\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.4247 - val_loss: 7.4716\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4186 - val_loss: 7.4665\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.4131 - val_loss: 7.4609\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.4070 - val_loss: 7.4556\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.4011 - val_loss: 7.4510\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3958 - val_loss: 7.4458\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3901 - val_loss: 7.4412\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3849 - val_loss: 7.4362\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.3794 - val_loss: 7.4312\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.3741 - val_loss: 7.4262\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3685 - val_loss: 7.4214\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3633 - val_loss: 7.4168\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3581 - val_loss: 7.4122\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3531 - val_loss: 7.4076\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.3480 - val_loss: 7.4028\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.3428 - val_loss: 7.3982\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3379 - val_loss: 7.3936\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.3330 - val_loss: 7.3888\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.3279 - val_loss: 7.3840\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.3229 - val_loss: 7.3791\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3177 - val_loss: 7.3745\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3127 - val_loss: 7.3700\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3080 - val_loss: 7.3655\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3032 - val_loss: 7.3608\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2980 - val_loss: 7.3564\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2934 - val_loss: 7.3519\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.2886 - val_loss: 7.3472\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2835 - val_loss: 7.3429\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2789 - val_loss: 7.3383\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.504 - 0s 86us/sample - loss: 7.2739 - val_loss: 7.3335\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2690 - val_loss: 7.3291\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 7.2642 - val_loss: 7.3246\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.2594 - val_loss: 7.3204\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.2547 - val_loss: 7.3159\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2500 - val_loss: 7.3117\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2455 - val_loss: 7.3078\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.2414 - val_loss: 7.3038\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.2371 - val_loss: 7.2996\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.2324 - val_loss: 7.2951\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.2278 - val_loss: 7.2910\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 59us/sample - loss: 7.2232 - val_loss: 7.2874\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2194 - val_loss: 7.2832\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.2150 - val_loss: 7.2792\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2109 - val_loss: 7.2754\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2070 - val_loss: 7.2714\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2027 - val_loss: 7.2677\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1987 - val_loss: 7.2641\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1949 - val_loss: 7.2604\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1909 - val_loss: 7.2569\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1873 - val_loss: 7.2534\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1834 - val_loss: 7.2498\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1795 - val_loss: 7.2461\n",
      "Epoch 303/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1756 - val_loss: 7.2426\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1719 - val_loss: 7.2393\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1682 - val_loss: 7.2359\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1644 - val_loss: 7.2324\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1605 - val_loss: 7.2290\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1569 - val_loss: 7.2257\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1531 - val_loss: 7.2224\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1496 - val_loss: 7.2191\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1461 - val_loss: 7.2157\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.1427 - val_loss: 7.2122\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.1389 - val_loss: 7.2092\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.1357 - val_loss: 7.2060\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1324 - val_loss: 7.2026\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1290 - val_loss: 7.1998\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.1263 - val_loss: 7.1968\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.1231 - val_loss: 7.1937\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.1198 - val_loss: 7.1905\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.1166 - val_loss: 7.1875\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.1135 - val_loss: 7.1849\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.1107 - val_loss: 7.1819\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1077 - val_loss: 7.1791\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1048 - val_loss: 7.1764\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1018 - val_loss: 7.1735\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.0987 - val_loss: 7.1708\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.0957 - val_loss: 7.1679\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.0927 - val_loss: 7.1652\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 7.0899 - val_loss: 7.1625\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.0871 - val_loss: 7.1598\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.0841 - val_loss: 7.1571\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.0815 - val_loss: 7.1543\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.0785 - val_loss: 7.1517\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0760 - val_loss: 7.1490\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.0733 - val_loss: 7.1466\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.0706 - val_loss: 7.1441\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.0680 - val_loss: 7.1415\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0654 - val_loss: 7.1390\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0629 - val_loss: 7.1366\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.0605 - val_loss: 7.1343\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.0582 - val_loss: 7.1326\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.0563 - val_loss: 7.1303\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.0541 - val_loss: 7.1281\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.0517 - val_loss: 7.1258\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.0496 - val_loss: 7.1237\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.0476 - val_loss: 7.1217\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.0456 - val_loss: 7.1195\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.0436 - val_loss: 7.1174\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.0417 - val_loss: 7.1154\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0395 - val_loss: 7.1136\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.0376 - val_loss: 7.1119\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.0358 - val_loss: 7.1102\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.0341 - val_loss: 7.1083\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.0322 - val_loss: 7.1067\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.0306 - val_loss: 7.1049\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.0286 - val_loss: 7.1031\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.0267 - val_loss: 7.1015\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.0252 - val_loss: 7.0996\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.0233 - val_loss: 7.0979\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.0216 - val_loss: 7.0962\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0199 - val_loss: 7.0940\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.0180 - val_loss: 7.0927\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.0166 - val_loss: 7.0912\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.0149 - val_loss: 7.0896\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.0132 - val_loss: 7.0882\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.0117 - val_loss: 7.0869\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.0102 - val_loss: 7.0856\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.0087 - val_loss: 7.0841\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.0071 - val_loss: 7.0825\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0053 - val_loss: 7.0807\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.0038 - val_loss: 7.0793\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0021 - val_loss: 7.0780\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.0006 - val_loss: 7.0764\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.9989 - val_loss: 7.0748\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.9972 - val_loss: 7.0735\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.9959 - val_loss: 7.0725\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.9947 - val_loss: 7.0711\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.9932 - val_loss: 7.0696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.9917 - val_loss: 7.0679\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9901 - val_loss: 7.0665\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9885 - val_loss: 7.0652\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9872 - val_loss: 7.0635\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9857 - val_loss: 7.0621\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9844 - val_loss: 7.0608\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.9829 - val_loss: 7.0594\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9815 - val_loss: 7.0579\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9801 - val_loss: 7.0567\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9789 - val_loss: 7.0556\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9776 - val_loss: 7.0543\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9763 - val_loss: 7.0533\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.9751 - val_loss: 7.0519\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9737 - val_loss: 7.0507\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9722 - val_loss: 7.0496\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.9710 - val_loss: 7.0487\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.9699 - val_loss: 7.0475\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.9686 - val_loss: 7.0461\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9672 - val_loss: 7.0447\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.9657 - val_loss: 7.0437\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9645 - val_loss: 7.0423\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9632 - val_loss: 7.0414\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9618 - val_loss: 7.0403\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9607 - val_loss: 7.0394\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9595 - val_loss: 7.0383\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9584 - val_loss: 7.0370\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9570 - val_loss: 7.0362\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9559 - val_loss: 7.0350\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9547 - val_loss: 7.0340\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9536 - val_loss: 7.0332\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.9526 - val_loss: 7.0320\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9515 - val_loss: 7.0310\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9502 - val_loss: 7.0297\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.9490 - val_loss: 7.0287\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9479 - val_loss: 7.0280\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9470 - val_loss: 7.0272\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.9459 - val_loss: 7.0262\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.9448 - val_loss: 7.0253\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9438 - val_loss: 7.0242\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9428 - val_loss: 7.0233\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9417 - val_loss: 7.0225\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9407 - val_loss: 7.0218\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9397 - val_loss: 7.0210\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9386 - val_loss: 7.0201\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9377 - val_loss: 7.0193\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9369 - val_loss: 7.0186\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9358 - val_loss: 7.0181\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9349 - val_loss: 7.0174\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9342 - val_loss: 7.0170\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9335 - val_loss: 7.0163\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.9326 - val_loss: 7.0159\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9318 - val_loss: 7.0153\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9310 - val_loss: 7.0147\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9303 - val_loss: 7.0140\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.9298 - val_loss: 7.0134\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9289 - val_loss: 7.0127\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9281 - val_loss: 7.0119\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9272 - val_loss: 7.0113\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9264 - val_loss: 7.0107\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9257 - val_loss: 7.0102\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.9251 - val_loss: 7.0094\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9243 - val_loss: 7.0087\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.9239 - val_loss: 7.0080\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9231 - val_loss: 7.0073\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.9223 - val_loss: 7.0070\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9217 - val_loss: 7.0063\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.9210 - val_loss: 7.0060\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9204 - val_loss: 7.0055\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9196 - val_loss: 7.0051\n",
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.9188 - val_loss: 7.0044\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.9182 - val_loss: 7.0039\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9175 - val_loss: 7.0032\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9169 - val_loss: 7.0028\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9163 - val_loss: 7.0023\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9157 - val_loss: 7.0017\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9149 - val_loss: 7.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9143 - val_loss: 7.0008\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9137 - val_loss: 7.0002\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9131 - val_loss: 7.0000\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.9125 - val_loss: 6.9994\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 6.9118 - val_loss: 6.9989\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9111 - val_loss: 6.9987\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9106 - val_loss: 6.9981\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9101 - val_loss: 6.9975\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9094 - val_loss: 6.9971\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.9088 - val_loss: 6.9967\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.9083 - val_loss: 6.9962\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9078 - val_loss: 6.9958\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9072 - val_loss: 6.9953\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.9068 - val_loss: 6.9947\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9061 - val_loss: 6.9942\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9055 - val_loss: 6.9938\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9049 - val_loss: 6.9931\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9044 - val_loss: 6.9927\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9038 - val_loss: 6.9923\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9033 - val_loss: 6.9919\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9027 - val_loss: 6.9914\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9023 - val_loss: 6.9909\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9017 - val_loss: 6.9906\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9012 - val_loss: 6.9900\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9006 - val_loss: 6.9896\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9002 - val_loss: 6.9891\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8996 - val_loss: 6.9886\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8990 - val_loss: 6.9880\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8984 - val_loss: 6.9877\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.8979 - val_loss: 6.9871\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8974 - val_loss: 6.9867\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8972 - val_loss: 6.9862\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8967 - val_loss: 6.9856\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8963 - val_loss: 6.9853\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8957 - val_loss: 6.9847\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8951 - val_loss: 6.9845\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8945 - val_loss: 6.9842\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8941 - val_loss: 6.9838\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8934 - val_loss: 6.9835\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8930 - val_loss: 6.9833\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8925 - val_loss: 6.9829\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8920 - val_loss: 6.9825\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8915 - val_loss: 6.9822\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.8909 - val_loss: 6.9818\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8904 - val_loss: 6.9816\n",
      "Epoch 500/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8900 - val_loss: 6.9813\n",
      "594/594 [==============================] - 0s 34us/sample - loss: 7.5528\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=271, total=  46.9s\n",
      "[CV] learning_rate=0.001683454924600351, n_hidden=0, n_neurons=271 ...\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 279us/sample - loss: 13.9620 - val_loss: 13.7456\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.9044 - val_loss: 13.6880\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.8468 - val_loss: 13.6307\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.7894 - val_loss: 13.5735\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.7328 - val_loss: 13.5172\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.6766 - val_loss: 13.4609\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.6209 - val_loss: 13.4053\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.5655 - val_loss: 13.3502\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.5106 - val_loss: 13.2958\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.4562 - val_loss: 13.2416\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.4020 - val_loss: 13.1878\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.3488 - val_loss: 13.1349\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 13.2962 - val_loss: 13.0817\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.2434 - val_loss: 13.0294\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.1916 - val_loss: 12.9760\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.1391 - val_loss: 12.9234\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.0873 - val_loss: 12.8713\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.0357 - val_loss: 12.8200\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.9846 - val_loss: 12.7687\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.9338 - val_loss: 12.7176\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.8834 - val_loss: 12.6667\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.8337 - val_loss: 12.6162\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.7840 - val_loss: 12.5657\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.7349 - val_loss: 12.5172\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.6874 - val_loss: 12.4680\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.6388 - val_loss: 12.4197\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.5910 - val_loss: 12.3718\n",
      "Epoch 28/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.5441 - val_loss: 12.3252\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.4983 - val_loss: 12.2795\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.4517 - val_loss: 12.2330\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.4057 - val_loss: 12.1875\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.3605 - val_loss: 12.1416\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.3149 - val_loss: 12.0959\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.2696 - val_loss: 12.0516\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.2260 - val_loss: 12.0068\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.1816 - val_loss: 11.9629\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.1381 - val_loss: 11.9192\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.0947 - val_loss: 11.8763\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.0515 - val_loss: 11.8332\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.0082 - val_loss: 11.7910\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.9659 - val_loss: 11.7481\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.9232 - val_loss: 11.7066\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.8814 - val_loss: 11.6654\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.8394 - val_loss: 11.6240\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.7971 - val_loss: 11.5822\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.7552 - val_loss: 11.5414\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.7139 - val_loss: 11.5000\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.6720 - val_loss: 11.4594\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.6306 - val_loss: 11.4197\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.5900 - val_loss: 11.3795\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 11.5488 - val_loss: 11.3403\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.5084 - val_loss: 11.3007\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.4678 - val_loss: 11.2622\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.4279 - val_loss: 11.2235\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.3879 - val_loss: 11.1849\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.3490 - val_loss: 11.1464\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.3098 - val_loss: 11.1083\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.2710 - val_loss: 11.0703\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.2324 - val_loss: 11.0327\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.1942 - val_loss: 10.9956\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.1571 - val_loss: 10.9597\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.1213 - val_loss: 10.9250\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.0861 - val_loss: 10.8903\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.0517 - val_loss: 10.8556\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.0169 - val_loss: 10.8209\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.9825 - val_loss: 10.7860\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.9482 - val_loss: 10.7508\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.9136 - val_loss: 10.7162\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.8790 - val_loss: 10.6826\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.8458 - val_loss: 10.6486\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.8124 - val_loss: 10.6151\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.7794 - val_loss: 10.5814\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.7459 - val_loss: 10.5482\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.7130 - val_loss: 10.5156\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.6809 - val_loss: 10.4826\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.6476 - val_loss: 10.4500\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.6153 - val_loss: 10.4184\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.5836 - val_loss: 10.3862\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.5511 - val_loss: 10.3541\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.5187 - val_loss: 10.3235\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.4877 - val_loss: 10.2922\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.4559 - val_loss: 10.2626\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4258 - val_loss: 10.2320\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.3946 - val_loss: 10.2025\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.3637 - val_loss: 10.1734\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.3331 - val_loss: 10.1448\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.3030 - val_loss: 10.1159\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.2727 - val_loss: 10.0877\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.2431 - val_loss: 10.0597\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.2135 - val_loss: 10.0320\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.1845 - val_loss: 10.0040\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.1555 - val_loss: 9.9770\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.1276 - val_loss: 9.9496\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0997 - val_loss: 9.9228\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.0718 - val_loss: 9.8965\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0444 - val_loss: 9.8706\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.0174 - val_loss: 9.8440\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.9898 - val_loss: 9.8177\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.9625 - val_loss: 9.7915\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.9353 - val_loss: 9.7655\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.9087 - val_loss: 9.7391\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8816 - val_loss: 9.7128\n",
      "Epoch 103/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.8547 - val_loss: 9.6866\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.8280 - val_loss: 9.6608\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.8018 - val_loss: 9.6353\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.7760 - val_loss: 9.6108\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.7510 - val_loss: 9.5858\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7252 - val_loss: 9.5611\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.6993 - val_loss: 9.5363\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.6737 - val_loss: 9.5124\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.6489 - val_loss: 9.4880\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.6241 - val_loss: 9.4638\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.5995 - val_loss: 9.4400\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5752 - val_loss: 9.4169\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5519 - val_loss: 9.3936\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5283 - val_loss: 9.3708\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.5048 - val_loss: 9.3479\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.4814 - val_loss: 9.3261\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 56us/sample - loss: 9.4591 - val_loss: 9.3042\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.4366 - val_loss: 9.2819\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 9.4142 - val_loss: 9.2598\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 9.3920 - val_loss: 9.2383\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.3703 - val_loss: 9.2163\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.3481 - val_loss: 9.1954\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.3269 - val_loss: 9.1740\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.3055 - val_loss: 9.1529\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.2840 - val_loss: 9.1327\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2634 - val_loss: 9.1116\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.2423 - val_loss: 9.0910\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.2214 - val_loss: 9.0710\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.2011 - val_loss: 9.0517\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1814 - val_loss: 9.0316\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 9.1611 - val_loss: 9.0120\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1412 - val_loss: 8.9931\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 9.1218 - val_loss: 8.9738\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.1021 - val_loss: 8.9552\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.0829 - val_loss: 8.9367\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.0640 - val_loss: 8.9179\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 9.0451 - val_loss: 8.8998\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0268 - val_loss: 8.8816\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.0081 - val_loss: 8.8631\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.9893 - val_loss: 8.8451\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.9709 - val_loss: 8.8269\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.9523 - val_loss: 8.8092\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.9341 - val_loss: 8.7911\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9157 - val_loss: 8.7739\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.8981 - val_loss: 8.7561\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.8799 - val_loss: 8.7390\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.8628 - val_loss: 8.7221\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.8458 - val_loss: 8.7050\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.8290 - val_loss: 8.6888\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.8131 - val_loss: 8.6726\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.7973 - val_loss: 8.6559\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.7813 - val_loss: 8.6405\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.7662 - val_loss: 8.6241\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.7501 - val_loss: 8.6078\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.7343 - val_loss: 8.5922\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.7190 - val_loss: 8.5767\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.7042 - val_loss: 8.5607\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6885 - val_loss: 8.5452\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6735 - val_loss: 8.5303\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.6589 - val_loss: 8.5149\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.6441 - val_loss: 8.5001\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.6293 - val_loss: 8.4849\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.6144 - val_loss: 8.4705\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.5999 - val_loss: 8.4560\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.5858 - val_loss: 8.4415\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5712 - val_loss: 8.4272\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.5569 - val_loss: 8.4130\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5428 - val_loss: 8.3988\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5286 - val_loss: 8.3850\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5149 - val_loss: 8.3712\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.5011 - val_loss: 8.3579\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4879 - val_loss: 8.3447\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4747 - val_loss: 8.3315\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.4617 - val_loss: 8.3190\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4489 - val_loss: 8.3056\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.4357 - val_loss: 8.2926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4225 - val_loss: 8.2798\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.4100 - val_loss: 8.2669\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.3972 - val_loss: 8.2547\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.3851 - val_loss: 8.2420\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.3726 - val_loss: 8.2291\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3599 - val_loss: 8.2163\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.3472 - val_loss: 8.2048\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3355 - val_loss: 8.1927\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3238 - val_loss: 8.1807\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.3119 - val_loss: 8.1686\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3001 - val_loss: 8.1573\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.2887 - val_loss: 8.1458\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.2775 - val_loss: 8.1344\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.2664 - val_loss: 8.1230\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2554 - val_loss: 8.1116\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2444 - val_loss: 8.1006\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.2340 - val_loss: 8.0893\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2234 - val_loss: 8.0788\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2136 - val_loss: 8.0676\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.2031 - val_loss: 8.0563\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.1924 - val_loss: 8.0454\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1820 - val_loss: 8.0342\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.1714 - val_loss: 8.0234\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.1611 - val_loss: 8.0123\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.1506 - val_loss: 8.0025\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.1412 - val_loss: 7.9921\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1314 - val_loss: 7.9816\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1215 - val_loss: 7.9712\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 8.1116 - val_loss: 7.9604\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1018 - val_loss: 7.9499\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0916 - val_loss: 7.9399\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.0822 - val_loss: 7.9293\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.0720 - val_loss: 7.9190\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.0623 - val_loss: 7.9095\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.0534 - val_loss: 7.8996\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.0441 - val_loss: 7.8897\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.0348 - val_loss: 7.8802\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.0258 - val_loss: 7.8703\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.0166 - val_loss: 7.8608\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.0080 - val_loss: 7.8515\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.9994 - val_loss: 7.8424\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9910 - val_loss: 7.8327\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.9822 - val_loss: 7.8232\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.9737 - val_loss: 7.8141\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.9656 - val_loss: 7.8050\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9576 - val_loss: 7.7956\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.9493 - val_loss: 7.7875\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.9420 - val_loss: 7.7782\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.9340 - val_loss: 7.7697\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9264 - val_loss: 7.7614\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.9191 - val_loss: 7.7523\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9111 - val_loss: 7.7439\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.9039 - val_loss: 7.7358\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.8968 - val_loss: 7.7270\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.8893 - val_loss: 7.7190\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.8822 - val_loss: 7.7107\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.8752 - val_loss: 7.7025\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.8679 - val_loss: 7.6945\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.8609 - val_loss: 7.6865\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.8537 - val_loss: 7.6789\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.8468 - val_loss: 7.6709\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.8396 - val_loss: 7.6634\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.8329 - val_loss: 7.6555\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8258 - val_loss: 7.6477\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.8191 - val_loss: 7.6403\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8125 - val_loss: 7.6327\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.8062 - val_loss: 7.6256\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8002 - val_loss: 7.6182\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7940 - val_loss: 7.6113\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.7882 - val_loss: 7.6044\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7821 - val_loss: 7.5973\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.7762 - val_loss: 7.5899\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.7700 - val_loss: 7.5828\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.7640 - val_loss: 7.5761\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7585 - val_loss: 7.5692\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7528 - val_loss: 7.5626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7470 - val_loss: 7.5560\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.7414 - val_loss: 7.5494\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7358 - val_loss: 7.5435\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.7307 - val_loss: 7.5367\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.7248 - val_loss: 7.5305\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.7193 - val_loss: 7.5240\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.7134 - val_loss: 7.5180\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.7081 - val_loss: 7.5118\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.7026 - val_loss: 7.5058\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6973 - val_loss: 7.4994\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6916 - val_loss: 7.4937\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.6865 - val_loss: 7.4875\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6810 - val_loss: 7.4815\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.6757 - val_loss: 7.4757\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6706 - val_loss: 7.4698\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.6653 - val_loss: 7.4645\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.6605 - val_loss: 7.4586\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.6552 - val_loss: 7.4534\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.6506 - val_loss: 7.4479\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6456 - val_loss: 7.4423\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.6405 - val_loss: 7.4371\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.6359 - val_loss: 7.4314\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6309 - val_loss: 7.4255\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.6257 - val_loss: 7.4198\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.6207 - val_loss: 7.4145\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6160 - val_loss: 7.4090\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.6115 - val_loss: 7.4039\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6068 - val_loss: 7.3986\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6022 - val_loss: 7.3932\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.5977 - val_loss: 7.3883\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.5934 - val_loss: 7.3833\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5891 - val_loss: 7.3786\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.5850 - val_loss: 7.3740\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.5810 - val_loss: 7.3691\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.5767 - val_loss: 7.3644\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5726 - val_loss: 7.3597\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.5684 - val_loss: 7.3556\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5648 - val_loss: 7.3509\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.5607 - val_loss: 7.3464\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.5567 - val_loss: 7.3416\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5525 - val_loss: 7.3371\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5486 - val_loss: 7.3328\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5450 - val_loss: 7.3287\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5413 - val_loss: 7.3245\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.5376 - val_loss: 7.3202\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5337 - val_loss: 7.3163\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5301 - val_loss: 7.3122\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5263 - val_loss: 7.3081\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5226 - val_loss: 7.3041\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5188 - val_loss: 7.3006\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5156 - val_loss: 7.2967\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.5119 - val_loss: 7.2929\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5084 - val_loss: 7.2893\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5051 - val_loss: 7.2858\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.5020 - val_loss: 7.2821\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4988 - val_loss: 7.2785\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.4955 - val_loss: 7.2753\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.4927 - val_loss: 7.2718\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.4894 - val_loss: 7.2686\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4866 - val_loss: 7.2649\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4833 - val_loss: 7.2613\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4801 - val_loss: 7.2579\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.4770 - val_loss: 7.2544\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.4738 - val_loss: 7.2513\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.4709 - val_loss: 7.2480\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.4679 - val_loss: 7.2448\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4649 - val_loss: 7.2419\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.4623 - val_loss: 7.2388\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4595 - val_loss: 7.2358\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.4566 - val_loss: 7.2326\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.4538 - val_loss: 7.2294\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.4509 - val_loss: 7.2264\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.4480 - val_loss: 7.2233\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 7.4453 - val_loss: 7.2200\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.4423 - val_loss: 7.2169\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.4395 - val_loss: 7.2139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4367 - val_loss: 7.2111\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4341 - val_loss: 7.2078\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4313 - val_loss: 7.2048\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4283 - val_loss: 7.2021\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4258 - val_loss: 7.1992\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4232 - val_loss: 7.1959\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4202 - val_loss: 7.1928\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.4174 - val_loss: 7.1895\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4144 - val_loss: 7.1865\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4119 - val_loss: 7.1838\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.4092 - val_loss: 7.1811\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.4068 - val_loss: 7.1785\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.4045 - val_loss: 7.1757\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4020 - val_loss: 7.1728\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3993 - val_loss: 7.1700\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3968 - val_loss: 7.1672\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.3944 - val_loss: 7.1643\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3918 - val_loss: 7.1617\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3895 - val_loss: 7.1589\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3870 - val_loss: 7.1563\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.3846 - val_loss: 7.1537\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3823 - val_loss: 7.1512\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3800 - val_loss: 7.1485\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3775 - val_loss: 7.1463\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3753 - val_loss: 7.1436\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3729 - val_loss: 7.1409\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3704 - val_loss: 7.1387\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3685 - val_loss: 7.1362\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3663 - val_loss: 7.1340\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3642 - val_loss: 7.1318\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3622 - val_loss: 7.1290\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3597 - val_loss: 7.1266\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3577 - val_loss: 7.1241\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3553 - val_loss: 7.1219\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3533 - val_loss: 7.1197\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3514 - val_loss: 7.1177\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3496 - val_loss: 7.1154\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3475 - val_loss: 7.1132\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3456 - val_loss: 7.1109\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3435 - val_loss: 7.1087\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3415 - val_loss: 7.1064\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.3394 - val_loss: 7.1043\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3375 - val_loss: 7.1020\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3354 - val_loss: 7.0998\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3333 - val_loss: 7.0980\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3316 - val_loss: 7.0963\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3301 - val_loss: 7.0941\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.3282 - val_loss: 7.0923\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3264 - val_loss: 7.0900\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3244 - val_loss: 7.0881\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3226 - val_loss: 7.0858\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3207 - val_loss: 7.0837\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3187 - val_loss: 7.0817\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3170 - val_loss: 7.0797\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3152 - val_loss: 7.0777\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.3135 - val_loss: 7.0758\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.3119 - val_loss: 7.0739\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3101 - val_loss: 7.0721\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3085 - val_loss: 7.0701\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3067 - val_loss: 7.0687\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3052 - val_loss: 7.0670\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3037 - val_loss: 7.0652\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3018 - val_loss: 7.0635\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3002 - val_loss: 7.0617\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2986 - val_loss: 7.0602\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.2970 - val_loss: 7.0585\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.2954 - val_loss: 7.0568\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2938 - val_loss: 7.0555\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2925 - val_loss: 7.0540\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2909 - val_loss: 7.0525\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2892 - val_loss: 7.0509\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2879 - val_loss: 7.0497\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2865 - val_loss: 7.0482\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2851 - val_loss: 7.0467\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2836 - val_loss: 7.0452\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2821 - val_loss: 7.0435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2806 - val_loss: 7.0422\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2794 - val_loss: 7.0409\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2780 - val_loss: 7.0393\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2766 - val_loss: 7.0380\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2752 - val_loss: 7.0365\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2739 - val_loss: 7.0350\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2726 - val_loss: 7.0337\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2714 - val_loss: 7.0325\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2702 - val_loss: 7.0311\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2689 - val_loss: 7.0299\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2677 - val_loss: 7.0286\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2665 - val_loss: 7.0273\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2652 - val_loss: 7.0258\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2640 - val_loss: 7.0246\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2629 - val_loss: 7.0235\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2617 - val_loss: 7.0222\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2606 - val_loss: 7.0210\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2594 - val_loss: 7.0199\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2584 - val_loss: 7.0187\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2573 - val_loss: 7.0175\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2563 - val_loss: 7.0167\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2555 - val_loss: 7.0155\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2544 - val_loss: 7.0144\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2535 - val_loss: 7.0134\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2525 - val_loss: 7.0125\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2517 - val_loss: 7.0114\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2509 - val_loss: 7.0105\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2498 - val_loss: 7.0095\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2490 - val_loss: 7.0082\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.2479 - val_loss: 7.0071\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2468 - val_loss: 7.0059\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2458 - val_loss: 7.0050\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2450 - val_loss: 7.0040\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2439 - val_loss: 7.0030\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2431 - val_loss: 7.0020\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2422 - val_loss: 7.0010\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2413 - val_loss: 7.0000\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2403 - val_loss: 6.9992\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2395 - val_loss: 6.9983\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2387 - val_loss: 6.9974\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2378 - val_loss: 6.9966\n",
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2369 - val_loss: 6.9957\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2363 - val_loss: 6.9949\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2356 - val_loss: 6.9938\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2348 - val_loss: 6.9931\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 58us/sample - loss: 7.2342 - val_loss: 6.9921\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2333 - val_loss: 6.9909\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2324 - val_loss: 6.9902\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2317 - val_loss: 6.9894\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2309 - val_loss: 6.9885\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2304 - val_loss: 6.9878\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2296 - val_loss: 6.9868\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2289 - val_loss: 6.9859\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2281 - val_loss: 6.9854\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2275 - val_loss: 6.9845\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 8.203 - 0s 62us/sample - loss: 7.2270 - val_loss: 6.9839\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2263 - val_loss: 6.9830\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2257 - val_loss: 6.9824\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2252 - val_loss: 6.9816\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2246 - val_loss: 6.9812\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2242 - val_loss: 6.9805\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2236 - val_loss: 6.9796\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2230 - val_loss: 6.9789\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2225 - val_loss: 6.9781\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.2218 - val_loss: 6.9773\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2212 - val_loss: 6.9766\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2206 - val_loss: 6.9761\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2201 - val_loss: 6.9753\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2196 - val_loss: 6.9748\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2191 - val_loss: 6.9742\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2186 - val_loss: 6.9738\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2182 - val_loss: 6.9732\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2177 - val_loss: 6.9728\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2174 - val_loss: 6.9723\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2168 - val_loss: 6.9716\n",
      "Epoch 482/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2162 - val_loss: 6.9710\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2157 - val_loss: 6.9705\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2152 - val_loss: 6.9701\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2148 - val_loss: 6.9695\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2143 - val_loss: 6.9690\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2138 - val_loss: 6.9688\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2134 - val_loss: 6.9682\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2129 - val_loss: 6.9678\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2125 - val_loss: 6.9675\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2121 - val_loss: 6.9672\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2117 - val_loss: 6.9666\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2112 - val_loss: 6.9662\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2108 - val_loss: 6.9660\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2103 - val_loss: 6.9657\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2100 - val_loss: 6.9653\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2096 - val_loss: 6.9648\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2090 - val_loss: 6.9645\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2087 - val_loss: 6.9642\n",
      "Epoch 500/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2083 - val_loss: 6.9638\n",
      "594/594 [==============================] - 0s 47us/sample - loss: 6.9650\n",
      "[CV]  learning_rate=0.001683454924600351, n_hidden=0, n_neurons=271, total=  45.2s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 276us/sample - loss: 13.9807 - val_loss: 13.4766\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.6823 - val_loss: 13.1971\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.3987 - val_loss: 12.9215\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.1230 - val_loss: 12.6535\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.8590 - val_loss: 12.3961\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.6028 - val_loss: 12.1450\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.3532 - val_loss: 11.9038\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.1117 - val_loss: 11.6741\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.8809 - val_loss: 11.4562\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.6589 - val_loss: 11.2496\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.4479 - val_loss: 11.0512\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.2418 - val_loss: 10.8605\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.0480 - val_loss: 10.6848\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.8631 - val_loss: 10.5128\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.6830 - val_loss: 10.3510\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.5150 - val_loss: 10.1958\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.3502 - val_loss: 10.0509\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.1968 - val_loss: 9.9056\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.0429 - val_loss: 9.7698\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.9002 - val_loss: 9.6350\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.7616 - val_loss: 9.5090\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.6343 - val_loss: 9.3885\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5140 - val_loss: 9.2723\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.3976 - val_loss: 9.1562\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.2833 - val_loss: 9.0476\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.1770 - val_loss: 8.9374\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.0712 - val_loss: 8.8370\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9735 - val_loss: 8.7429\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.8804 - val_loss: 8.6507\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.7906 - val_loss: 8.5619\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7044 - val_loss: 8.4760\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6208 - val_loss: 8.3961\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5433 - val_loss: 8.3225\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.4701 - val_loss: 8.2496\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.3995 - val_loss: 8.1802\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.3320 - val_loss: 8.1162\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.2701 - val_loss: 8.0590\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2150 - val_loss: 8.0013\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1585 - val_loss: 7.9453\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1046 - val_loss: 7.8928\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0549 - val_loss: 7.8413\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.0058 - val_loss: 7.7896\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.9585 - val_loss: 7.7473\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.9185 - val_loss: 7.7054\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.8784 - val_loss: 7.6663\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8395 - val_loss: 7.6287\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8035 - val_loss: 7.5950\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.7709 - val_loss: 7.5628\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.7388 - val_loss: 7.5338\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7106 - val_loss: 7.5074\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6837 - val_loss: 7.4814\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.6573 - val_loss: 7.4562\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.6328 - val_loss: 7.4323\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6098 - val_loss: 7.4082\n",
      "Epoch 55/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5878 - val_loss: 7.3876\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.5675 - val_loss: 7.3682\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.5487 - val_loss: 7.3466\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.5281 - val_loss: 7.3272\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5098 - val_loss: 7.3071\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4916 - val_loss: 7.2889\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4750 - val_loss: 7.2704\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4587 - val_loss: 7.2542\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 187us/sample - loss: 7.4452 - val_loss: 7.2375\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4308 - val_loss: 7.2206\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4165 - val_loss: 7.2056\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4036 - val_loss: 7.1891\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3890 - val_loss: 7.1751\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3767 - val_loss: 7.1613\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3639 - val_loss: 7.1479\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3522 - val_loss: 7.1353\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3417 - val_loss: 7.1239\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3310 - val_loss: 7.1135\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3213 - val_loss: 7.1028\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3110 - val_loss: 7.0918\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3008 - val_loss: 7.0823\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2911 - val_loss: 7.0750\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2826 - val_loss: 7.0662\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2737 - val_loss: 7.0583\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2668 - val_loss: 7.0510\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2602 - val_loss: 7.0451\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2538 - val_loss: 7.0396\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2477 - val_loss: 7.0351\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2427 - val_loss: 7.0296\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2378 - val_loss: 7.0250\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2329 - val_loss: 7.0209\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2290 - val_loss: 7.0171\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2243 - val_loss: 7.0142\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2198 - val_loss: 7.0112\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2157 - val_loss: 7.0088\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2117 - val_loss: 7.0045\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2069 - val_loss: 7.0013\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2026 - val_loss: 6.9991\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1990 - val_loss: 6.9964\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1954 - val_loss: 6.9946\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1928 - val_loss: 6.9923\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1897 - val_loss: 6.9898\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 116us/sample - loss: 7.1865 - val_loss: 6.9871\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 7.1838 - val_loss: 6.9857\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.1807 - val_loss: 6.9846\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1788 - val_loss: 6.9820\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1767 - val_loss: 6.9810\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1742 - val_loss: 6.9801\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1722 - val_loss: 6.9787\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1703 - val_loss: 6.9781\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1682 - val_loss: 6.9760\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1666 - val_loss: 6.9753\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1653 - val_loss: 6.9733\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1632 - val_loss: 6.9722\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1614 - val_loss: 6.9726\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1597 - val_loss: 6.9724\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1583 - val_loss: 6.9708\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1569 - val_loss: 6.9710\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1555 - val_loss: 6.9696\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1545 - val_loss: 6.9688\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1536 - val_loss: 6.9688\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1531 - val_loss: 6.9680\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1518 - val_loss: 6.9672\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1512 - val_loss: 6.9665\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1502 - val_loss: 6.9656\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1492 - val_loss: 6.9647\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1484 - val_loss: 6.9634\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1475 - val_loss: 6.9632\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1472 - val_loss: 6.9633\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1463 - val_loss: 6.9624\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1452 - val_loss: 6.9625\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1445 - val_loss: 6.9629\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1437 - val_loss: 6.9624\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1428 - val_loss: 6.9625\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1427 - val_loss: 6.9620\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1419 - val_loss: 6.9623\n",
      "Epoch 131/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1418 - val_loss: 6.9619\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1414 - val_loss: 6.9613\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1408 - val_loss: 6.9614\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1404 - val_loss: 6.9616\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1402 - val_loss: 6.9613\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1395 - val_loss: 6.9611\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1391 - val_loss: 6.9619\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1393 - val_loss: 6.9613\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1386 - val_loss: 6.9611\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1382 - val_loss: 6.9604\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1381 - val_loss: 6.9598\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.1378 - val_loss: 6.9602\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1374 - val_loss: 6.9590\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1372 - val_loss: 6.9597\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1367 - val_loss: 6.9596\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1364 - val_loss: 6.9579\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1363 - val_loss: 6.9584\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1360 - val_loss: 6.9589\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1357 - val_loss: 6.9588\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1353 - val_loss: 6.9588\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1354 - val_loss: 6.9580\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1352 - val_loss: 6.9580\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1352 - val_loss: 6.9584\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1348 - val_loss: 6.9585\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1348 - val_loss: 6.9579\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1347 - val_loss: 6.9580\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1347 - val_loss: 6.9577\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1345 - val_loss: 6.9587\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1343 - val_loss: 6.9586\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1338 - val_loss: 6.9581\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1340 - val_loss: 6.9581\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.1339 - val_loss: 6.9581\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1339 - val_loss: 6.9581\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1338 - val_loss: 6.9583\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1335 - val_loss: 6.9586\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1332 - val_loss: 6.9588\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1333 - val_loss: 6.9583\n",
      "594/594 [==============================] - 0s 39us/sample - loss: 6.9606\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=  15.5s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 283us/sample - loss: 13.9203 - val_loss: 13.5896\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.6326 - val_loss: 13.3065\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.3564 - val_loss: 13.0338\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.0875 - val_loss: 12.7758\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.8340 - val_loss: 12.5210\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.5797 - val_loss: 12.2685\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.3297 - val_loss: 12.0264\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.0878 - val_loss: 11.7913\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.8530 - val_loss: 11.5642\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.6276 - val_loss: 11.3455\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.4095 - val_loss: 11.1375\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.1959 - val_loss: 10.9406\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.9910 - val_loss: 10.7525\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.7948 - val_loss: 10.5731\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.6040 - val_loss: 10.3989\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.4204 - val_loss: 10.2292\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.2381 - val_loss: 10.0701\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.0707 - val_loss: 9.9171\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.9112 - val_loss: 9.7776\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.7609 - val_loss: 9.6352\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.6109 - val_loss: 9.4990\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.4666 - val_loss: 9.3678\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3283 - val_loss: 9.2456\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.2004 - val_loss: 9.1268\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.0770 - val_loss: 9.0109\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.9571 - val_loss: 8.8999\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.8460 - val_loss: 8.7976\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 8.7382 - val_loss: 8.6966\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6336 - val_loss: 8.6045\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.5378 - val_loss: 8.5139\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.4462 - val_loss: 8.4294\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.3594 - val_loss: 8.3451\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.2727 - val_loss: 8.2664\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1923 - val_loss: 8.1910\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1163 - val_loss: 8.1185\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.0433 - val_loss: 8.0495\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.9740 - val_loss: 7.9864\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.9090 - val_loss: 7.9272\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8495 - val_loss: 7.8683\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.7908 - val_loss: 7.8147\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.7409 - val_loss: 7.7635\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6930 - val_loss: 7.7167\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6500 - val_loss: 7.6744\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.6117 - val_loss: 7.6325\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.5732 - val_loss: 7.5899\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.5355 - val_loss: 7.5524\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5013 - val_loss: 7.5155\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4672 - val_loss: 7.4821\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.4355 - val_loss: 7.4498\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4050 - val_loss: 7.4216\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3762 - val_loss: 7.3955\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3478 - val_loss: 7.3697\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3198 - val_loss: 7.3484\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2949 - val_loss: 7.3257\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2703 - val_loss: 7.3027\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2456 - val_loss: 7.2802\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2235 - val_loss: 7.2596\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2019 - val_loss: 7.2418\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1824 - val_loss: 7.2235\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1632 - val_loss: 7.2074\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1449 - val_loss: 7.1909\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1268 - val_loss: 7.1760\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1094 - val_loss: 7.1618\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.0941 - val_loss: 7.1473\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.0789 - val_loss: 7.1354\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.0671 - val_loss: 7.1220\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0544 - val_loss: 7.1117\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0434 - val_loss: 7.1010\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.0332 - val_loss: 7.0910\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.0234 - val_loss: 7.0822\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.0148 - val_loss: 7.0732\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.0053 - val_loss: 7.0656\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9968 - val_loss: 7.0579\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9884 - val_loss: 7.0502\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9808 - val_loss: 7.0418\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9728 - val_loss: 7.0360\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9659 - val_loss: 7.0309\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9601 - val_loss: 7.0260\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9546 - val_loss: 7.0204\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9493 - val_loss: 7.0159\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9446 - val_loss: 7.0119\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9397 - val_loss: 7.0087\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9357 - val_loss: 7.0060\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9318 - val_loss: 7.0017\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9266 - val_loss: 6.9990\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9234 - val_loss: 6.9964\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.9196 - val_loss: 6.9939\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.447 - 0s 68us/sample - loss: 6.9165 - val_loss: 6.9915\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9128 - val_loss: 6.9889\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9091 - val_loss: 6.9866\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9055 - val_loss: 6.9834\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9014 - val_loss: 6.9806\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.8983 - val_loss: 6.9776\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8951 - val_loss: 6.9761\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.8925 - val_loss: 6.9745\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8900 - val_loss: 6.9721\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8871 - val_loss: 6.9696\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8842 - val_loss: 6.9691\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8820 - val_loss: 6.9685\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8798 - val_loss: 6.9659\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8778 - val_loss: 6.9657\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8755 - val_loss: 6.9652\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8736 - val_loss: 6.9651\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8714 - val_loss: 6.9636\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8694 - val_loss: 6.9626\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8678 - val_loss: 6.9620\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8662 - val_loss: 6.9603\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8646 - val_loss: 6.9601\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8630 - val_loss: 6.9614\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8615 - val_loss: 6.9616\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8605 - val_loss: 6.9608\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 6.8597 - val_loss: 6.9609\n",
      "Epoch 113/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8583 - val_loss: 6.9590\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8564 - val_loss: 6.9594\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8560 - val_loss: 6.9582\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8552 - val_loss: 6.9574\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 6.8548 - val_loss: 6.9562\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8539 - val_loss: 6.9560\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8535 - val_loss: 6.9554\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8524 - val_loss: 6.9548\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8521 - val_loss: 6.9528\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8512 - val_loss: 6.9525\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8512 - val_loss: 6.9519\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8503 - val_loss: 6.9512\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8501 - val_loss: 6.9521\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.8494 - val_loss: 6.9527\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8494 - val_loss: 6.9521\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8487 - val_loss: 6.9511\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 143us/sample - loss: 6.8488 - val_loss: 6.9512\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8483 - val_loss: 6.9523\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8481 - val_loss: 6.9525\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8480 - val_loss: 6.9521\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.8481 - val_loss: 6.9513\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8473 - val_loss: 6.9511\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8475 - val_loss: 6.9502\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8470 - val_loss: 6.9507\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8474 - val_loss: 6.9513\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8472 - val_loss: 6.9508\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.8471 - val_loss: 6.9516\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8467 - val_loss: 6.9510\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8471 - val_loss: 6.9516\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8467 - val_loss: 6.9524\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8469 - val_loss: 6.9513\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8465 - val_loss: 6.9526\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.8465 - val_loss: 6.9531\n",
      "594/594 [==============================] - 0s 37us/sample - loss: 7.5572\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=  13.3s\n",
      "[CV] learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21 ....\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 282us/sample - loss: 13.8460 - val_loss: 13.5618\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.5636 - val_loss: 13.2739\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.2847 - val_loss: 12.9963\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.0146 - val_loss: 12.7337\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.7569 - val_loss: 12.4759\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.5075 - val_loss: 12.2287\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.2670 - val_loss: 11.9933\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.0356 - val_loss: 11.7665\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.8193 - val_loss: 11.5525\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.6129 - val_loss: 11.3451\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.4130 - val_loss: 11.1413\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.2190 - val_loss: 10.9539\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.0379 - val_loss: 10.7722\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.8633 - val_loss: 10.5986\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.6968 - val_loss: 10.4333\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.5372 - val_loss: 10.2741\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.3814 - val_loss: 10.1219\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.2318 - val_loss: 9.9777\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.0889 - val_loss: 9.8409\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.9521 - val_loss: 9.7062\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8189 - val_loss: 9.5766\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.6911 - val_loss: 9.4526\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.5672 - val_loss: 9.3271\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.4463 - val_loss: 9.2146\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3360 - val_loss: 9.1001\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2225 - val_loss: 8.9924\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.1164 - val_loss: 8.8868\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0151 - val_loss: 8.7897\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.9241 - val_loss: 8.6945\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8397 - val_loss: 8.6049\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7531 - val_loss: 8.5256\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.6742 - val_loss: 8.4447\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5950 - val_loss: 8.3711\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5205 - val_loss: 8.3028\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4509 - val_loss: 8.2378\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3867 - val_loss: 8.1754\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3244 - val_loss: 8.1148\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.2653 - val_loss: 8.0572\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.2083 - val_loss: 7.9984\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.1510 - val_loss: 7.9444\n",
      "Epoch 41/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.0982 - val_loss: 7.8927\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.0478 - val_loss: 7.8469\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.0034 - val_loss: 7.8006\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9595 - val_loss: 7.7566\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.9191 - val_loss: 7.7121\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.8794 - val_loss: 7.6746\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.8458 - val_loss: 7.6347\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.8111 - val_loss: 7.5972\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.759 - 0s 75us/sample - loss: 7.7788 - val_loss: 7.5641\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7484 - val_loss: 7.5304\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7193 - val_loss: 7.5007\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.6922 - val_loss: 7.4716\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6653 - val_loss: 7.4435\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6406 - val_loss: 7.4174\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.6177 - val_loss: 7.3947\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5967 - val_loss: 7.3681\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5732 - val_loss: 7.3471\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5552 - val_loss: 7.3241\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5353 - val_loss: 7.3024\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5169 - val_loss: 7.2816\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4988 - val_loss: 7.2645\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.4830 - val_loss: 7.2495\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4691 - val_loss: 7.2343\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4553 - val_loss: 7.2193\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4423 - val_loss: 7.2045\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.4281 - val_loss: 7.1899\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.4148 - val_loss: 7.1766\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4020 - val_loss: 7.1636\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3905 - val_loss: 7.1516\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3797 - val_loss: 7.1398\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3703 - val_loss: 7.1284\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3605 - val_loss: 7.1167\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3502 - val_loss: 7.1054\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3409 - val_loss: 7.0960\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.3325 - val_loss: 7.0846\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3230 - val_loss: 7.0772\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3164 - val_loss: 7.0700\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3086 - val_loss: 7.0621\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3009 - val_loss: 7.0544\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2936 - val_loss: 7.0478\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2870 - val_loss: 7.0407\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2807 - val_loss: 7.0343\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2741 - val_loss: 7.0261\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2677 - val_loss: 7.0200\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2621 - val_loss: 7.0138\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2572 - val_loss: 7.0085\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2526 - val_loss: 7.0035\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2477 - val_loss: 6.9978\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2431 - val_loss: 6.9926\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2385 - val_loss: 6.9883\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2343 - val_loss: 6.9844\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2311 - val_loss: 6.9802\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2268 - val_loss: 6.9763\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2232 - val_loss: 6.9723\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2199 - val_loss: 6.9692\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2168 - val_loss: 6.9668\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2143 - val_loss: 6.9639\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2117 - val_loss: 6.9613\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2095 - val_loss: 6.9594\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2077 - val_loss: 6.9577\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2056 - val_loss: 6.9560\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2034 - val_loss: 6.9541\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2016 - val_loss: 6.9526\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1994 - val_loss: 6.9514\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1978 - val_loss: 6.9495\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1962 - val_loss: 6.9489\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1941 - val_loss: 6.9477\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1926 - val_loss: 6.9463\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1911 - val_loss: 6.9455\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1893 - val_loss: 6.9445\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1875 - val_loss: 6.9432\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1851 - val_loss: 6.9434\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1843 - val_loss: 6.9419\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1828 - val_loss: 6.9421\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1809 - val_loss: 6.9410\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1797 - val_loss: 6.9407\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1788 - val_loss: 6.9407\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1773 - val_loss: 6.9407\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1767 - val_loss: 6.9401\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1756 - val_loss: 6.9390\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1749 - val_loss: 6.9381\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1740 - val_loss: 6.9381\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1727 - val_loss: 6.9380\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1721 - val_loss: 6.9373\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1707 - val_loss: 6.9368\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1696 - val_loss: 6.9374\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1686 - val_loss: 6.9368\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1676 - val_loss: 6.9372\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1666 - val_loss: 6.9365\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1654 - val_loss: 6.9357\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1642 - val_loss: 6.9355\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1639 - val_loss: 6.9346\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1631 - val_loss: 6.9346\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1619 - val_loss: 6.9341\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1617 - val_loss: 6.9331\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1603 - val_loss: 6.9328\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1595 - val_loss: 6.9326\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1594 - val_loss: 6.9311\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1585 - val_loss: 6.9315\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1585 - val_loss: 6.9320\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1579 - val_loss: 6.9326\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1571 - val_loss: 6.9319\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1567 - val_loss: 6.9307\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1560 - val_loss: 6.9315\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1557 - val_loss: 6.9319\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1554 - val_loss: 6.9319\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.1547 - val_loss: 6.9318\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1547 - val_loss: 6.9312\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1546 - val_loss: 6.9313\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1544 - val_loss: 6.9320\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1546 - val_loss: 6.9330\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1540 - val_loss: 6.9336\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1542 - val_loss: 6.9338\n",
      "594/594 [==============================] - 0s 38us/sample - loss: 6.9022\n",
      "[CV]  learning_rate=0.008731907739399206, n_hidden=0, n_neurons=21, total=  14.0s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=0, n_neurons=215 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 274us/sample - loss: 14.1255 - val_loss: 13.7894\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 14.1040 - val_loss: 13.7686\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 14.0829 - val_loss: 13.7479\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 14.0618 - val_loss: 13.7268\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 14.0404 - val_loss: 13.7058\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 14.0191 - val_loss: 13.6849\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.9978 - val_loss: 13.6639\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.9765 - val_loss: 13.6430\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.9552 - val_loss: 13.6223\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.9339 - val_loss: 13.6015\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.9127 - val_loss: 13.5808\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.8915 - val_loss: 13.5601\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.8704 - val_loss: 13.5397\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.8495 - val_loss: 13.5190\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 13.8284 - val_loss: 13.4984\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.8072 - val_loss: 13.4777\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 13.7862 - val_loss: 13.4572\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.7652 - val_loss: 13.4366\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.7443 - val_loss: 13.4162\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.7234 - val_loss: 13.3958\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.7027 - val_loss: 13.3754\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.6818 - val_loss: 13.3554\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.6613 - val_loss: 13.3353\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.6408 - val_loss: 13.3150\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.6202 - val_loss: 13.2947\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.5994 - val_loss: 13.2743\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.5787 - val_loss: 13.2542\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.5579 - val_loss: 13.2344\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.5374 - val_loss: 13.2142\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.5167 - val_loss: 13.1942\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.4960 - val_loss: 13.1743\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.4753 - val_loss: 13.1543\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.4546 - val_loss: 13.1345\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.4341 - val_loss: 13.1147\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.4137 - val_loss: 13.0951\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.3932 - val_loss: 13.0757\n",
      "Epoch 37/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.3732 - val_loss: 13.0563\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.3529 - val_loss: 13.0369\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.3326 - val_loss: 13.0176\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.3124 - val_loss: 12.9983\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.2923 - val_loss: 12.9790\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.2722 - val_loss: 12.9597\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.2521 - val_loss: 12.9407\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.2323 - val_loss: 12.9215\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.2123 - val_loss: 12.9023\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.1923 - val_loss: 12.8835\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.1728 - val_loss: 12.8646\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.1533 - val_loss: 12.8456\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.1337 - val_loss: 12.8267\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.1142 - val_loss: 12.8076\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.0947 - val_loss: 12.7888\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.0752 - val_loss: 12.7699\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.0558 - val_loss: 12.7509\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.0364 - val_loss: 12.7321\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 13.0172 - val_loss: 12.7134\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.9982 - val_loss: 12.6948\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.9793 - val_loss: 12.6763\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.9606 - val_loss: 12.6578\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.9420 - val_loss: 12.6394\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.9233 - val_loss: 12.6209\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.9047 - val_loss: 12.6025\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.8861 - val_loss: 12.5842\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.8676 - val_loss: 12.5657\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.8492 - val_loss: 12.5475\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.8308 - val_loss: 12.5293\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.8126 - val_loss: 12.5113\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.7945 - val_loss: 12.4933\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7764 - val_loss: 12.4753\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.7583 - val_loss: 12.4574\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.7403 - val_loss: 12.4394\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.7222 - val_loss: 12.4215\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.7041 - val_loss: 12.4035\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.6861 - val_loss: 12.3857\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.6681 - val_loss: 12.3678\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.6501 - val_loss: 12.3501\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.6322 - val_loss: 12.3323\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.6143 - val_loss: 12.3145\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.5965 - val_loss: 12.2968\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.5786 - val_loss: 12.2791\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.5608 - val_loss: 12.2614\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.5431 - val_loss: 12.2437\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 12.5253 - val_loss: 12.2260\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.5077 - val_loss: 12.2085\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.4900 - val_loss: 12.1910\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.4724 - val_loss: 12.1735\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.4548 - val_loss: 12.1560\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 12.4371 - val_loss: 12.1385\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.4196 - val_loss: 12.1210\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.4020 - val_loss: 12.1041\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.3850 - val_loss: 12.0868\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.3675 - val_loss: 12.0700\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.3505 - val_loss: 12.0528\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.3332 - val_loss: 12.0358\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.3160 - val_loss: 12.0187\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.2987 - val_loss: 12.0014\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.2814 - val_loss: 11.9845\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.2644 - val_loss: 11.9675\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.2473 - val_loss: 11.9505\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.2301 - val_loss: 11.9335\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.2128 - val_loss: 11.9168\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.1957 - val_loss: 11.9001\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.1788 - val_loss: 11.8837\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.1621 - val_loss: 11.8671\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.1452 - val_loss: 11.8505\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.1284 - val_loss: 11.8340\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.1114 - val_loss: 11.8178\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.0948 - val_loss: 11.8015\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.0779 - val_loss: 11.7852\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.0611 - val_loss: 11.7691\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.0445 - val_loss: 11.7529\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 12.0277 - val_loss: 11.7369\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.0110 - val_loss: 11.7209\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.9943 - val_loss: 11.7049\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.9776 - val_loss: 11.6891\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.9612 - val_loss: 11.6731\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.9447 - val_loss: 11.6573\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.9282 - val_loss: 11.6416\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.9118 - val_loss: 11.6260\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.8954 - val_loss: 11.6104\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.8791 - val_loss: 11.5948\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.8627 - val_loss: 11.5791\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.8464 - val_loss: 11.5636\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.8300 - val_loss: 11.5484\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.8139 - val_loss: 11.5330\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.7975 - val_loss: 11.5175\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.7811 - val_loss: 11.5021\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.7648 - val_loss: 11.4868\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.7486 - val_loss: 11.4716\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 11.7325 - val_loss: 11.4562\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.7164 - val_loss: 11.4408\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.7003 - val_loss: 11.4255\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.6842 - val_loss: 11.4103\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.6682 - val_loss: 11.3953\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.6522 - val_loss: 11.3803\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.6363 - val_loss: 11.3654\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.6207 - val_loss: 11.3504\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.6050 - val_loss: 11.3355\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.5896 - val_loss: 11.3208\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.5741 - val_loss: 11.3063\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 55us/sample - loss: 11.5589 - val_loss: 11.2918\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.5435 - val_loss: 11.2774\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.5284 - val_loss: 11.2629\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.5130 - val_loss: 11.2487\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.4978 - val_loss: 11.2343\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.4825 - val_loss: 11.2201\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.4674 - val_loss: 11.2060\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.4523 - val_loss: 11.1919\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.4372 - val_loss: 11.1781\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.4222 - val_loss: 11.1643\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.4071 - val_loss: 11.1506\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.3921 - val_loss: 11.1369\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.3772 - val_loss: 11.1234\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.3624 - val_loss: 11.1100\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.3480 - val_loss: 11.0968\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3335 - val_loss: 11.0833\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3190 - val_loss: 11.0701\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3048 - val_loss: 11.0567\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.2904 - val_loss: 11.0436\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.2762 - val_loss: 11.0304\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.2619 - val_loss: 11.0172\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.2476 - val_loss: 11.0042\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.2335 - val_loss: 10.9910\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.2193 - val_loss: 10.9782\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.2055 - val_loss: 10.9651\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.1914 - val_loss: 10.9525\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.1776 - val_loss: 10.9397\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.1637 - val_loss: 10.9267\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.1496 - val_loss: 10.9138\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.1357 - val_loss: 10.9008\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.1217 - val_loss: 10.8880\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.1080 - val_loss: 10.8752\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.0943 - val_loss: 10.8626\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.0808 - val_loss: 10.8499\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.0672 - val_loss: 10.8372\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.0535 - val_loss: 10.8243\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.0398 - val_loss: 10.8117\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.0263 - val_loss: 10.7993\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.0131 - val_loss: 10.7868\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.9996 - val_loss: 10.7741\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.9860 - val_loss: 10.7617\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.9726 - val_loss: 10.7490\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.9590 - val_loss: 10.7363\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.9454 - val_loss: 10.7239\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.9321 - val_loss: 10.7115\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.9189 - val_loss: 10.6990\n",
      "Epoch 186/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.9055 - val_loss: 10.6867\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.8924 - val_loss: 10.6745\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.8793 - val_loss: 10.6621\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.8661 - val_loss: 10.6497\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.8529 - val_loss: 10.6375\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.8401 - val_loss: 10.6254\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.8272 - val_loss: 10.6134\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.8145 - val_loss: 10.6014\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.8018 - val_loss: 10.5893\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.7889 - val_loss: 10.5771\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.7761 - val_loss: 10.5654\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.7636 - val_loss: 10.5534\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.7508 - val_loss: 10.5414\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.7381 - val_loss: 10.5294\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.7254 - val_loss: 10.5177\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.7130 - val_loss: 10.5059\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.7005 - val_loss: 10.4940\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.6879 - val_loss: 10.4825\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.6757 - val_loss: 10.4707\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.6632 - val_loss: 10.4591\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.6508 - val_loss: 10.4476\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.6385 - val_loss: 10.4362\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.6262 - val_loss: 10.4246\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.6138 - val_loss: 10.4136\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.6018 - val_loss: 10.4021\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.5893 - val_loss: 10.3906\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.5769 - val_loss: 10.3793\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.5648 - val_loss: 10.3681\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.5528 - val_loss: 10.3566\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.5405 - val_loss: 10.3450\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.5282 - val_loss: 10.3336\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.5159 - val_loss: 10.3222\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.5037 - val_loss: 10.3108\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.4915 - val_loss: 10.2994\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.4792 - val_loss: 10.2881\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4670 - val_loss: 10.2771\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.4552 - val_loss: 10.2658\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4431 - val_loss: 10.2548\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.4313 - val_loss: 10.2436\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.4194 - val_loss: 10.2322\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.4073 - val_loss: 10.2209\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.3951 - val_loss: 10.2095\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.3830 - val_loss: 10.1981\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.3709 - val_loss: 10.1868\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.3588 - val_loss: 10.1757\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 10.31 - 0s 73us/sample - loss: 10.3469 - val_loss: 10.1644\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.3349 - val_loss: 10.1534\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.3232 - val_loss: 10.1422\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.3114 - val_loss: 10.1310\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.2997 - val_loss: 10.1200\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.2882 - val_loss: 10.1094\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.2769 - val_loss: 10.0982\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.2652 - val_loss: 10.0871\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.2537 - val_loss: 10.0766\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2427 - val_loss: 10.0656\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2312 - val_loss: 10.0548\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2199 - val_loss: 10.0441\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2089 - val_loss: 10.0332\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.1975 - val_loss: 10.0224\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.1863 - val_loss: 10.0118\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.1753 - val_loss: 10.0009\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.1641 - val_loss: 9.9901\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.1529 - val_loss: 9.9793\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.1417 - val_loss: 9.9685\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.1305 - val_loss: 9.9579\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.1196 - val_loss: 9.9475\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.1087 - val_loss: 9.9370\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.0979 - val_loss: 9.9264\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.0869 - val_loss: 9.9161\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0762 - val_loss: 9.9061\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0657 - val_loss: 9.8957\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.0549 - val_loss: 9.8855\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.0443 - val_loss: 9.8754\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.0340 - val_loss: 9.8654\n",
      "Epoch 260/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.0236 - val_loss: 9.8552\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.0130 - val_loss: 9.8449\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.0022 - val_loss: 9.8347\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.9916 - val_loss: 9.8245\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.9812 - val_loss: 9.8147\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.9711 - val_loss: 9.8046\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.9606 - val_loss: 9.7947\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.9504 - val_loss: 9.7846\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.9401 - val_loss: 9.7744\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.9297 - val_loss: 9.7644\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.9194 - val_loss: 9.7544\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.9091 - val_loss: 9.7444\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8989 - val_loss: 9.7348\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8891 - val_loss: 9.7254\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.8794 - val_loss: 9.7155\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.8693 - val_loss: 9.7060\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.8597 - val_loss: 9.6966\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.8500 - val_loss: 9.6870\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8402 - val_loss: 9.6773\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.8305 - val_loss: 9.6677\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.8206 - val_loss: 9.6580\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8108 - val_loss: 9.6486\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.8013 - val_loss: 9.6391\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.7918 - val_loss: 9.6295\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.7821 - val_loss: 9.6202\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7727 - val_loss: 9.6108\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.7631 - val_loss: 9.6017\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.7539 - val_loss: 9.5926\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7448 - val_loss: 9.5836\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.7357 - val_loss: 9.5744\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.7265 - val_loss: 9.5652\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.7171 - val_loss: 9.5560\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.7077 - val_loss: 9.5469\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6984 - val_loss: 9.5379\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.6893 - val_loss: 9.5292\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6804 - val_loss: 9.5203\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.6713 - val_loss: 9.5116\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.6624 - val_loss: 9.5028\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.6535 - val_loss: 9.4940\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.6445 - val_loss: 9.4853\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.6356 - val_loss: 9.4766\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.6266 - val_loss: 9.4678\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6176 - val_loss: 9.4592\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.6088 - val_loss: 9.4505\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.5998 - val_loss: 9.4418\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.5908 - val_loss: 9.4330\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5817 - val_loss: 9.4243\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5726 - val_loss: 9.4158\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.5639 - val_loss: 9.4071\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.5549 - val_loss: 9.3987\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.5463 - val_loss: 9.3900\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5375 - val_loss: 9.3813\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.5285 - val_loss: 9.3729\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 9.5199 - val_loss: 9.3644\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.5112 - val_loss: 9.3559\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5026 - val_loss: 9.3475\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.4941 - val_loss: 9.3394\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.4859 - val_loss: 9.3307\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.4772 - val_loss: 9.3222\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.4686 - val_loss: 9.3138\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.4601 - val_loss: 9.3056\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.4519 - val_loss: 9.2975\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.4436 - val_loss: 9.2894\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.4353 - val_loss: 9.2813\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.4271 - val_loss: 9.2728\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4184 - val_loss: 9.2644\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.4099 - val_loss: 9.2562\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.4014 - val_loss: 9.2480\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.3931 - val_loss: 9.2399\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.3849 - val_loss: 9.2315\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.3764 - val_loss: 9.2232\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.3680 - val_loss: 9.2153\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.3600 - val_loss: 9.2072\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3518 - val_loss: 9.1990\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.3436 - val_loss: 9.1910\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3355 - val_loss: 9.1829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.3274 - val_loss: 9.1749\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3193 - val_loss: 9.1668\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.3111 - val_loss: 9.1586\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.3029 - val_loss: 9.1504\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.2946 - val_loss: 9.1425\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2866 - val_loss: 9.1345\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2786 - val_loss: 9.1264\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2704 - val_loss: 9.1185\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.2625 - val_loss: 9.1105\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.2546 - val_loss: 9.1028\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.2470 - val_loss: 9.0950\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.2391 - val_loss: 9.0875\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.2315 - val_loss: 9.0795\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2235 - val_loss: 9.0718\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.2159 - val_loss: 9.0640\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.2079 - val_loss: 9.0560\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1999 - val_loss: 9.0485\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.1924 - val_loss: 9.0408\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1846 - val_loss: 9.0331\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.1768 - val_loss: 9.0254\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.1689 - val_loss: 9.0177\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1611 - val_loss: 9.0099\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.1532 - val_loss: 9.0022\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1454 - val_loss: 8.9944\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.1377 - val_loss: 8.9867\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1299 - val_loss: 8.9790\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.1222 - val_loss: 8.9715\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.1146 - val_loss: 8.9642\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1074 - val_loss: 8.9567\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0998 - val_loss: 8.9495\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0925 - val_loss: 8.9419\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0850 - val_loss: 8.9346\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0777 - val_loss: 8.9274\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.0705 - val_loss: 8.9200\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.0631 - val_loss: 8.9126\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.0558 - val_loss: 8.9057\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.0488 - val_loss: 8.8985\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0418 - val_loss: 8.8913\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0346 - val_loss: 8.8842\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0276 - val_loss: 8.8771\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0206 - val_loss: 8.8699\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0135 - val_loss: 8.8629\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0065 - val_loss: 8.8561\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.9997 - val_loss: 8.8491\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.9928 - val_loss: 8.8422\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9858 - val_loss: 8.8352\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9790 - val_loss: 8.8283\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.9722 - val_loss: 8.8215\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9654 - val_loss: 8.8147\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.9586 - val_loss: 8.8080\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.9518 - val_loss: 8.8013\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.9452 - val_loss: 8.7945\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9383 - val_loss: 8.7877\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.9314 - val_loss: 8.7808\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.9245 - val_loss: 8.7743\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.9179 - val_loss: 8.7675\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.9110 - val_loss: 8.7609\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9044 - val_loss: 8.7541\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8976 - val_loss: 8.7476\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8909 - val_loss: 8.7409\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.8841 - val_loss: 8.7342\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8774 - val_loss: 8.7276\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8706 - val_loss: 8.7209\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.8639 - val_loss: 8.7143\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8572 - val_loss: 8.7077\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8505 - val_loss: 8.7013\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8442 - val_loss: 8.6950\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.8376 - val_loss: 8.6883\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.8310 - val_loss: 8.6818\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.8245 - val_loss: 8.6754\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.8181 - val_loss: 8.6690\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.8117 - val_loss: 8.6625\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.8052 - val_loss: 8.6563\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7989 - val_loss: 8.6500\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7926 - val_loss: 8.6434\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.7861 - val_loss: 8.6372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.7798 - val_loss: 8.6308\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7734 - val_loss: 8.6247\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.7673 - val_loss: 8.6187\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.7612 - val_loss: 8.6124\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.7550 - val_loss: 8.6063\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.7490 - val_loss: 8.6002\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7429 - val_loss: 8.5942\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.7370 - val_loss: 8.5881\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7309 - val_loss: 8.5818\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7247 - val_loss: 8.5758\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7187 - val_loss: 8.5695\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7125 - val_loss: 8.5635\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.7065 - val_loss: 8.5574\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7004 - val_loss: 8.5514\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.6943 - val_loss: 8.5453\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6883 - val_loss: 8.5394\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6825 - val_loss: 8.5335\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 10.20 - 0s 65us/sample - loss: 8.6766 - val_loss: 8.5278\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6709 - val_loss: 8.5219\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.6650 - val_loss: 8.5158\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.6591 - val_loss: 8.5101\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6534 - val_loss: 8.5043\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6476 - val_loss: 8.4985\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6419 - val_loss: 8.4927\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6360 - val_loss: 8.4869\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.6302 - val_loss: 8.4814\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.6247 - val_loss: 8.4756\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6189 - val_loss: 8.4697\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.6132 - val_loss: 8.4638\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6075 - val_loss: 8.4582\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.6018 - val_loss: 8.4527\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5963 - val_loss: 8.4469\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5907 - val_loss: 8.4414\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5853 - val_loss: 8.4357\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5797 - val_loss: 8.4301\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5741 - val_loss: 8.4244\n",
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5684 - val_loss: 8.4188\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.5629 - val_loss: 8.4134\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.5576 - val_loss: 8.4077\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5521 - val_loss: 8.4022\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.5467 - val_loss: 8.3968\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5414 - val_loss: 8.3914\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.5361 - val_loss: 8.3858\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5307 - val_loss: 8.3803\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.5256 - val_loss: 8.3748\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.5204 - val_loss: 8.3696\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5154 - val_loss: 8.3643\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5103 - val_loss: 8.3593\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5056 - val_loss: 8.3542\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.5006 - val_loss: 8.3489\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4956 - val_loss: 8.3434\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.4904 - val_loss: 8.3380\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4853 - val_loss: 8.3328\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.4804 - val_loss: 8.3277\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4754 - val_loss: 8.3226\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4705 - val_loss: 8.3175\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4656 - val_loss: 8.3123\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.4605 - val_loss: 8.3072\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4554 - val_loss: 8.3021\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4505 - val_loss: 8.2971\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4457 - val_loss: 8.2922\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4411 - val_loss: 8.2871\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.4362 - val_loss: 8.2819\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.4312 - val_loss: 8.2771\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4265 - val_loss: 8.2722\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.4217 - val_loss: 8.2672\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 54us/sample - loss: 8.4168 - val_loss: 8.2620\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4119 - val_loss: 8.2570\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.4070 - val_loss: 8.2520\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 8.4021 - val_loss: 8.2472\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 8.3975 - val_loss: 8.2423\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 8.3928 - val_loss: 8.2375\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3881 - val_loss: 8.2328\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.3835 - val_loss: 8.2279\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.3788 - val_loss: 8.2230\n",
      "Epoch 487/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.3740 - val_loss: 8.2183\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.3695 - val_loss: 8.2137\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.3650 - val_loss: 8.2090\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.3604 - val_loss: 8.2043\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.3558 - val_loss: 8.1999\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.3514 - val_loss: 8.1952\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.3469 - val_loss: 8.1906\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.3425 - val_loss: 8.1860\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.3382 - val_loss: 8.1815\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3338 - val_loss: 8.1767\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.3293 - val_loss: 8.1724\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3251 - val_loss: 8.1679\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.3207 - val_loss: 8.1633\n",
      "Epoch 500/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.3162 - val_loss: 8.1588\n",
      "594/594 [==============================] - 0s 32us/sample - loss: 8.2159\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=0, n_neurons=215, total=  45.0s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=0, n_neurons=215 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 293us/sample - loss: 14.0556 - val_loss: 13.7553\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 14.0343 - val_loss: 13.7342\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 14.0132 - val_loss: 13.7132\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 13.9921 - val_loss: 13.6923\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 13.9710 - val_loss: 13.6715\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.9499 - val_loss: 13.6506\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.9288 - val_loss: 13.6297\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.9077 - val_loss: 13.6089\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.8867 - val_loss: 13.5883\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.8657 - val_loss: 13.5678\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.8449 - val_loss: 13.5474\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.8241 - val_loss: 13.5270\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.8033 - val_loss: 13.5067\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.7825 - val_loss: 13.4862\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.7618 - val_loss: 13.4660\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.7411 - val_loss: 13.4457\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.7205 - val_loss: 13.4255\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 13.6998 - val_loss: 13.4052\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.6792 - val_loss: 13.3851\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 13.6587 - val_loss: 13.3649\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.6381 - val_loss: 13.3447\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.6177 - val_loss: 13.3245\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.5973 - val_loss: 13.3044\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.5769 - val_loss: 13.2844\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.5567 - val_loss: 13.2644\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.5366 - val_loss: 13.2445\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.5166 - val_loss: 13.2247\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.4966 - val_loss: 13.2049\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.4767 - val_loss: 13.1852\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.4568 - val_loss: 13.1655\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.4370 - val_loss: 13.1460\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.4172 - val_loss: 13.1265\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.3975 - val_loss: 13.1072\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.3778 - val_loss: 13.0880\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.3584 - val_loss: 13.0687\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.3387 - val_loss: 13.0494\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.3191 - val_loss: 13.0301\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.2995 - val_loss: 13.0110\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.2799 - val_loss: 12.9920\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.2604 - val_loss: 12.9733\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.2411 - val_loss: 12.9545\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.2216 - val_loss: 12.9356\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.2021 - val_loss: 12.9167\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.1826 - val_loss: 12.8979\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.1631 - val_loss: 12.8791\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.1436 - val_loss: 12.8606\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.1244 - val_loss: 12.8419\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.1049 - val_loss: 12.8232\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.0854 - val_loss: 12.8043\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.0660 - val_loss: 12.7857\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.0466 - val_loss: 12.7670\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.0273 - val_loss: 12.7484\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.0081 - val_loss: 12.7296\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.9889 - val_loss: 12.7111\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 12.9696 - val_loss: 12.6927\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.9507 - val_loss: 12.6741\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.9315 - val_loss: 12.6556\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.9124 - val_loss: 12.6371\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.8934 - val_loss: 12.6185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.8744 - val_loss: 12.6000\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.8555 - val_loss: 12.5814\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.8366 - val_loss: 12.5630\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.8178 - val_loss: 12.5446\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.7992 - val_loss: 12.5263\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.7805 - val_loss: 12.5083\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.7622 - val_loss: 12.4900\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.7437 - val_loss: 12.4719\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7255 - val_loss: 12.4537\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.7070 - val_loss: 12.4355\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.6886 - val_loss: 12.4175\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 12.6703 - val_loss: 12.3996\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.6521 - val_loss: 12.3817\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.6339 - val_loss: 12.3639\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.6156 - val_loss: 12.3461\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.5976 - val_loss: 12.3285\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.5796 - val_loss: 12.3109\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.5616 - val_loss: 12.2936\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.5439 - val_loss: 12.2762\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.5260 - val_loss: 12.2587\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.5081 - val_loss: 12.2418\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.4907 - val_loss: 12.2246\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 12.4729 - val_loss: 12.2075\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.4554 - val_loss: 12.1903\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.4377 - val_loss: 12.1731\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.4200 - val_loss: 12.1560\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.4023 - val_loss: 12.1389\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.3848 - val_loss: 12.1219\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.3672 - val_loss: 12.1049\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.3497 - val_loss: 12.0882\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.3324 - val_loss: 12.0712\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.3149 - val_loss: 12.0543\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.2975 - val_loss: 12.0378\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.2804 - val_loss: 12.0210\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.2630 - val_loss: 12.0042\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.2456 - val_loss: 11.9875\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.2284 - val_loss: 11.9708\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.2112 - val_loss: 11.9541\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.1940 - val_loss: 11.9375\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.1769 - val_loss: 11.9213\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.1601 - val_loss: 11.9049\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.1432 - val_loss: 11.8885\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.1264 - val_loss: 11.8722\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 12.1095 - val_loss: 11.8562\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.0929 - val_loss: 11.8403\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.0765 - val_loss: 11.8242\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.0600 - val_loss: 11.8081\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.0434 - val_loss: 11.7922\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.0270 - val_loss: 11.7761\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.0106 - val_loss: 11.7602\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.9943 - val_loss: 11.7442\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.9779 - val_loss: 11.7284\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.9615 - val_loss: 11.7127\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.9452 - val_loss: 11.6967\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.9290 - val_loss: 11.6810\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.9128 - val_loss: 11.6653\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.8967 - val_loss: 11.6496\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.8806 - val_loss: 11.6340\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.8645 - val_loss: 11.6183\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.8485 - val_loss: 11.6028\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.8325 - val_loss: 11.5871\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.8166 - val_loss: 11.5716\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.8007 - val_loss: 11.5563\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.7849 - val_loss: 11.5408\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.7690 - val_loss: 11.5254\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.7531 - val_loss: 11.5100\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.7373 - val_loss: 11.4948\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.7215 - val_loss: 11.4796\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.7058 - val_loss: 11.4642\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.6901 - val_loss: 11.4489\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.6745 - val_loss: 11.4339\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.6589 - val_loss: 11.4188\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.6433 - val_loss: 11.4039\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.6278 - val_loss: 11.3889\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.6124 - val_loss: 11.3743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.5971 - val_loss: 11.3594\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.5818 - val_loss: 11.3450\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.5668 - val_loss: 11.3305\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.5518 - val_loss: 11.3159\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.5366 - val_loss: 11.3017\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.5217 - val_loss: 11.2874\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.5067 - val_loss: 11.2730\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.4917 - val_loss: 11.2585\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.4765 - val_loss: 11.2442\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.4613 - val_loss: 11.2298\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.4461 - val_loss: 11.2156\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.4311 - val_loss: 11.2012\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.4160 - val_loss: 11.1867\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.4010 - val_loss: 11.1724\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3859 - val_loss: 11.1585\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3711 - val_loss: 11.1445\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.3563 - val_loss: 11.1307\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.3415 - val_loss: 11.1166\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.3266 - val_loss: 11.1027\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.3119 - val_loss: 11.0892\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.2976 - val_loss: 11.0752\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.2827 - val_loss: 11.0612\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.2679 - val_loss: 11.0472\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.2531 - val_loss: 11.0334\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.2386 - val_loss: 11.0197\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.2238 - val_loss: 11.0059\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.2091 - val_loss: 10.9923\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.1944 - val_loss: 10.9785\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.1797 - val_loss: 10.9654\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.1655 - val_loss: 10.9517\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.1509 - val_loss: 10.9384\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.1367 - val_loss: 10.9253\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.1224 - val_loss: 10.9120\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.1080 - val_loss: 10.8989\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.0936 - val_loss: 10.8857\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.0793 - val_loss: 10.8727\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.0652 - val_loss: 10.8594\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.0510 - val_loss: 10.8464\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.0370 - val_loss: 10.8335\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.0230 - val_loss: 10.8203\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.0089 - val_loss: 10.8071\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.9947 - val_loss: 10.7943\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.9808 - val_loss: 10.7813\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.9668 - val_loss: 10.7685\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.9529 - val_loss: 10.7559\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.9392 - val_loss: 10.7430\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.9252 - val_loss: 10.7304\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.9114 - val_loss: 10.7175\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.8976 - val_loss: 10.7049\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.8839 - val_loss: 10.6921\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.8701 - val_loss: 10.6796\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.8565 - val_loss: 10.6670\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.8428 - val_loss: 10.6547\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.8295 - val_loss: 10.6421\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.8158 - val_loss: 10.6299\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.8024 - val_loss: 10.6175\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.7891 - val_loss: 10.6051\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.7757 - val_loss: 10.5927\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.7621 - val_loss: 10.5804\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.7488 - val_loss: 10.5683\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.7356 - val_loss: 10.5561\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.7224 - val_loss: 10.5441\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.7093 - val_loss: 10.5321\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.6960 - val_loss: 10.5201\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.6827 - val_loss: 10.5081\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.6694 - val_loss: 10.4963\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.6564 - val_loss: 10.4844\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.6431 - val_loss: 10.4726\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.6300 - val_loss: 10.4611\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.6173 - val_loss: 10.4492\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.6043 - val_loss: 10.4375\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.5912 - val_loss: 10.4258\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.5782 - val_loss: 10.4139\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.5652 - val_loss: 10.4022\n",
      "Epoch 209/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.5522 - val_loss: 10.3906\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.5394 - val_loss: 10.3791\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.5266 - val_loss: 10.3675\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.5139 - val_loss: 10.3560\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.5012 - val_loss: 10.3445\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.4886 - val_loss: 10.3329\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4758 - val_loss: 10.3213\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.4631 - val_loss: 10.3097\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.4503 - val_loss: 10.2981\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.4377 - val_loss: 10.2866\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.4251 - val_loss: 10.2753\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.4127 - val_loss: 10.2638\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.4002 - val_loss: 10.2527\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 10.3882 - val_loss: 10.2414\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.3759 - val_loss: 10.2300\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 10.3636 - val_loss: 10.2189\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.3515 - val_loss: 10.2078\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.3393 - val_loss: 10.1967\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.3271 - val_loss: 10.1858\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.3150 - val_loss: 10.1751\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.3033 - val_loss: 10.1641\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.2912 - val_loss: 10.1538\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.2797 - val_loss: 10.1432\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.2680 - val_loss: 10.1325\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.2561 - val_loss: 10.1218\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.2442 - val_loss: 10.1110\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.2323 - val_loss: 10.1002\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.2202 - val_loss: 10.0896\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2083 - val_loss: 10.0788\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.1963 - val_loss: 10.0682\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.1844 - val_loss: 10.0576\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1727 - val_loss: 10.0472\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.1612 - val_loss: 10.0367\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.1495 - val_loss: 10.0264\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 10.1381 - val_loss: 10.0157\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1263 - val_loss: 10.0053\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.1146 - val_loss: 9.9948\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.1031 - val_loss: 9.9841\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.0913 - val_loss: 9.9739\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.0799 - val_loss: 9.9632\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0683 - val_loss: 9.9529\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.0568 - val_loss: 9.9424\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.0454 - val_loss: 9.9320\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.0339 - val_loss: 9.9214\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.0223 - val_loss: 9.9109\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.0107 - val_loss: 9.9006\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.9993 - val_loss: 9.8905\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.9880 - val_loss: 9.8801\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.9768 - val_loss: 9.8698\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.9653 - val_loss: 9.8596\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.9539 - val_loss: 9.8495\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.9428 - val_loss: 9.8392\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.9312 - val_loss: 9.8288\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.9199 - val_loss: 9.8187\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.9088 - val_loss: 9.8088\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.8980 - val_loss: 9.7987\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.8870 - val_loss: 9.7887\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.8760 - val_loss: 9.7788\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.8652 - val_loss: 9.7688\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.8542 - val_loss: 9.7588\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8435 - val_loss: 9.7488\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.8327 - val_loss: 9.7389\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.8220 - val_loss: 9.7290\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.8114 - val_loss: 9.7194\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.8011 - val_loss: 9.7098\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.7907 - val_loss: 9.7000\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.7802 - val_loss: 9.6905\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.7699 - val_loss: 9.6810\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.7596 - val_loss: 9.6714\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.7493 - val_loss: 9.6618\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.7391 - val_loss: 9.6523\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.7286 - val_loss: 9.6426\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.7182 - val_loss: 9.6332\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.7081 - val_loss: 9.6239\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.6980 - val_loss: 9.6144\n",
      "Epoch 284/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.6877 - val_loss: 9.6050\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.6775 - val_loss: 9.5955\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.6672 - val_loss: 9.5865\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.6573 - val_loss: 9.5774\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.6475 - val_loss: 9.5680\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.6375 - val_loss: 9.5585\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.6275 - val_loss: 9.5493\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 10.50 - 0s 66us/sample - loss: 9.6176 - val_loss: 9.5404\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.6080 - val_loss: 9.5313\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.5982 - val_loss: 9.5223\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5884 - val_loss: 9.5135\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.5790 - val_loss: 9.5044\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5694 - val_loss: 9.4958\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.5601 - val_loss: 9.4870\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.5508 - val_loss: 9.4782\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5414 - val_loss: 9.4695\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.5320 - val_loss: 9.4609\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.5227 - val_loss: 9.4522\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.5134 - val_loss: 9.4435\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5041 - val_loss: 9.4348\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.4947 - val_loss: 9.4263\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.4856 - val_loss: 9.4177\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.4763 - val_loss: 9.4092\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.4672 - val_loss: 9.4009\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.4583 - val_loss: 9.3925\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4493 - val_loss: 9.3841\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.4405 - val_loss: 9.3757\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.4317 - val_loss: 9.3673\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.4229 - val_loss: 9.3590\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4140 - val_loss: 9.3508\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.4052 - val_loss: 9.3425\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3964 - val_loss: 9.3342\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3876 - val_loss: 9.3265\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3794 - val_loss: 9.3181\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.3704 - val_loss: 9.3097\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3615 - val_loss: 9.3011\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.3525 - val_loss: 9.2930\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.3438 - val_loss: 9.2850\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3352 - val_loss: 9.2770\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.3267 - val_loss: 9.2690\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3182 - val_loss: 9.2612\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.3097 - val_loss: 9.2530\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.3011 - val_loss: 9.2449\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.2923 - val_loss: 9.2368\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.2836 - val_loss: 9.2288\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.2751 - val_loss: 9.2206\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.2663 - val_loss: 9.2125\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.2576 - val_loss: 9.2044\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.2489 - val_loss: 9.1963\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.2402 - val_loss: 9.1882\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.2318 - val_loss: 9.1803\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.2232 - val_loss: 9.1722\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.2146 - val_loss: 9.1642\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2061 - val_loss: 9.1561\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.1975 - val_loss: 9.1480\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.1890 - val_loss: 9.1399\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.1804 - val_loss: 9.1320\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1721 - val_loss: 9.1241\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.1638 - val_loss: 9.1161\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.1554 - val_loss: 9.1083\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.1473 - val_loss: 9.1004\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.1392 - val_loss: 9.0927\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.1312 - val_loss: 9.0849\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1232 - val_loss: 9.0773\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.1153 - val_loss: 9.0697\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.1073 - val_loss: 9.0619\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.0992 - val_loss: 9.0541\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0911 - val_loss: 9.0467\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.0832 - val_loss: 9.0393\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.0756 - val_loss: 9.0316\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.0677 - val_loss: 9.0243\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0601 - val_loss: 9.0167\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.0521 - val_loss: 9.0090\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.0441 - val_loss: 9.0016\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.0364 - val_loss: 8.9940\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0285 - val_loss: 8.9866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.0208 - val_loss: 8.9791\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0129 - val_loss: 8.9714\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0050 - val_loss: 8.9640\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9971 - val_loss: 8.9566\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.9893 - val_loss: 8.9491\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.9813 - val_loss: 8.9420\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9738 - val_loss: 8.9347\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9662 - val_loss: 8.9274\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9585 - val_loss: 8.9202\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9508 - val_loss: 8.9127\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9428 - val_loss: 8.9051\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.9349 - val_loss: 8.8979\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.9272 - val_loss: 8.8906\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9194 - val_loss: 8.8832\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9116 - val_loss: 8.8759\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9039 - val_loss: 8.8688\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.8964 - val_loss: 8.8620\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.8892 - val_loss: 8.8549\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.8817 - val_loss: 8.8480\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.8743 - val_loss: 8.8409\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.8666 - val_loss: 8.8338\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.8590 - val_loss: 8.8268\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8515 - val_loss: 8.8196\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8439 - val_loss: 8.8127\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8364 - val_loss: 8.8059\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8292 - val_loss: 8.7990\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.8216 - val_loss: 8.7921\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8142 - val_loss: 8.7852\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.8068 - val_loss: 8.7782\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7994 - val_loss: 8.7713\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7919 - val_loss: 8.7648\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7850 - val_loss: 8.7580\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7777 - val_loss: 8.7512\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.7704 - val_loss: 8.7444\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.7632 - val_loss: 8.7381\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 8.7562 - val_loss: 8.7313\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7489 - val_loss: 8.7245\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.7416 - val_loss: 8.7177\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7342 - val_loss: 8.7111\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7270 - val_loss: 8.7042\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.7196 - val_loss: 8.6977\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.7124 - val_loss: 8.6913\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.7056 - val_loss: 8.6848\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.6986 - val_loss: 8.6783\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6915 - val_loss: 8.6716\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.6844 - val_loss: 8.6653\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6775 - val_loss: 8.6588\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6705 - val_loss: 8.6522\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.6633 - val_loss: 8.6458\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6563 - val_loss: 8.6393\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.6493 - val_loss: 8.6326\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.6422 - val_loss: 8.6261\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.6351 - val_loss: 8.6196\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6281 - val_loss: 8.6133\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.6213 - val_loss: 8.6072\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.6147 - val_loss: 8.6009\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.6080 - val_loss: 8.5945\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6011 - val_loss: 8.5882\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.5944 - val_loss: 8.5819\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.5878 - val_loss: 8.5757\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5811 - val_loss: 8.5696\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5745 - val_loss: 8.5632\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.5677 - val_loss: 8.5569\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5610 - val_loss: 8.5507\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.5543 - val_loss: 8.5444\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.5476 - val_loss: 8.5384\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5411 - val_loss: 8.5324\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.5346 - val_loss: 8.5265\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.5283 - val_loss: 8.5206\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5219 - val_loss: 8.5148\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.5154 - val_loss: 8.5090\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5091 - val_loss: 8.5032\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5028 - val_loss: 8.4976\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.4969 - val_loss: 8.4918\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.4906 - val_loss: 8.4861\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4845 - val_loss: 8.4803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 8.4781 - val_loss: 8.4746\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.4720 - val_loss: 8.4691\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4659 - val_loss: 8.4636\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 111us/sample - loss: 8.4600 - val_loss: 8.4577\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 8.4537 - val_loss: 8.4522\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.4477 - val_loss: 8.4464\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.4414 - val_loss: 8.4406\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.4352 - val_loss: 8.4349\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4291 - val_loss: 8.4295\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 8.4231 - val_loss: 8.4240\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.4172 - val_loss: 8.4183\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 8.4110 - val_loss: 8.4129\n",
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.4049 - val_loss: 8.4073\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3990 - val_loss: 8.4018\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3929 - val_loss: 8.3963\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3868 - val_loss: 8.3907\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.3809 - val_loss: 8.3853\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.3749 - val_loss: 8.3798\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.3690 - val_loss: 8.3744\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.3631 - val_loss: 8.3691\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.3574 - val_loss: 8.3637\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.3515 - val_loss: 8.3584\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3456 - val_loss: 8.3530\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.3398 - val_loss: 8.3477\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.3341 - val_loss: 8.3422\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.3282 - val_loss: 8.3369\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.3225 - val_loss: 8.3315\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.3166 - val_loss: 8.3261\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.3108 - val_loss: 8.3210\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.3052 - val_loss: 8.3155\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.2994 - val_loss: 8.3104\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2939 - val_loss: 8.3050\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2881 - val_loss: 8.2996\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.2824 - val_loss: 8.2944\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.2766 - val_loss: 8.2891\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.2711 - val_loss: 8.2839\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.2655 - val_loss: 8.2786\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.2600 - val_loss: 8.2734\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.2545 - val_loss: 8.2680\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.2490 - val_loss: 8.2630\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.2437 - val_loss: 8.2578\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.2382 - val_loss: 8.2529\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.2330 - val_loss: 8.2476\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2274 - val_loss: 8.2427\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2223 - val_loss: 8.2374\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.2167 - val_loss: 8.2322\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.2112 - val_loss: 8.2269\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.2057 - val_loss: 8.2218\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.2002 - val_loss: 8.2170\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.1950 - val_loss: 8.2120\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.1895 - val_loss: 8.2070\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1842 - val_loss: 8.2022\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.1791 - val_loss: 8.1973\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 8.677 - 0s 67us/sample - loss: 8.1738 - val_loss: 8.1924\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1686 - val_loss: 8.1876\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.1633 - val_loss: 8.1829\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.1583 - val_loss: 8.1778\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1530 - val_loss: 8.1728\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.1476 - val_loss: 8.1681\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.1426 - val_loss: 8.1634\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.1374 - val_loss: 8.1585\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1323 - val_loss: 8.1537\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1273 - val_loss: 8.1490\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.1222 - val_loss: 8.1442\n",
      "Epoch 500/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1170 - val_loss: 8.1394\n",
      "594/594 [==============================] - 0s 43us/sample - loss: 8.5559\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=0, n_neurons=215, total=  44.8s\n",
      "[CV] learning_rate=0.0006154014789262348, n_hidden=0, n_neurons=215 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 284us/sample - loss: 13.9351 - val_loss: 13.7331\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.9149 - val_loss: 13.7118\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.8942 - val_loss: 13.6905\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.8735 - val_loss: 13.6692\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.8528 - val_loss: 13.6480\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.8321 - val_loss: 13.6266\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.8115 - val_loss: 13.6054\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 13.7910 - val_loss: 13.5843\n",
      "Epoch 9/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.7705 - val_loss: 13.5635\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.7501 - val_loss: 13.5427\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.7298 - val_loss: 13.5220\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.7096 - val_loss: 13.5013\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.6893 - val_loss: 13.4807\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 1s 462us/sample - loss: 13.6691 - val_loss: 13.4604\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.6493 - val_loss: 13.4400\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 13.6295 - val_loss: 13.4197\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.6095 - val_loss: 13.3994\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 13.5895 - val_loss: 13.3793\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 13.5698 - val_loss: 13.3592\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.5501 - val_loss: 13.3392\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.5304 - val_loss: 13.3191\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.5109 - val_loss: 13.2993\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.4914 - val_loss: 13.2793\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.4719 - val_loss: 13.2595\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.4525 - val_loss: 13.2397\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.4331 - val_loss: 13.2199\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.4136 - val_loss: 13.2001\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.3943 - val_loss: 13.1804\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.3750 - val_loss: 13.1611\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.3556 - val_loss: 13.1416\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.3365 - val_loss: 13.1225\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.3176 - val_loss: 13.1032\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.2985 - val_loss: 13.0839\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.2794 - val_loss: 13.0650\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.2606 - val_loss: 13.0459\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.2416 - val_loss: 13.0271\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.2229 - val_loss: 13.0080\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.2040 - val_loss: 12.9889\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.1852 - val_loss: 12.9699\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.1663 - val_loss: 12.9512\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.1478 - val_loss: 12.9324\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.1290 - val_loss: 12.9139\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.1105 - val_loss: 12.8955\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.0920 - val_loss: 12.8769\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.0733 - val_loss: 12.8582\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.0546 - val_loss: 12.8397\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.0360 - val_loss: 12.8211\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.0174 - val_loss: 12.8026\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.9990 - val_loss: 12.7845\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.9809 - val_loss: 12.7661\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.9626 - val_loss: 12.7478\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.9442 - val_loss: 12.7294\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.9259 - val_loss: 12.7111\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.9075 - val_loss: 12.6929\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.8891 - val_loss: 12.6747\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.8707 - val_loss: 12.6566\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.8524 - val_loss: 12.6386\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.8344 - val_loss: 12.6205\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.8164 - val_loss: 12.6025\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7985 - val_loss: 12.5846\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7807 - val_loss: 12.5667\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.7629 - val_loss: 12.5494\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7458 - val_loss: 12.5320\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7286 - val_loss: 12.5145\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.7114 - val_loss: 12.4969\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.6939 - val_loss: 12.4793\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.6765 - val_loss: 12.4616\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.6593 - val_loss: 12.4443\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.6420 - val_loss: 12.4271\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 12.6250 - val_loss: 12.4099\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.6080 - val_loss: 12.3925\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.5909 - val_loss: 12.3751\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.5738 - val_loss: 12.3580\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.5570 - val_loss: 12.3410\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.5402 - val_loss: 12.3238\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.5231 - val_loss: 12.3065\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.5062 - val_loss: 12.2896\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.4894 - val_loss: 12.2726\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.4726 - val_loss: 12.2556\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.4557 - val_loss: 12.2391\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.4393 - val_loss: 12.2222\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.4224 - val_loss: 12.2059\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.4063 - val_loss: 12.1888\n",
      "Epoch 84/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.3895 - val_loss: 12.1719\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.3727 - val_loss: 12.1550\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.3560 - val_loss: 12.1382\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.3393 - val_loss: 12.1214\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.3226 - val_loss: 12.1046\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.3059 - val_loss: 12.0880\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.2894 - val_loss: 12.0716\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.2732 - val_loss: 12.0549\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.2569 - val_loss: 12.0384\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.2406 - val_loss: 12.0218\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.2244 - val_loss: 12.0054\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.2082 - val_loss: 11.9890\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.1920 - val_loss: 11.9729\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.1762 - val_loss: 11.9564\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.1600 - val_loss: 11.9400\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.1439 - val_loss: 11.9236\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.1277 - val_loss: 11.9074\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.1117 - val_loss: 11.8911\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.0957 - val_loss: 11.8749\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.0797 - val_loss: 11.8588\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.0637 - val_loss: 11.8428\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.0478 - val_loss: 11.8268\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.0319 - val_loss: 11.8110\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.0160 - val_loss: 11.7953\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.0002 - val_loss: 11.7796\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.9844 - val_loss: 11.7639\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.9687 - val_loss: 11.7484\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.9533 - val_loss: 11.7327\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.9377 - val_loss: 11.7171\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.9223 - val_loss: 11.7014\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.9068 - val_loss: 11.6860\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.8913 - val_loss: 11.6705\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.8758 - val_loss: 11.6552\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.8605 - val_loss: 11.6399\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.8453 - val_loss: 11.6249\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.8306 - val_loss: 11.6101\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.8157 - val_loss: 11.5949\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.8007 - val_loss: 11.5799\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.7858 - val_loss: 11.5651\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.7711 - val_loss: 11.5500\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.7563 - val_loss: 11.5353\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.7416 - val_loss: 11.5203\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.7268 - val_loss: 11.5052\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.7119 - val_loss: 11.4908\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.6976 - val_loss: 11.4758\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.6829 - val_loss: 11.4609\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.6682 - val_loss: 11.4461\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.6535 - val_loss: 11.4314\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.6389 - val_loss: 11.4168\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.6243 - val_loss: 11.4023\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.6098 - val_loss: 11.3880\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.5954 - val_loss: 11.3734\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.5809 - val_loss: 11.3592\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.5666 - val_loss: 11.3450\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 55us/sample - loss: 11.5524 - val_loss: 11.3305\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.5381 - val_loss: 11.3166\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.5243 - val_loss: 11.3025\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.5103 - val_loss: 11.2882\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.4962 - val_loss: 11.2740\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.4821 - val_loss: 11.2599\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.4681 - val_loss: 11.2459\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.4542 - val_loss: 11.2319\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.4404 - val_loss: 11.2183\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.4267 - val_loss: 11.2043\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.4130 - val_loss: 11.1906\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3992 - val_loss: 11.1770\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.3857 - val_loss: 11.1637\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.3725 - val_loss: 11.1502\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3590 - val_loss: 11.1365\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.3454 - val_loss: 11.1231\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3320 - val_loss: 11.1101\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.3188 - val_loss: 11.0964\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.3052 - val_loss: 11.0830\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.2915 - val_loss: 11.0695\n",
      "Epoch 158/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.2779 - val_loss: 11.0560\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.2643 - val_loss: 11.0426\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.2509 - val_loss: 11.0293\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.2374 - val_loss: 11.0163\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.2242 - val_loss: 11.0029\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.2108 - val_loss: 10.9899\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.1976 - val_loss: 10.9765\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.1843 - val_loss: 10.9635\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.1712 - val_loss: 10.9503\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.1580 - val_loss: 10.9370\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.1448 - val_loss: 10.9240\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.1317 - val_loss: 10.9111\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.1188 - val_loss: 10.8981\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.1057 - val_loss: 10.8850\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.0926 - val_loss: 10.8720\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.0795 - val_loss: 10.8592\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.0667 - val_loss: 10.8461\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.0537 - val_loss: 10.8332\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.0409 - val_loss: 10.8207\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.0282 - val_loss: 10.8079\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.0152 - val_loss: 10.7953\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.0024 - val_loss: 10.7824\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.9894 - val_loss: 10.7697\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.9767 - val_loss: 10.7572\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.9641 - val_loss: 10.7445\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.9514 - val_loss: 10.7318\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.9387 - val_loss: 10.7191\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.9260 - val_loss: 10.7068\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.9135 - val_loss: 10.6945\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.9011 - val_loss: 10.6822\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.8888 - val_loss: 10.6700\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.8764 - val_loss: 10.6581\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.8643 - val_loss: 10.6461\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.8522 - val_loss: 10.6341\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.8401 - val_loss: 10.6221\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.8278 - val_loss: 10.6100\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.8156 - val_loss: 10.5983\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.8035 - val_loss: 10.5864\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.7914 - val_loss: 10.5745\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.7793 - val_loss: 10.5626\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.7672 - val_loss: 10.5505\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.7549 - val_loss: 10.5385\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.7426 - val_loss: 10.5265\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.7305 - val_loss: 10.5148\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.7186 - val_loss: 10.5030\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.7066 - val_loss: 10.4916\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.6949 - val_loss: 10.4801\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.6832 - val_loss: 10.4685\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.6712 - val_loss: 10.4568\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.6592 - val_loss: 10.4454\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.6475 - val_loss: 10.4338\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.6356 - val_loss: 10.4224\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.6240 - val_loss: 10.4109\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.6122 - val_loss: 10.3996\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.6007 - val_loss: 10.3887\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.5894 - val_loss: 10.3776\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.5780 - val_loss: 10.3664\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.5665 - val_loss: 10.3555\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.5552 - val_loss: 10.3443\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.5438 - val_loss: 10.3333\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.5327 - val_loss: 10.3222\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.5213 - val_loss: 10.3114\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.5102 - val_loss: 10.3003\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4990 - val_loss: 10.2893\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4878 - val_loss: 10.2786\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.4768 - val_loss: 10.2677\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.4657 - val_loss: 10.2569\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.4548 - val_loss: 10.2464\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.4440 - val_loss: 10.2357\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.4331 - val_loss: 10.2253\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.4226 - val_loss: 10.2151\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4121 - val_loss: 10.2045\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.4014 - val_loss: 10.1942\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 10.3908 - val_loss: 10.1840\n",
      "Epoch 232/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.3804 - val_loss: 10.1739\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.3698 - val_loss: 10.1639\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.3595 - val_loss: 10.1537\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.3490 - val_loss: 10.1434\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.3383 - val_loss: 10.1334\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.3279 - val_loss: 10.1234\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.3175 - val_loss: 10.1136\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.3074 - val_loss: 10.1035\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.2970 - val_loss: 10.0937\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.2868 - val_loss: 10.0837\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.2763 - val_loss: 10.0738\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.2661 - val_loss: 10.0637\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.2556 - val_loss: 10.0537\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.2452 - val_loss: 10.0438\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.2350 - val_loss: 10.0339\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.2249 - val_loss: 10.0243\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.2148 - val_loss: 10.0145\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.2047 - val_loss: 10.0046\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.1944 - val_loss: 9.9947\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.1842 - val_loss: 9.9851\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.1740 - val_loss: 9.9754\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.1642 - val_loss: 9.9658\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.1543 - val_loss: 9.9565\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.1446 - val_loss: 9.9470\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.1346 - val_loss: 9.9376\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.1249 - val_loss: 9.9282\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.1151 - val_loss: 9.9187\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.1053 - val_loss: 9.9095\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.0959 - val_loss: 9.9002\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.0863 - val_loss: 9.8911\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.0769 - val_loss: 9.8820\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0675 - val_loss: 9.8729\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.0582 - val_loss: 9.8636\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.0487 - val_loss: 9.8544\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.0392 - val_loss: 9.8452\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0298 - val_loss: 9.8361\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.0204 - val_loss: 9.8271\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0114 - val_loss: 9.8179\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.0022 - val_loss: 9.8090\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.9931 - val_loss: 9.7999\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.9838 - val_loss: 9.7911\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.9750 - val_loss: 9.7821\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.9658 - val_loss: 9.7730\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.9566 - val_loss: 9.7641\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.9475 - val_loss: 9.7551\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.9387 - val_loss: 9.7461\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.9297 - val_loss: 9.7373\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.9208 - val_loss: 9.7285\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.9121 - val_loss: 9.7196\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.9033 - val_loss: 9.7109\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.8945 - val_loss: 9.7022\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.8859 - val_loss: 9.6935\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.8773 - val_loss: 9.6847\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8685 - val_loss: 9.6760\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.8599 - val_loss: 9.6673\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.8514 - val_loss: 9.6589\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.8430 - val_loss: 9.6503\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8344 - val_loss: 9.6417\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.8259 - val_loss: 9.6331\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.8174 - val_loss: 9.6249\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.8091 - val_loss: 9.6164\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.8007 - val_loss: 9.6080\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7921 - val_loss: 9.5994\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.7835 - val_loss: 9.5910\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.7751 - val_loss: 9.5828\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.7668 - val_loss: 9.5742\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.7582 - val_loss: 9.5656\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7496 - val_loss: 9.5570\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7410 - val_loss: 9.5486\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7326 - val_loss: 9.5401\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.7241 - val_loss: 9.5316\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.7156 - val_loss: 9.5233\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.7073 - val_loss: 9.5148\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.6990 - val_loss: 9.5063\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.6905 - val_loss: 9.4979\n",
      "Epoch 307/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6822 - val_loss: 9.4897\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.6740 - val_loss: 9.4812\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.6656 - val_loss: 9.4728\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6572 - val_loss: 9.4646\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.6491 - val_loss: 9.4567\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6411 - val_loss: 9.4484\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.6330 - val_loss: 9.4406\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6252 - val_loss: 9.4323\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.6169 - val_loss: 9.4240\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.6086 - val_loss: 9.4159\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.6004 - val_loss: 9.4076\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.5921 - val_loss: 9.3996\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5840 - val_loss: 9.3913\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5758 - val_loss: 9.3831\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 180us/sample - loss: 9.5676 - val_loss: 9.3748\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.5594 - val_loss: 9.3668\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5514 - val_loss: 9.3589\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.5435 - val_loss: 9.3510\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.5356 - val_loss: 9.3428\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.5274 - val_loss: 9.3349\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.5193 - val_loss: 9.3269\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.5113 - val_loss: 9.3188\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.5032 - val_loss: 9.3110\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.4952 - val_loss: 9.3032\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.4875 - val_loss: 9.2953\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.4796 - val_loss: 9.2875\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4717 - val_loss: 9.2796\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.4639 - val_loss: 9.2721\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.4564 - val_loss: 9.2641\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.4484 - val_loss: 9.2560\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.4404 - val_loss: 9.2480\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.4325 - val_loss: 9.2400\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4246 - val_loss: 9.2320\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4167 - val_loss: 9.2245\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4092 - val_loss: 9.2167\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.4015 - val_loss: 9.2093\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.3941 - val_loss: 9.2015\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3862 - val_loss: 9.1937\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3784 - val_loss: 9.1860\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.3706 - val_loss: 9.1782\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3627 - val_loss: 9.1702\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3548 - val_loss: 9.1626\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.3471 - val_loss: 9.1549\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.3394 - val_loss: 9.1474\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3317 - val_loss: 9.1396\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.3239 - val_loss: 9.1322\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.3164 - val_loss: 9.1244\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3086 - val_loss: 9.1170\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.3011 - val_loss: 9.1093\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.2934 - val_loss: 9.1016\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.2857 - val_loss: 9.0943\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.2784 - val_loss: 9.0867\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.2708 - val_loss: 9.0795\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.2635 - val_loss: 9.0723\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.2563 - val_loss: 9.0648\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.2488 - val_loss: 9.0575\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.2415 - val_loss: 9.0501\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.2339 - val_loss: 9.0430\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.2267 - val_loss: 9.0358\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.2193 - val_loss: 9.0289\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.2122 - val_loss: 9.0217\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.2050 - val_loss: 9.0147\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1978 - val_loss: 9.0076\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.1906 - val_loss: 9.0003\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1833 - val_loss: 8.9932\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1762 - val_loss: 8.9862\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1690 - val_loss: 8.9790\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.1617 - val_loss: 8.9718\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.1545 - val_loss: 8.9648\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.1474 - val_loss: 8.9581\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1405 - val_loss: 8.9512\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.1335 - val_loss: 8.9443\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.1264 - val_loss: 8.9374\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1193 - val_loss: 8.9305\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.1122 - val_loss: 8.9236\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.1051 - val_loss: 8.9166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.0980 - val_loss: 8.9097\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.0910 - val_loss: 8.9028\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.0839 - val_loss: 8.8960\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.0768 - val_loss: 8.8893\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0699 - val_loss: 8.8825\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 9.0629 - val_loss: 8.8758\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0561 - val_loss: 8.8690\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0491 - val_loss: 8.8626\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0424 - val_loss: 8.8560\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0356 - val_loss: 8.8492\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.0286 - val_loss: 8.8426\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0219 - val_loss: 8.8363\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0154 - val_loss: 8.8296\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0087 - val_loss: 8.8230\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.0020 - val_loss: 8.8164\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9953 - val_loss: 8.8101\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9890 - val_loss: 8.8034\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.9823 - val_loss: 8.7970\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.9757 - val_loss: 8.7908\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9692 - val_loss: 8.7844\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.9626 - val_loss: 8.7778\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9559 - val_loss: 8.7713\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.9492 - val_loss: 8.7650\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.9427 - val_loss: 8.7585\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.9361 - val_loss: 8.7522\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9295 - val_loss: 8.7457\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9228 - val_loss: 8.7392\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.9162 - val_loss: 8.7330\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 8.9098 - val_loss: 8.7268\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.9033 - val_loss: 8.7207\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.8968 - val_loss: 8.7144\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.8904 - val_loss: 8.7083\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.8840 - val_loss: 8.7020\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.8776 - val_loss: 8.6958\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.8710 - val_loss: 8.6896\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8647 - val_loss: 8.6836\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.8585 - val_loss: 8.6774\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8521 - val_loss: 8.6714\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8457 - val_loss: 8.6652\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8394 - val_loss: 8.6591\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8330 - val_loss: 8.6530\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.8268 - val_loss: 8.6471\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.8205 - val_loss: 8.6412\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8144 - val_loss: 8.6350\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.8080 - val_loss: 8.6292\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.8021 - val_loss: 8.6233\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.7960 - val_loss: 8.6175\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 8.789 - 0s 73us/sample - loss: 8.7899 - val_loss: 8.6115\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.7837 - val_loss: 8.6058\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7778 - val_loss: 8.6000\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7719 - val_loss: 8.5941\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.7659 - val_loss: 8.5883\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.7598 - val_loss: 8.5823\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.7538 - val_loss: 8.5765\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.7479 - val_loss: 8.5707\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.7419 - val_loss: 8.5651\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7362 - val_loss: 8.5595\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.7303 - val_loss: 8.5540\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.7246 - val_loss: 8.5483\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7187 - val_loss: 8.5426\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7129 - val_loss: 8.5371\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.7073 - val_loss: 8.5316\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.7016 - val_loss: 8.5264\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.6961 - val_loss: 8.5209\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6905 - val_loss: 8.5156\n",
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6850 - val_loss: 8.5103\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.6795 - val_loss: 8.5050\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.6740 - val_loss: 8.4995\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.6683 - val_loss: 8.4942\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6630 - val_loss: 8.4888\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6575 - val_loss: 8.4833\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.6519 - val_loss: 8.4782\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6467 - val_loss: 8.4728\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.6412 - val_loss: 8.4673\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6356 - val_loss: 8.4619\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.6302 - val_loss: 8.4565\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.6247 - val_loss: 8.4510\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.6192 - val_loss: 8.4457\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.6138 - val_loss: 8.4405\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6085 - val_loss: 8.4350\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6030 - val_loss: 8.4298\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.5977 - val_loss: 8.4246\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.5925 - val_loss: 8.4193\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.5870 - val_loss: 8.4141\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.5817 - val_loss: 8.4087\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.5764 - val_loss: 8.4034\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.5711 - val_loss: 8.3982\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.5658 - val_loss: 8.3929\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.5605 - val_loss: 8.3875\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 8.5552 - val_loss: 8.3823\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5501 - val_loss: 8.3774\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.5451 - val_loss: 8.3722\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.5399 - val_loss: 8.3672\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 8.5350 - val_loss: 8.3622\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.5300 - val_loss: 8.3575\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.5253 - val_loss: 8.3525\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.5204 - val_loss: 8.3477\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5157 - val_loss: 8.3426\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.5106 - val_loss: 8.3375\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.5056 - val_loss: 8.3324\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5005 - val_loss: 8.3275\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4957 - val_loss: 8.3226\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.4910 - val_loss: 8.3176\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.4861 - val_loss: 8.3126\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.4812 - val_loss: 8.3079\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 8.4765 - val_loss: 8.3029\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.4715 - val_loss: 8.2980\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.4668 - val_loss: 8.2933\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.4621 - val_loss: 8.2883\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 8.4573 - val_loss: 8.2833\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.4524 - val_loss: 8.2784\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 8.4477 - val_loss: 8.2737\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 8.4431 - val_loss: 8.2689\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.4384 - val_loss: 8.2642\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 8.4338 - val_loss: 8.2593\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 8.4291 - val_loss: 8.2546\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.4244 - val_loss: 8.2497\n",
      "Epoch 500/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 8.4197 - val_loss: 8.2451\n",
      "594/594 [==============================] - 0s 41us/sample - loss: 8.3234\n",
      "[CV]  learning_rate=0.0006154014789262348, n_hidden=0, n_neurons=215, total=  45.8s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=1, n_neurons=373 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 361us/sample - loss: 14.0571 - val_loss: 13.7306\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 104us/sample - loss: 13.9840 - val_loss: 13.6580\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 13.9124 - val_loss: 13.5872\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 13.8422 - val_loss: 13.5169\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 13.7726 - val_loss: 13.4465\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 13.7020 - val_loss: 13.3766\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 13.6331 - val_loss: 13.3085\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 114us/sample - loss: 13.5665 - val_loss: 13.2410\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 116us/sample - loss: 13.5005 - val_loss: 13.1736\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 13.4347 - val_loss: 13.1063\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 13.3692 - val_loss: 13.0400\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 109us/sample - loss: 13.3049 - val_loss: 12.9738\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 13.2413 - val_loss: 12.9085\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 13.1781 - val_loss: 12.8432\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 13.1149 - val_loss: 12.7781\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 13.0519 - val_loss: 12.7131\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 12.9902 - val_loss: 12.6494\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 12.9295 - val_loss: 12.5861\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 12.8688 - val_loss: 12.5242\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 12.8094 - val_loss: 12.4610\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 12.7489 - val_loss: 12.3986\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 12.6891 - val_loss: 12.3375\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 12.6299 - val_loss: 12.2762\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 109us/sample - loss: 12.5706 - val_loss: 12.2138\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 12.5104 - val_loss: 12.1520\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 12.4506 - val_loss: 12.0906\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 12.3906 - val_loss: 12.0299\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 12.3311 - val_loss: 11.9705\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 12.2727 - val_loss: 11.9116\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 12.2147 - val_loss: 11.8514\n",
      "Epoch 31/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 94us/sample - loss: 12.1556 - val_loss: 11.7913\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 12.0965 - val_loss: 11.7326\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 12.0390 - val_loss: 11.6727\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 11.9805 - val_loss: 11.6136\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 11.9231 - val_loss: 11.5541\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 11.8654 - val_loss: 11.4957\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.8087 - val_loss: 11.4368\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 11.7515 - val_loss: 11.3786\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.6944 - val_loss: 11.3203\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.6375 - val_loss: 11.2625\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.5806 - val_loss: 11.2048\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.5238 - val_loss: 11.1471\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 11.4665 - val_loss: 11.0908\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 11.4103 - val_loss: 11.0346\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.3544 - val_loss: 10.9782\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.2986 - val_loss: 10.9219\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.2428 - val_loss: 10.8667\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.1875 - val_loss: 10.8103\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.1313 - val_loss: 10.7529\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.0740 - val_loss: 10.6949\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.0162 - val_loss: 10.6392\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.9600 - val_loss: 10.5827\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.9025 - val_loss: 10.5286\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 10.8466 - val_loss: 10.4729\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 10.7887 - val_loss: 10.4185\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 10.7321 - val_loss: 10.3640\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.6757 - val_loss: 10.3089\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.6191 - val_loss: 10.2551\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.5634 - val_loss: 10.2006\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.5066 - val_loss: 10.1466\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.4499 - val_loss: 10.0937\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.3931 - val_loss: 10.0418\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.3376 - val_loss: 9.9895\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 10.2820 - val_loss: 9.9377\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.2270 - val_loss: 9.8868\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 10.1735 - val_loss: 9.8359\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 10.1199 - val_loss: 9.7864\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.0672 - val_loss: 9.7373\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 9.865 - 0s 85us/sample - loss: 10.0151 - val_loss: 9.6863\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 104us/sample - loss: 9.9608 - val_loss: 9.6350\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 9.9068 - val_loss: 9.5842\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 9.8534 - val_loss: 9.5342\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 9.8007 - val_loss: 9.4851\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.7492 - val_loss: 9.4349\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 9.6975 - val_loss: 9.3855\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.6469 - val_loss: 9.3370\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.5973 - val_loss: 9.2878\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.5473 - val_loss: 9.2394\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.4981 - val_loss: 9.1922\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 9.4504 - val_loss: 9.1444\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.4020 - val_loss: 9.0983\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3541 - val_loss: 9.0537\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.3068 - val_loss: 9.0099\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.2598 - val_loss: 8.9658\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.2130 - val_loss: 8.9234\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.1678 - val_loss: 8.8822\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1241 - val_loss: 8.8406\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.0801 - val_loss: 8.8006\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.0374 - val_loss: 8.7624\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.9973 - val_loss: 8.7227\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.9556 - val_loss: 8.6852\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.9166 - val_loss: 8.6467\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.8767 - val_loss: 8.6087\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 8.8374 - val_loss: 8.5702\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.7978 - val_loss: 8.5316\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.7584 - val_loss: 8.4955\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.7205 - val_loss: 8.4585\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6817 - val_loss: 8.4236\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.6452 - val_loss: 8.3910\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6107 - val_loss: 8.3546\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.5736 - val_loss: 8.3182\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.5371 - val_loss: 8.2834\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.5023 - val_loss: 8.2496\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.4682 - val_loss: 8.2155\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.4339 - val_loss: 8.1813\n",
      "Epoch 106/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.3994 - val_loss: 8.1486\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3671 - val_loss: 8.1150\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.3336 - val_loss: 8.0827\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.3017 - val_loss: 8.0507\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.2703 - val_loss: 8.0178\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.2384 - val_loss: 7.9872\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.2082 - val_loss: 7.9573\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.1789 - val_loss: 7.9284\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 8.1498 - val_loss: 7.9015\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.1231 - val_loss: 7.8749\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.0967 - val_loss: 7.8486\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.0702 - val_loss: 7.8217\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.0432 - val_loss: 7.7956\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.0169 - val_loss: 7.7698\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.9917 - val_loss: 7.7451\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.9673 - val_loss: 7.7212\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.9433 - val_loss: 7.6993\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.9216 - val_loss: 7.6778\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.9001 - val_loss: 7.6552\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.8779 - val_loss: 7.6343\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.8580 - val_loss: 7.6146\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.8388 - val_loss: 7.5941\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.8198 - val_loss: 7.5763\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.8030 - val_loss: 7.5576\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.7852 - val_loss: 7.5402\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.7689 - val_loss: 7.5231\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.7530 - val_loss: 7.5057\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.7365 - val_loss: 7.4900\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.7210 - val_loss: 7.4750\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.7063 - val_loss: 7.4588\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.6912 - val_loss: 7.4442\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.6773 - val_loss: 7.4305\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.6641 - val_loss: 7.4167\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6507 - val_loss: 7.4031\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.6372 - val_loss: 7.3885\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.6230 - val_loss: 7.3755\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.6102 - val_loss: 7.3634\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.5981 - val_loss: 7.3517\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.5862 - val_loss: 7.3394\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.5732 - val_loss: 7.3286\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.5619 - val_loss: 7.3167\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5498 - val_loss: 7.3064\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.5390 - val_loss: 7.2959\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.5282 - val_loss: 7.2856\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.5180 - val_loss: 7.2744\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.5068 - val_loss: 7.2637\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.4963 - val_loss: 7.2540\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.4868 - val_loss: 7.2449\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.4776 - val_loss: 7.2366\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4689 - val_loss: 7.2286\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.4609 - val_loss: 7.2212\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.4528 - val_loss: 7.2133\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4448 - val_loss: 7.2058\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.4366 - val_loss: 7.1994\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4295 - val_loss: 7.1929\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.4221 - val_loss: 7.1869\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4152 - val_loss: 7.1809\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4084 - val_loss: 7.1754\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.4023 - val_loss: 7.1695\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3958 - val_loss: 7.1646\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3901 - val_loss: 7.1596\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3844 - val_loss: 7.1542\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3787 - val_loss: 7.1487\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3725 - val_loss: 7.1426\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3662 - val_loss: 7.1379\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3609 - val_loss: 7.1327\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3553 - val_loss: 7.1281\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3501 - val_loss: 7.1237\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3449 - val_loss: 7.1185\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3392 - val_loss: 7.1142\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3344 - val_loss: 7.1104\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3300 - val_loss: 7.1066\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3256 - val_loss: 7.1027\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3211 - val_loss: 7.0988\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3166 - val_loss: 7.0951\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3120 - val_loss: 7.0911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3071 - val_loss: 7.0876\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3030 - val_loss: 7.0842\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.2989 - val_loss: 7.0817\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.378 - 0s 77us/sample - loss: 7.2955 - val_loss: 7.0790\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.2919 - val_loss: 7.0761\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2879 - val_loss: 7.0731\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2840 - val_loss: 7.0709\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2809 - val_loss: 7.0686\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2776 - val_loss: 7.0664\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2748 - val_loss: 7.0642\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2716 - val_loss: 7.0619\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2686 - val_loss: 7.0598\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2655 - val_loss: 7.0578\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2625 - val_loss: 7.0557\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2596 - val_loss: 7.0549\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.2569 - val_loss: 7.0531\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2544 - val_loss: 7.0512\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.2518 - val_loss: 7.0496\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2495 - val_loss: 7.0479\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2474 - val_loss: 7.0467\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2449 - val_loss: 7.0452\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.2428 - val_loss: 7.0446\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.173 - 0s 82us/sample - loss: 7.2411 - val_loss: 7.0437\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2390 - val_loss: 7.0428\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2372 - val_loss: 7.0417\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2354 - val_loss: 7.0413\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2338 - val_loss: 7.0401\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2319 - val_loss: 7.0392\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2303 - val_loss: 7.0386\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2285 - val_loss: 7.0376\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2266 - val_loss: 7.0365\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2249 - val_loss: 7.0358\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2233 - val_loss: 7.0347\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2217 - val_loss: 7.0333\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2201 - val_loss: 7.0324\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2181 - val_loss: 7.0307\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.2165 - val_loss: 7.0300\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2151 - val_loss: 7.0293\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2137 - val_loss: 7.0283\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2121 - val_loss: 7.0279\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2107 - val_loss: 7.0271\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2091 - val_loss: 7.0264\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2080 - val_loss: 7.0255\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2066 - val_loss: 7.0245\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2052 - val_loss: 7.0236\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2038 - val_loss: 7.0231\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2025 - val_loss: 7.0225\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2013 - val_loss: 7.0218\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1999 - val_loss: 7.0210\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1989 - val_loss: 7.0206\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1977 - val_loss: 7.0197\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1967 - val_loss: 7.0193\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1955 - val_loss: 7.0189\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1945 - val_loss: 7.0184\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1934 - val_loss: 7.0182\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1925 - val_loss: 7.0180\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1915 - val_loss: 7.0175\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1904 - val_loss: 7.0174\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1896 - val_loss: 7.0172\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1887 - val_loss: 7.0169\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1879 - val_loss: 7.0163\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1870 - val_loss: 7.0163\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1861 - val_loss: 7.0155\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1854 - val_loss: 7.0149\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.1846 - val_loss: 7.0147\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1839 - val_loss: 7.0144\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1831 - val_loss: 7.0141\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1823 - val_loss: 7.0140\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1816 - val_loss: 7.0141\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1809 - val_loss: 7.0136\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1801 - val_loss: 7.0135\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1794 - val_loss: 7.0128\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1786 - val_loss: 7.0126\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1778 - val_loss: 7.0127\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1771 - val_loss: 7.0125\n",
      "Epoch 257/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1763 - val_loss: 7.0125\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1755 - val_loss: 7.0122\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1748 - val_loss: 7.0115\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1740 - val_loss: 7.0113\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1734 - val_loss: 7.0108\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1728 - val_loss: 7.0107\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1719 - val_loss: 7.0103\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.1711 - val_loss: 7.0103\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1704 - val_loss: 7.0098\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.1699 - val_loss: 7.0094\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1691 - val_loss: 7.0091\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1683 - val_loss: 7.0089\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.1674 - val_loss: 7.0085\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 134us/sample - loss: 7.1667 - val_loss: 7.0078\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.1660 - val_loss: 7.0078\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 7.1653 - val_loss: 7.0078\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1648 - val_loss: 7.0081\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1640 - val_loss: 7.0077\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1632 - val_loss: 7.0071\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1626 - val_loss: 7.0071\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.1618 - val_loss: 7.0070\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1606 - val_loss: 7.0070\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.1599 - val_loss: 7.0067\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1592 - val_loss: 7.0067\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1586 - val_loss: 7.0068\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1579 - val_loss: 7.0065\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1571 - val_loss: 7.0061\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1564 - val_loss: 7.0060\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1558 - val_loss: 7.0056\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1551 - val_loss: 7.0052\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1544 - val_loss: 7.0052\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1537 - val_loss: 7.0050\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1531 - val_loss: 7.0051\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1524 - val_loss: 7.0052\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1517 - val_loss: 7.0046\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.1511 - val_loss: 7.0042\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1503 - val_loss: 7.0043\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1497 - val_loss: 7.0041\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1491 - val_loss: 7.0042\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1485 - val_loss: 7.0043\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1479 - val_loss: 7.0041\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1472 - val_loss: 7.0040\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1464 - val_loss: 7.0037\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1458 - val_loss: 7.0032\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1452 - val_loss: 7.0034\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1446 - val_loss: 7.0035\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1441 - val_loss: 7.0033\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1434 - val_loss: 7.0029\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1429 - val_loss: 7.0029\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1424 - val_loss: 7.0028\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1417 - val_loss: 7.0031\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1410 - val_loss: 7.0032\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1404 - val_loss: 7.0034\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1400 - val_loss: 7.0033\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1392 - val_loss: 7.0031\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1386 - val_loss: 7.0031\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1381 - val_loss: 7.0032\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1374 - val_loss: 7.0031\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1368 - val_loss: 7.0033\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1363 - val_loss: 7.0033\n",
      "594/594 [==============================] - 0s 39us/sample - loss: 6.9456\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=1, n_neurons=373, total=  32.2s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=1, n_neurons=373 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 312us/sample - loss: 13.8787 - val_loss: 13.5937\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.8122 - val_loss: 13.5268\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.7457 - val_loss: 13.4602\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 13.6796 - val_loss: 13.3947\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 13.6148 - val_loss: 13.3284\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.5491 - val_loss: 13.2624\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 13.4836 - val_loss: 13.1964\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.4183 - val_loss: 13.1308\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.3533 - val_loss: 13.0651\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.2883 - val_loss: 12.9996\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.2232 - val_loss: 12.9344\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.1586 - val_loss: 12.8695\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.0946 - val_loss: 12.8052\n",
      "Epoch 14/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 82us/sample - loss: 13.0314 - val_loss: 12.7420\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 12.9694 - val_loss: 12.6779\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 12.9062 - val_loss: 12.6142\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.8426 - val_loss: 12.5518\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.7796 - val_loss: 12.4892\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.7167 - val_loss: 12.4268\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.6544 - val_loss: 12.3640\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.5919 - val_loss: 12.3016\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.5297 - val_loss: 12.2393\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.4675 - val_loss: 12.1784\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.4070 - val_loss: 12.1176\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.3464 - val_loss: 12.0565\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.2849 - val_loss: 11.9947\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 12.2231 - val_loss: 11.9332\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.1612 - val_loss: 11.8712\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 12.0995 - val_loss: 11.8106\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 12.0390 - val_loss: 11.7494\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 11.9782 - val_loss: 11.6909\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.9193 - val_loss: 11.6322\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.8602 - val_loss: 11.5737\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.8006 - val_loss: 11.5164\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.7423 - val_loss: 11.4586\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.6833 - val_loss: 11.4007\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.6240 - val_loss: 11.3433\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.5660 - val_loss: 11.2858\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 11.5080 - val_loss: 11.2271\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.4487 - val_loss: 11.1692\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.3900 - val_loss: 11.1100\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3302 - val_loss: 11.0503\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.2703 - val_loss: 10.9912\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.2115 - val_loss: 10.9326\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.1531 - val_loss: 10.8741\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.0946 - val_loss: 10.8176\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 11.0382 - val_loss: 10.7598\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.9798 - val_loss: 10.7027\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.9210 - val_loss: 10.6455\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.8617 - val_loss: 10.5877\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.8017 - val_loss: 10.5305\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.7418 - val_loss: 10.4737\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 10.6822 - val_loss: 10.4194\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.6243 - val_loss: 10.3644\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.5655 - val_loss: 10.3100\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.5068 - val_loss: 10.2551\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 10.4468 - val_loss: 10.2005\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.3862 - val_loss: 10.1469\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.3266 - val_loss: 10.0929\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.2660 - val_loss: 10.0382\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.2049 - val_loss: 9.9832\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.1438 - val_loss: 9.9292\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.0841 - val_loss: 9.8749\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.0239 - val_loss: 9.8209\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.9644 - val_loss: 9.7702\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.9085 - val_loss: 9.7173\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.8506 - val_loss: 9.6643\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.7928 - val_loss: 9.6113\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.7352 - val_loss: 9.5579\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.6765 - val_loss: 9.5053\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.6188 - val_loss: 9.4524\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.5607 - val_loss: 9.4012\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.5049 - val_loss: 9.3504\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.4495 - val_loss: 9.3003\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.3946 - val_loss: 9.2494\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.3395 - val_loss: 9.1996\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.2861 - val_loss: 9.1503\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.2334 - val_loss: 9.1021\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.1809 - val_loss: 9.0547\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.1293 - val_loss: 9.0097\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.0798 - val_loss: 8.9622\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.0280 - val_loss: 8.9168\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.9797 - val_loss: 8.8715\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.9304 - val_loss: 8.8263\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.8818 - val_loss: 8.7831\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.8353 - val_loss: 8.7413\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.7905 - val_loss: 8.6980\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.7440 - val_loss: 8.6550\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.6982 - val_loss: 8.6124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.6527 - val_loss: 8.5694\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.6069 - val_loss: 8.5264\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.5619 - val_loss: 8.4849\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.5185 - val_loss: 8.4449\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.4755 - val_loss: 8.4051\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.4323 - val_loss: 8.3668\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3901 - val_loss: 8.3274\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.3472 - val_loss: 8.2884\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.3062 - val_loss: 8.2525\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.2676 - val_loss: 8.2178\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.2310 - val_loss: 8.1812\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.1930 - val_loss: 8.1456\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1558 - val_loss: 8.1120\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.1201 - val_loss: 8.0794\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.0857 - val_loss: 8.0463\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.0515 - val_loss: 8.0132\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.0174 - val_loss: 7.9823\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.9863 - val_loss: 7.9512\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.9553 - val_loss: 7.9219\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.9257 - val_loss: 7.8921\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.8957 - val_loss: 7.8622\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.8658 - val_loss: 7.8343\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.8376 - val_loss: 7.8072\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.8107 - val_loss: 7.7789\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.7828 - val_loss: 7.7519\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.7564 - val_loss: 7.7264\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.7307 - val_loss: 7.7016\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.7056 - val_loss: 7.6754\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.6796 - val_loss: 7.6521\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6551 - val_loss: 7.6276\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.6295 - val_loss: 7.6048\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.6061 - val_loss: 7.5830\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.5841 - val_loss: 7.5632\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.5642 - val_loss: 7.5430\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.5436 - val_loss: 7.5233\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.5234 - val_loss: 7.5037\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.5031 - val_loss: 7.4845\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.4827 - val_loss: 7.4663\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.4635 - val_loss: 7.4479\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4441 - val_loss: 7.4308\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.4257 - val_loss: 7.4160\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4090 - val_loss: 7.4018\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.3934 - val_loss: 7.3854\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.3754 - val_loss: 7.3694\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3583 - val_loss: 7.3553\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.3432 - val_loss: 7.3416\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.3287 - val_loss: 7.3285\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.3145 - val_loss: 7.3159\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3010 - val_loss: 7.3036\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2882 - val_loss: 7.2916\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2752 - val_loss: 7.2792\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.2625 - val_loss: 7.2680\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2507 - val_loss: 7.2574\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2393 - val_loss: 7.2467\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2278 - val_loss: 7.2369\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2171 - val_loss: 7.2271\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2065 - val_loss: 7.2182\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1967 - val_loss: 7.2101\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1876 - val_loss: 7.2027\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1794 - val_loss: 7.1952\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1708 - val_loss: 7.1871\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1622 - val_loss: 7.1804\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.1545 - val_loss: 7.1735\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.1466 - val_loss: 7.1677\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1398 - val_loss: 7.1624\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1335 - val_loss: 7.1557\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1260 - val_loss: 7.1496\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.1192 - val_loss: 7.1431\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1119 - val_loss: 7.1382\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.153 - 0s 89us/sample - loss: 7.1060 - val_loss: 7.1329\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.0997 - val_loss: 7.1277\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.0936 - val_loss: 7.1222\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.0874 - val_loss: 7.1173\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.0815 - val_loss: 7.1134\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.0766 - val_loss: 7.1079\n",
      "Epoch 165/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.0702 - val_loss: 7.1039\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.0653 - val_loss: 7.0999\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0602 - val_loss: 7.0966\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.0559 - val_loss: 7.0928\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0509 - val_loss: 7.0890\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.0457 - val_loss: 7.0860\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.0412 - val_loss: 7.0827\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.0364 - val_loss: 7.0799\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.0320 - val_loss: 7.0773\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.0276 - val_loss: 7.0744\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.0231 - val_loss: 7.0720\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.0196 - val_loss: 7.0703\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.0164 - val_loss: 7.0684\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.0129 - val_loss: 7.0664\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.0092 - val_loss: 7.0642\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.0056 - val_loss: 7.0618\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.0021 - val_loss: 7.0598\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9985 - val_loss: 7.0576\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.9951 - val_loss: 7.0557\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9919 - val_loss: 7.0538\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9888 - val_loss: 7.0527\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9862 - val_loss: 7.0510\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9834 - val_loss: 7.0497\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.9811 - val_loss: 7.0486\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9784 - val_loss: 7.0479\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9761 - val_loss: 7.0465\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9736 - val_loss: 7.0456\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9711 - val_loss: 7.0442\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9687 - val_loss: 7.0433\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9664 - val_loss: 7.0425\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9643 - val_loss: 7.0413\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9621 - val_loss: 7.0407\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9601 - val_loss: 7.0395\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9577 - val_loss: 7.0388\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9551 - val_loss: 7.0378\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9530 - val_loss: 7.0370\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9507 - val_loss: 7.0361\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9484 - val_loss: 7.0352\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9464 - val_loss: 7.0350\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.9449 - val_loss: 7.0343\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9430 - val_loss: 7.0338\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9414 - val_loss: 7.0333\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9395 - val_loss: 7.0330\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9378 - val_loss: 7.0330\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9362 - val_loss: 7.0329\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.9347 - val_loss: 7.0327\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9330 - val_loss: 7.0325\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9316 - val_loss: 7.0321\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9302 - val_loss: 7.0315\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9289 - val_loss: 7.0311\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.9275 - val_loss: 7.0304\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9261 - val_loss: 7.0302\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.9244 - val_loss: 7.0297\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.9231 - val_loss: 7.0294\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9220 - val_loss: 7.0292\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.9209 - val_loss: 7.0290\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9196 - val_loss: 7.0289\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9187 - val_loss: 7.0289\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9173 - val_loss: 7.0287\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9161 - val_loss: 7.0284\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9149 - val_loss: 7.0284\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.9138 - val_loss: 7.0284\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.9129 - val_loss: 7.0286\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.9118 - val_loss: 7.0285\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9108 - val_loss: 7.0284\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.9098 - val_loss: 7.0281\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9089 - val_loss: 7.0278\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9079 - val_loss: 7.0280\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.9068 - val_loss: 7.0282\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9058 - val_loss: 7.0281\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9048 - val_loss: 7.0277\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9040 - val_loss: 7.0279\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9030 - val_loss: 7.0276\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9020 - val_loss: 7.0279\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9010 - val_loss: 7.0274\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9001 - val_loss: 7.0276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8992 - val_loss: 7.0276\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8983 - val_loss: 7.0273\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8975 - val_loss: 7.0275\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8965 - val_loss: 7.0277\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8955 - val_loss: 7.0279\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8947 - val_loss: 7.0278\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.8937 - val_loss: 7.0280\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.8930 - val_loss: 7.0279\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8921 - val_loss: 7.0280\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8912 - val_loss: 7.0278\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8904 - val_loss: 7.0280\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.8896 - val_loss: 7.0281\n",
      "594/594 [==============================] - 0s 39us/sample - loss: 7.6071\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=1, n_neurons=373, total=  24.9s\n",
      "[CV] learning_rate=0.0003920021771415983, n_hidden=1, n_neurons=373 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 299us/sample - loss: 13.8963 - val_loss: 13.7408\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.8269 - val_loss: 13.6719\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.7575 - val_loss: 13.6031\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.6889 - val_loss: 13.5350\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 13.6212 - val_loss: 13.4677\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.5538 - val_loss: 13.4005\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 13.4865 - val_loss: 13.3337\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 13.4195 - val_loss: 13.2671\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.3527 - val_loss: 13.2010\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.2865 - val_loss: 13.1347\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.2204 - val_loss: 13.0685\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 13.1541 - val_loss: 13.0023\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 13.0891 - val_loss: 12.9376\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 13.0251 - val_loss: 12.8737\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.9624 - val_loss: 12.8106\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.9004 - val_loss: 12.7466\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.8370 - val_loss: 12.6832\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.7740 - val_loss: 12.6202\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 12.7112 - val_loss: 12.5574\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 12.6487 - val_loss: 12.4947\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 12.5864 - val_loss: 12.4320\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.5248 - val_loss: 12.3702\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 12.4634 - val_loss: 12.3082\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 12.4027 - val_loss: 12.2492\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 12.3452 - val_loss: 12.1886\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 12.2861 - val_loss: 12.1277\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.2268 - val_loss: 12.0672\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.1676 - val_loss: 12.0077\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 12.1097 - val_loss: 11.9507\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 12.0547 - val_loss: 11.8913\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 11.9973 - val_loss: 11.8333\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.9408 - val_loss: 11.7747\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.8836 - val_loss: 11.7165\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.8267 - val_loss: 11.6608\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.7718 - val_loss: 11.6033\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.7154 - val_loss: 11.5468\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.6602 - val_loss: 11.4908\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.6052 - val_loss: 11.4347\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.5499 - val_loss: 11.3778\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.4937 - val_loss: 11.3212\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 11.4381 - val_loss: 11.2635\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 11.3815 - val_loss: 11.2066\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 11.3261 - val_loss: 11.1501\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.2711 - val_loss: 11.0935\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.2151 - val_loss: 11.0365\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.1593 - val_loss: 10.9816\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.1058 - val_loss: 10.9254\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.0512 - val_loss: 10.8696\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.9970 - val_loss: 10.8158\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.9452 - val_loss: 10.7612\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.8922 - val_loss: 10.7072\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.8393 - val_loss: 10.6518\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.7855 - val_loss: 10.5975\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.7328 - val_loss: 10.5434\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 10.6804 - val_loss: 10.4896\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.6283 - val_loss: 10.4354\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.5754 - val_loss: 10.3825\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 10.5237 - val_loss: 10.3301\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 10.4717 - val_loss: 10.2780\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.4201 - val_loss: 10.2257\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 10.3691 - val_loss: 10.1757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.3199 - val_loss: 10.1281\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.2730 - val_loss: 10.0802\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.2254 - val_loss: 10.0313\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.1764 - val_loss: 9.9832\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.1282 - val_loss: 9.9334\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.0786 - val_loss: 9.8829\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.0292 - val_loss: 9.8330\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.9801 - val_loss: 9.7852\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.9329 - val_loss: 9.7373\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.8849 - val_loss: 9.6900\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.8377 - val_loss: 9.6423\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.7899 - val_loss: 9.5951\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.7426 - val_loss: 9.5489\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.6965 - val_loss: 9.5011\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.6483 - val_loss: 9.4558\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.6018 - val_loss: 9.4106\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.5553 - val_loss: 9.3646\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.5082 - val_loss: 9.3177\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.4606 - val_loss: 9.2737\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.4158 - val_loss: 9.2274\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.3691 - val_loss: 9.1840\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3255 - val_loss: 9.1378\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.2796 - val_loss: 9.0930\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.2352 - val_loss: 9.0485\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1908 - val_loss: 9.0038\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.1463 - val_loss: 8.9601\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.1020 - val_loss: 8.9160\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.0583 - val_loss: 8.8720\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.0147 - val_loss: 8.8289\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.9729 - val_loss: 8.7860\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.9304 - val_loss: 8.7460\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.8901 - val_loss: 8.7049\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.8492 - val_loss: 8.6648\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.8090 - val_loss: 8.6262\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.7702 - val_loss: 8.5886\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7331 - val_loss: 8.5497\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6951 - val_loss: 8.5127\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6577 - val_loss: 8.4769\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.6213 - val_loss: 8.4412\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.5852 - val_loss: 8.4047\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.5488 - val_loss: 8.3698\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.5140 - val_loss: 8.3350\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.4793 - val_loss: 8.3025\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.4474 - val_loss: 8.2690\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 8.4144 - val_loss: 8.2379\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.3837 - val_loss: 8.2070\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.3538 - val_loss: 8.1762\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.3233 - val_loss: 8.1464\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 8.2943 - val_loss: 8.1164\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.2650 - val_loss: 8.0855\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.2355 - val_loss: 8.0552\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.2068 - val_loss: 8.0259\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.1784 - val_loss: 7.9988\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1517 - val_loss: 7.9702\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.1236 - val_loss: 7.9427\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.0969 - val_loss: 7.9154\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.0703 - val_loss: 7.8901\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.0462 - val_loss: 7.8640\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.0210 - val_loss: 7.8373\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.9953 - val_loss: 7.8108\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.9698 - val_loss: 7.7852\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.9450 - val_loss: 7.7589\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.9193 - val_loss: 7.7348\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.8954 - val_loss: 7.7094\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.8704 - val_loss: 7.6845\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.8459 - val_loss: 7.6619\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.8243 - val_loss: 7.6386\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.8016 - val_loss: 7.6168\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.7799 - val_loss: 7.5977\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.7613 - val_loss: 7.5799\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.7432 - val_loss: 7.5621\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.7254 - val_loss: 7.5433\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.7067 - val_loss: 7.5252\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.6893 - val_loss: 7.5070\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.6717 - val_loss: 7.4903\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.6560 - val_loss: 7.4743\n",
      "Epoch 138/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.6415 - val_loss: 7.4579\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.6272 - val_loss: 7.4429\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.6141 - val_loss: 7.4276\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.6008 - val_loss: 7.4117\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.5871 - val_loss: 7.3960\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.5742 - val_loss: 7.3806\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.5612 - val_loss: 7.3672\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.5500 - val_loss: 7.3523\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.5375 - val_loss: 7.3391\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.5262 - val_loss: 7.3251\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.5143 - val_loss: 7.3123\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.5034 - val_loss: 7.3007\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.4934 - val_loss: 7.2884\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4826 - val_loss: 7.2779\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.4731 - val_loss: 7.2672\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.4633 - val_loss: 7.2564\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.4537 - val_loss: 7.2462\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.4446 - val_loss: 7.2344\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.4338 - val_loss: 7.2238\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.4241 - val_loss: 7.2138\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.4148 - val_loss: 7.2043\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4064 - val_loss: 7.1942\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3973 - val_loss: 7.1855\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.3893 - val_loss: 7.1770\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3819 - val_loss: 7.1686\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.3747 - val_loss: 7.1611\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3681 - val_loss: 7.1520\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3602 - val_loss: 7.1446\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3537 - val_loss: 7.1364\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.3467 - val_loss: 7.1284\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3400 - val_loss: 7.1216\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3339 - val_loss: 7.1147\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3278 - val_loss: 7.1081\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3217 - val_loss: 7.1019\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3160 - val_loss: 7.0960\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.3108 - val_loss: 7.0912\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3064 - val_loss: 7.0864\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.3021 - val_loss: 7.0811\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2975 - val_loss: 7.0773\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2941 - val_loss: 7.0725\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2898 - val_loss: 7.0685\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2858 - val_loss: 7.0648\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.2821 - val_loss: 7.0610\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2781 - val_loss: 7.0576\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2748 - val_loss: 7.0542\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2712 - val_loss: 7.0509\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2680 - val_loss: 7.0472\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2643 - val_loss: 7.0448\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2614 - val_loss: 7.0417\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2584 - val_loss: 7.0387\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2552 - val_loss: 7.0358\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2520 - val_loss: 7.0334\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2491 - val_loss: 7.0310\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 7.2462 - val_loss: 7.0291\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2435 - val_loss: 7.0268\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2409 - val_loss: 7.0246\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2380 - val_loss: 7.0229\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2357 - val_loss: 7.0206\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2332 - val_loss: 7.0192\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.2314 - val_loss: 7.0176\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2293 - val_loss: 7.0156\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.2269 - val_loss: 7.0139\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2249 - val_loss: 7.0122\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.2229 - val_loss: 7.0108\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2212 - val_loss: 7.0094\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2195 - val_loss: 7.0084\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2177 - val_loss: 7.0071\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2163 - val_loss: 7.0056\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.2147 - val_loss: 7.0045\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2129 - val_loss: 7.0032\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2113 - val_loss: 7.0024\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2099 - val_loss: 7.0017\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.2086 - val_loss: 7.0003\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.2068 - val_loss: 6.9992\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2051 - val_loss: 6.9984\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.2039 - val_loss: 6.9971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.2025 - val_loss: 6.9960\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.2012 - val_loss: 6.9955\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1998 - val_loss: 6.9949\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1988 - val_loss: 6.9947\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1976 - val_loss: 6.9938\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1966 - val_loss: 6.9932\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1956 - val_loss: 6.9925\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1940 - val_loss: 6.9919\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1928 - val_loss: 6.9914\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1917 - val_loss: 6.9909\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1904 - val_loss: 6.9902\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1893 - val_loss: 6.9904\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1883 - val_loss: 6.9906\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1874 - val_loss: 6.9905\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1864 - val_loss: 6.9906\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1854 - val_loss: 6.9900\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1842 - val_loss: 6.9896\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1831 - val_loss: 6.9895\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.1823 - val_loss: 6.9895\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1813 - val_loss: 6.9893\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1803 - val_loss: 6.9893\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1792 - val_loss: 6.9893\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1783 - val_loss: 6.9891\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.1774 - val_loss: 6.9886\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.1766 - val_loss: 6.9887\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 146us/sample - loss: 7.1757 - val_loss: 6.9881\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 113us/sample - loss: 7.1747 - val_loss: 6.9885\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 7.1740 - val_loss: 6.9887\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.1731 - val_loss: 6.9887\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.1723 - val_loss: 6.9888\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.1716 - val_loss: 6.9889\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1708 - val_loss: 6.9891\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1702 - val_loss: 6.9894\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.1692 - val_loss: 6.9893\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1684 - val_loss: 6.9892\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1676 - val_loss: 6.9890\n",
      "594/594 [==============================] - 0s 37us/sample - loss: 7.0578\n",
      "[CV]  learning_rate=0.0003920021771415983, n_hidden=1, n_neurons=373, total=  24.8s\n",
      "[CV] learning_rate=0.004779156784872302, n_hidden=1, n_neurons=131 ...\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 306us/sample - loss: 13.4839 - val_loss: 12.8075\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.7404 - val_loss: 12.0823\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.0493 - val_loss: 11.3833\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.3732 - val_loss: 10.7012\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.6909 - val_loss: 10.0552\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0240 - val_loss: 9.4481\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.4114 - val_loss: 8.8502\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 8.8575 - val_loss: 8.3600\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4074 - val_loss: 7.9511\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.0479 - val_loss: 7.6602\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.8000 - val_loss: 7.4186\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5964 - val_loss: 7.2394\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.4537 - val_loss: 7.1312\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3705 - val_loss: 7.0876\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3243 - val_loss: 7.0535\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2844 - val_loss: 7.0251\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2523 - val_loss: 7.0243\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2328 - val_loss: 7.0104\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2114 - val_loss: 7.0044\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1968 - val_loss: 6.9987\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1833 - val_loss: 6.9969\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1724 - val_loss: 6.9956\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1646 - val_loss: 6.9938\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1547 - val_loss: 6.9934\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1483 - val_loss: 6.9910\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1428 - val_loss: 6.9807\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1355 - val_loss: 6.9812\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1301 - val_loss: 6.9824\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1242 - val_loss: 6.9812\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1192 - val_loss: 6.9812\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1140 - val_loss: 6.9781\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1091 - val_loss: 6.9771\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1056 - val_loss: 6.9816\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1010 - val_loss: 6.9809\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.0945 - val_loss: 6.9793\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.0901 - val_loss: 6.9790\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0874 - val_loss: 6.9809\n",
      "Epoch 38/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.0842 - val_loss: 6.9850\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0791 - val_loss: 6.9877\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.0754 - val_loss: 6.9828\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.0725 - val_loss: 6.9843\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0678 - val_loss: 6.9820\n",
      "594/594 [==============================] - 0s 38us/sample - loss: 6.9416\n",
      "[CV]  learning_rate=0.004779156784872302, n_hidden=1, n_neurons=131, total=   4.4s\n",
      "[CV] learning_rate=0.004779156784872302, n_hidden=1, n_neurons=131 ...\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 317us/sample - loss: 13.2770 - val_loss: 12.6409\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.5798 - val_loss: 11.9219\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 11.8821 - val_loss: 11.2248\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.1877 - val_loss: 10.5624\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 52us/sample - loss: 10.4848 - val_loss: 9.8991\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 9.7761 - val_loss: 9.2624\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.1180 - val_loss: 8.7038\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.5378 - val_loss: 8.2213\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.0844 - val_loss: 7.8525\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.7385 - val_loss: 7.5720\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.492 - 0s 95us/sample - loss: 7.4685 - val_loss: 7.3688\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.2994 - val_loss: 7.2401\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1813 - val_loss: 7.1630\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.064 - 0s 86us/sample - loss: 7.1055 - val_loss: 7.1032\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.0513 - val_loss: 7.0741\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 7.0137 - val_loss: 7.0475\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 133us/sample - loss: 6.9847 - val_loss: 7.0374\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 6.9659 - val_loss: 7.0165\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9451 - val_loss: 7.0138\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.9297 - val_loss: 7.0048\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.9160 - val_loss: 7.0067\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.9036 - val_loss: 7.0064\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 6.8917 - val_loss: 7.0019\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 6.8800 - val_loss: 7.0025\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 6.8718 - val_loss: 6.9922\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 123us/sample - loss: 6.8640 - val_loss: 6.9930\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.8546 - val_loss: 6.9929\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.8464 - val_loss: 6.9952\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.8396 - val_loss: 6.9935\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.8329 - val_loss: 6.9902\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.8262 - val_loss: 6.9912\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8210 - val_loss: 6.9861\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8157 - val_loss: 6.9913\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.8105 - val_loss: 6.9964\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 115us/sample - loss: 6.8060 - val_loss: 6.9952\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.8005 - val_loss: 6.9948\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.7942 - val_loss: 6.9947\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.7902 - val_loss: 6.9969\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.7852 - val_loss: 6.9947\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.7793 - val_loss: 6.9986\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.7757 - val_loss: 6.9981\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.7723 - val_loss: 6.9924\n",
      "594/594 [==============================] - 0s 42us/sample - loss: 7.5479\n",
      "[CV]  learning_rate=0.004779156784872302, n_hidden=1, n_neurons=131, total=   4.9s\n",
      "[CV] learning_rate=0.004779156784872302, n_hidden=1, n_neurons=131 ...\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 323us/sample - loss: 13.5259 - val_loss: 13.0304\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.7903 - val_loss: 12.2903\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.0905 - val_loss: 11.5899\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.4343 - val_loss: 10.9289\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 10.8140 - val_loss: 10.2934\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2126 - val_loss: 9.6945\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.6437 - val_loss: 9.1617\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1240 - val_loss: 8.6717\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6509 - val_loss: 8.2527\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.2527 - val_loss: 7.9228\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.9464 - val_loss: 7.6699\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.7257 - val_loss: 7.4655\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.5698 - val_loss: 7.3176\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.4671 - val_loss: 7.2003\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 113us/sample - loss: 7.3877 - val_loss: 7.1263\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 7.3295 - val_loss: 7.0701\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2852 - val_loss: 7.0337\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.2572 - val_loss: 7.0089\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2355 - val_loss: 7.0042\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2182 - val_loss: 6.9992\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2047 - val_loss: 6.9941\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1944 - val_loss: 6.9929\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1859 - val_loss: 6.9907\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1760 - val_loss: 6.9899\n",
      "Epoch 25/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1682 - val_loss: 6.9781\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1614 - val_loss: 6.9798\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1545 - val_loss: 6.9762\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1476 - val_loss: 6.9807\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1405 - val_loss: 6.9813\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1299 - val_loss: 6.9815\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1243 - val_loss: 6.9818\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.1194 - val_loss: 6.9735\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.1143 - val_loss: 6.9763\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1106 - val_loss: 6.9858\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1083 - val_loss: 6.9901\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1035 - val_loss: 6.9850\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.0991 - val_loss: 6.9820\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.0962 - val_loss: 6.9871\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.0921 - val_loss: 6.9880\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 7.0887 - val_loss: 6.9860\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.0872 - val_loss: 6.9848\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.0830 - val_loss: 6.9864\n",
      "594/594 [==============================] - 0s 32us/sample - loss: 6.9578\n",
      "[CV]  learning_rate=0.004779156784872302, n_hidden=1, n_neurons=131, total=   4.4s\n",
      "[CV] learning_rate=0.00032983006724298584, n_hidden=1, n_neurons=344 .\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 305us/sample - loss: 14.1951 - val_loss: 13.8712\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 14.1287 - val_loss: 13.8091\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 14.0636 - val_loss: 13.7477\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.9996 - val_loss: 13.6875\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.9372 - val_loss: 13.6275\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.8748 - val_loss: 13.5682\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.8139 - val_loss: 13.5097\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 13.7540 - val_loss: 13.4523\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.6955 - val_loss: 13.3952\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 13.6371 - val_loss: 13.3378\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 13.5793 - val_loss: 13.2812\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.5225 - val_loss: 13.2247\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.4660 - val_loss: 13.1681\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 13.4092 - val_loss: 13.1112\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.3526 - val_loss: 13.0550\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.2966 - val_loss: 12.9984\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.2408 - val_loss: 12.9428\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 13.1869 - val_loss: 12.8882\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 13.1344 - val_loss: 12.8350\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 13.0832 - val_loss: 12.7821\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.0320 - val_loss: 12.7299\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.9814 - val_loss: 12.6787\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 12.9316 - val_loss: 12.6280\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.8823 - val_loss: 12.5768\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 12.8323 - val_loss: 12.5257\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 12.7823 - val_loss: 12.4744\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.7323 - val_loss: 12.4232\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.6823 - val_loss: 12.3726\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.6331 - val_loss: 12.3209\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.5829 - val_loss: 12.2692\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.5330 - val_loss: 12.2177\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.4831 - val_loss: 12.1670\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.4338 - val_loss: 12.1152\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.3834 - val_loss: 12.0636\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.3335 - val_loss: 12.0119\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.2834 - val_loss: 11.9618\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.2341 - val_loss: 11.9110\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.1844 - val_loss: 11.8608\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.1351 - val_loss: 11.8108\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.0860 - val_loss: 11.7612\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.0372 - val_loss: 11.7119\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 11.9887 - val_loss: 11.6627\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.9401 - val_loss: 11.6148\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.8927 - val_loss: 11.5662\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.8447 - val_loss: 11.5182\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.7972 - val_loss: 11.4703\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.7499 - val_loss: 11.4237\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.7037 - val_loss: 11.3760\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.6564 - val_loss: 11.3276\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.6084 - val_loss: 11.2793\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.5602 - val_loss: 11.2320\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.5130 - val_loss: 11.1840\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.4647 - val_loss: 11.1369\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.4176 - val_loss: 11.0880\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3689 - val_loss: 11.0401\n",
      "Epoch 56/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.3211 - val_loss: 10.9919\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.2730 - val_loss: 10.9432\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.2239 - val_loss: 10.8951\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.1755 - val_loss: 10.8470\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.1264 - val_loss: 10.7991\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.0771 - val_loss: 10.7519\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.0277 - val_loss: 10.7055\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.9787 - val_loss: 10.6583\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.9292 - val_loss: 10.6115\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.8801 - val_loss: 10.5642\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.8308 - val_loss: 10.5169\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.7815 - val_loss: 10.4704\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.7328 - val_loss: 10.4249\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.6848 - val_loss: 10.3782\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.6348 - val_loss: 10.3315\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.5846 - val_loss: 10.2841\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.5338 - val_loss: 10.2376\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.4846 - val_loss: 10.1922\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.4365 - val_loss: 10.1459\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.3879 - val_loss: 10.1001\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 10.3395 - val_loss: 10.0550\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.2922 - val_loss: 10.0091\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.2445 - val_loss: 9.9638\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.1968 - val_loss: 9.9191\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.1498 - val_loss: 9.8731\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.1016 - val_loss: 9.8271\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.0535 - val_loss: 9.7816\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.0060 - val_loss: 9.7369\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.9592 - val_loss: 9.6920\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.9123 - val_loss: 9.6473\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.8655 - val_loss: 9.6036\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.8192 - val_loss: 9.5610\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7728 - val_loss: 9.5176\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.7258 - val_loss: 9.4756\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.6811 - val_loss: 9.4322\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.6348 - val_loss: 9.3904\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5906 - val_loss: 9.3477\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.5459 - val_loss: 9.3054\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.5023 - val_loss: 9.2637\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.4598 - val_loss: 9.2224\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.4178 - val_loss: 9.1824\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.3770 - val_loss: 9.1415\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.3355 - val_loss: 9.1008\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2944 - val_loss: 9.0638\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.2561 - val_loss: 9.0242\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.2158 - val_loss: 8.9850\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1757 - val_loss: 8.9472\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.1371 - val_loss: 8.9080\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.0976 - val_loss: 8.8707\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0599 - val_loss: 8.8337\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.0226 - val_loss: 8.7990\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.9880 - val_loss: 8.7642\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.9526 - val_loss: 8.7306\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.9182 - val_loss: 8.6972\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.8837 - val_loss: 8.6636\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.8492 - val_loss: 8.6315\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.8158 - val_loss: 8.5988\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.7824 - val_loss: 8.5670\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7501 - val_loss: 8.5372\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.7195 - val_loss: 8.5059\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6876 - val_loss: 8.4752\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.6561 - val_loss: 8.4437\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6241 - val_loss: 8.4134\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5926 - val_loss: 8.3830\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5614 - val_loss: 8.3528\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5304 - val_loss: 8.3225\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.4991 - val_loss: 8.2939\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4698 - val_loss: 8.2654\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 8.4404 - val_loss: 8.2359\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.4100 - val_loss: 8.2074\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.3811 - val_loss: 8.1794\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.3526 - val_loss: 8.1512\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.3251 - val_loss: 8.1253\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.2999 - val_loss: 8.0985\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.2739 - val_loss: 8.0735\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.2492 - val_loss: 8.0478\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.2244 - val_loss: 8.0216\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.1998 - val_loss: 7.9981\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.1769 - val_loss: 7.9747\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.1543 - val_loss: 7.9497\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1308 - val_loss: 7.9260\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.1087 - val_loss: 7.9034\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.0872 - val_loss: 7.8809\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.0660 - val_loss: 7.8586\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.0449 - val_loss: 7.8357\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0233 - val_loss: 7.8146\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0031 - val_loss: 7.7942\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.9837 - val_loss: 7.7736\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.9646 - val_loss: 7.7521\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.9440 - val_loss: 7.7320\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9251 - val_loss: 7.7110\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.9054 - val_loss: 7.6912\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.8867 - val_loss: 7.6719\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.8685 - val_loss: 7.6539\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.8514 - val_loss: 7.6351\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.8336 - val_loss: 7.6171\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.8167 - val_loss: 7.6001\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.8005 - val_loss: 7.5838\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7846 - val_loss: 7.5678\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.7690 - val_loss: 7.5525\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.7543 - val_loss: 7.5377\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7401 - val_loss: 7.5225\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.7262 - val_loss: 7.5079\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.7124 - val_loss: 7.4941\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6997 - val_loss: 7.4804\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.6867 - val_loss: 7.4680\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.6747 - val_loss: 7.4545\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6617 - val_loss: 7.4432\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.6509 - val_loss: 7.4312\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6393 - val_loss: 7.4210\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6291 - val_loss: 7.4106\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6188 - val_loss: 7.4000\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6086 - val_loss: 7.3886\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.5972 - val_loss: 7.3772\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.5862 - val_loss: 7.3674\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5765 - val_loss: 7.3571\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5665 - val_loss: 7.3474\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.5571 - val_loss: 7.3379\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5478 - val_loss: 7.3279\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5381 - val_loss: 7.3196\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5297 - val_loss: 7.3115\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.5217 - val_loss: 7.3033\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5137 - val_loss: 7.2950\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5055 - val_loss: 7.2869\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4977 - val_loss: 7.2786\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4896 - val_loss: 7.2703\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4814 - val_loss: 7.2627\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.4742 - val_loss: 7.2548\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4667 - val_loss: 7.2486\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4607 - val_loss: 7.2415\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4536 - val_loss: 7.2343\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.4467 - val_loss: 7.2272\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4399 - val_loss: 7.2203\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4330 - val_loss: 7.2142\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.4267 - val_loss: 7.2081\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4208 - val_loss: 7.2025\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.4150 - val_loss: 7.1964\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.4089 - val_loss: 7.1906\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.4031 - val_loss: 7.1853\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3977 - val_loss: 7.1796\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3919 - val_loss: 7.1756\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3870 - val_loss: 7.1703\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3814 - val_loss: 7.1645\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.3756 - val_loss: 7.1596\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3706 - val_loss: 7.1544\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.3657 - val_loss: 7.1493\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3605 - val_loss: 7.1447\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3558 - val_loss: 7.1408\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.3515 - val_loss: 7.1368\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3472 - val_loss: 7.1333\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.3435 - val_loss: 7.1299\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3397 - val_loss: 7.1269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3362 - val_loss: 7.1234\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3323 - val_loss: 7.1207\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3286 - val_loss: 7.1177\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3251 - val_loss: 7.1142\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3215 - val_loss: 7.1115\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3184 - val_loss: 7.1091\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3157 - val_loss: 7.1066\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3127 - val_loss: 7.1036\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3096 - val_loss: 7.1009\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3061 - val_loss: 7.0979\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3030 - val_loss: 7.0958\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3006 - val_loss: 7.0937\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2983 - val_loss: 7.0912\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2955 - val_loss: 7.0892\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2932 - val_loss: 7.0869\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2907 - val_loss: 7.0848\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2886 - val_loss: 7.0826\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2863 - val_loss: 7.0803\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.296 - 0s 70us/sample - loss: 7.2841 - val_loss: 7.0779\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2818 - val_loss: 7.0760\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2798 - val_loss: 7.0744\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2780 - val_loss: 7.0726\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.209 - 0s 65us/sample - loss: 7.2760 - val_loss: 7.0709\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2741 - val_loss: 7.0694\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.2723 - val_loss: 7.0677\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2707 - val_loss: 7.0659\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2688 - val_loss: 7.0645\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2673 - val_loss: 7.0630\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2656 - val_loss: 7.0618\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2641 - val_loss: 7.0606\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2626 - val_loss: 7.0586\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2607 - val_loss: 7.0577\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2594 - val_loss: 7.0565\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2579 - val_loss: 7.0552\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2564 - val_loss: 7.0541\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2550 - val_loss: 7.0529\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2534 - val_loss: 7.0514\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2517 - val_loss: 7.0500\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2503 - val_loss: 7.0490\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2490 - val_loss: 7.0480\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 52us/sample - loss: 7.2475 - val_loss: 7.0471\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2463 - val_loss: 7.0464\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2450 - val_loss: 7.0457\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2437 - val_loss: 7.0444\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2422 - val_loss: 7.0436\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2410 - val_loss: 7.0420\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2395 - val_loss: 7.0412\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2383 - val_loss: 7.0407\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2372 - val_loss: 7.0400\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2361 - val_loss: 7.0394\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2348 - val_loss: 7.0386\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2336 - val_loss: 7.0376\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2322 - val_loss: 7.0368\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2313 - val_loss: 7.0360\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.2302 - val_loss: 7.0354\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.2288 - val_loss: 7.0346\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.2276 - val_loss: 7.0342\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2266 - val_loss: 7.0334\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2256 - val_loss: 7.0326\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2245 - val_loss: 7.0320\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.295 - 0s 65us/sample - loss: 7.2233 - val_loss: 7.0315\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2221 - val_loss: 7.0309\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2210 - val_loss: 7.0300\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2198 - val_loss: 7.0292\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2187 - val_loss: 7.0289\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2179 - val_loss: 7.0291\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2169 - val_loss: 7.0285\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2157 - val_loss: 7.0277\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2149 - val_loss: 7.0275\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2139 - val_loss: 7.0271\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2124 - val_loss: 7.0269\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2115 - val_loss: 7.0264\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2105 - val_loss: 7.0262\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2097 - val_loss: 7.0260\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2089 - val_loss: 7.0255\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2078 - val_loss: 7.0248\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2069 - val_loss: 7.0244\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2063 - val_loss: 7.0240\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2053 - val_loss: 7.0233\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2045 - val_loss: 7.0235\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2038 - val_loss: 7.0231\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2030 - val_loss: 7.0230\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2022 - val_loss: 7.0230\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2013 - val_loss: 7.0222\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.2005 - val_loss: 7.0217\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.1995 - val_loss: 7.0215\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1987 - val_loss: 7.0210\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1980 - val_loss: 7.0209\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1974 - val_loss: 7.0204\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.1966 - val_loss: 7.0199\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1959 - val_loss: 7.0196\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.1950 - val_loss: 7.0190\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.1943 - val_loss: 7.0183\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.1935 - val_loss: 7.0184\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.1928 - val_loss: 7.0182\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1921 - val_loss: 7.0177\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1915 - val_loss: 7.0173\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1907 - val_loss: 7.0170\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1900 - val_loss: 7.0167\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1892 - val_loss: 7.0167\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1884 - val_loss: 7.0166\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1877 - val_loss: 7.0166\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1872 - val_loss: 7.0164\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1863 - val_loss: 7.0161\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1854 - val_loss: 7.0158\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1848 - val_loss: 7.0157\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1841 - val_loss: 7.0155\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1833 - val_loss: 7.0155\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1826 - val_loss: 7.0152\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1820 - val_loss: 7.0153\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1813 - val_loss: 7.0148\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1805 - val_loss: 7.0144\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1797 - val_loss: 7.0145\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.1792 - val_loss: 7.0144\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1784 - val_loss: 7.0143\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1778 - val_loss: 7.0143\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1772 - val_loss: 7.0138\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.1763 - val_loss: 7.0138\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.1756 - val_loss: 7.0137\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1751 - val_loss: 7.0135\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1744 - val_loss: 7.0132\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1738 - val_loss: 7.0129\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1732 - val_loss: 7.0126\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1725 - val_loss: 7.0120\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1718 - val_loss: 7.0116\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1711 - val_loss: 7.0115\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1704 - val_loss: 7.0110\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1697 - val_loss: 7.0107\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1690 - val_loss: 7.0104\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1683 - val_loss: 7.0105\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1674 - val_loss: 7.0101\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1668 - val_loss: 7.0103\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1661 - val_loss: 7.0097\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1654 - val_loss: 7.0095\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1648 - val_loss: 7.0089\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1642 - val_loss: 7.0083\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 7.1636 - val_loss: 7.0079\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.1629 - val_loss: 7.0077\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.1623 - val_loss: 7.0074\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.1617 - val_loss: 7.0074\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1612 - val_loss: 7.0069\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1605 - val_loss: 7.0069\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1600 - val_loss: 7.0067\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1594 - val_loss: 7.0065\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1589 - val_loss: 7.0066\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1583 - val_loss: 7.0064\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1578 - val_loss: 7.0059\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1572 - val_loss: 7.0057\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1567 - val_loss: 7.0055\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1560 - val_loss: 7.0051\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1555 - val_loss: 7.0047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1549 - val_loss: 7.0048\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1544 - val_loss: 7.0045\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.1537 - val_loss: 7.0044\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.1531 - val_loss: 7.0044\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.1526 - val_loss: 7.0043\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 7.1521 - val_loss: 7.0043\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 7.1515 - val_loss: 7.0043\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1510 - val_loss: 7.0041\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1505 - val_loss: 7.0039\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1499 - val_loss: 7.0037\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1495 - val_loss: 7.0038\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1489 - val_loss: 7.0036\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 7.1483 - val_loss: 7.0037\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 7.1478 - val_loss: 7.0036\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1472 - val_loss: 7.0032\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1466 - val_loss: 7.0031\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1461 - val_loss: 7.0030\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1456 - val_loss: 7.0025\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1451 - val_loss: 7.0025\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1445 - val_loss: 7.0024\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1441 - val_loss: 7.0021\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1435 - val_loss: 7.0018\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1430 - val_loss: 7.0019\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1424 - val_loss: 7.0020\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1418 - val_loss: 7.0020\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1413 - val_loss: 7.0020\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1408 - val_loss: 7.0019\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1403 - val_loss: 7.0016\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1398 - val_loss: 7.0017\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1393 - val_loss: 7.0018\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1388 - val_loss: 7.0014\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1383 - val_loss: 7.0015\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1376 - val_loss: 7.0010\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1372 - val_loss: 7.0006\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1366 - val_loss: 7.0003\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1361 - val_loss: 7.0005\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1356 - val_loss: 7.0000\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1351 - val_loss: 7.0001\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1346 - val_loss: 7.0002\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1341 - val_loss: 7.0003\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.1337 - val_loss: 7.0001\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.1331 - val_loss: 6.9999\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.1326 - val_loss: 6.9998\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1321 - val_loss: 6.9997\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1317 - val_loss: 6.9996\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1311 - val_loss: 6.9994\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1307 - val_loss: 6.9995\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1302 - val_loss: 6.9991\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.1297 - val_loss: 6.9988\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.1292 - val_loss: 6.9993\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.1287 - val_loss: 6.9993\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.1282 - val_loss: 6.9993\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.1278 - val_loss: 6.9997\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.1272 - val_loss: 6.9995\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1267 - val_loss: 6.9998\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.1262 - val_loss: 6.9997\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 7.1257 - val_loss: 6.9999\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.1253 - val_loss: 6.9997\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.1249 - val_loss: 6.9996\n",
      "594/594 [==============================] - 0s 37us/sample - loss: 6.9269\n",
      "[CV]  learning_rate=0.00032983006724298584, n_hidden=1, n_neurons=344, total=  37.5s\n",
      "[CV] learning_rate=0.00032983006724298584, n_hidden=1, n_neurons=344 .\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 349us/sample - loss: 13.7556 - val_loss: 13.4656\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 13.7008 - val_loss: 13.4091\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 13.6458 - val_loss: 13.3534\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 13.5916 - val_loss: 13.2991\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 13.5382 - val_loss: 13.2440\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 13.4840 - val_loss: 13.1889\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 13.4301 - val_loss: 13.1342\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 13.3765 - val_loss: 13.0802\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 13.3232 - val_loss: 13.0261\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 13.2703 - val_loss: 12.9722\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 13.2176 - val_loss: 12.9186\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.1655 - val_loss: 12.8654\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 13.1142 - val_loss: 12.8128\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 13.0633 - val_loss: 12.7607\n",
      "Epoch 15/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 94us/sample - loss: 13.0130 - val_loss: 12.7082\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 12.9620 - val_loss: 12.6555\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 12.9109 - val_loss: 12.6035\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 118us/sample - loss: 12.8604 - val_loss: 12.5514\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 12.8098 - val_loss: 12.4991\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 12.7591 - val_loss: 12.4465\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 12.7084 - val_loss: 12.3945\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 12.6583 - val_loss: 12.3428\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 12.6084 - val_loss: 12.2922\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 12.5593 - val_loss: 12.2416\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 12.5099 - val_loss: 12.1904\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 12.4597 - val_loss: 12.1393\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.4095 - val_loss: 12.0890\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 12.3597 - val_loss: 12.0388\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 12.3103 - val_loss: 11.9895\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 12.2613 - val_loss: 11.9393\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 12.2115 - val_loss: 11.8902\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 12.1626 - val_loss: 11.8406\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 12.1130 - val_loss: 11.7914\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 12.0635 - val_loss: 11.7430\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 12.0147 - val_loss: 11.6940\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 11.9650 - val_loss: 11.6446\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 11.9151 - val_loss: 11.5957\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 11.8656 - val_loss: 11.5468\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 11.8164 - val_loss: 11.4971\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 11.7665 - val_loss: 11.4485\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 11.7179 - val_loss: 11.3992\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 11.6684 - val_loss: 11.3499\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 11.6186 - val_loss: 11.3009\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 11.5693 - val_loss: 11.2515\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 11.5195 - val_loss: 11.2019\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 11.4694 - val_loss: 11.1538\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 11.4209 - val_loss: 11.1044\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 11.3713 - val_loss: 11.0556\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.3217 - val_loss: 11.0066\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 11.2716 - val_loss: 10.9576\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 11.2215 - val_loss: 10.9094\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 11.1712 - val_loss: 10.8605\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 11.1207 - val_loss: 10.8142\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 11.0716 - val_loss: 10.7666\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.0218 - val_loss: 10.7191\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 10.9715 - val_loss: 10.6707\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 10.9203 - val_loss: 10.6226\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 10.8687 - val_loss: 10.5753\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 10.8177 - val_loss: 10.5275\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 10.7658 - val_loss: 10.4793\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 10.7140 - val_loss: 10.4313\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 10.6624 - val_loss: 10.3852\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 10.6121 - val_loss: 10.3386\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 10.5607 - val_loss: 10.2920\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 10.5092 - val_loss: 10.2468\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 10.4591 - val_loss: 10.2006\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 10.4082 - val_loss: 10.1548\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 10.3575 - val_loss: 10.1086\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 10.3068 - val_loss: 10.0618\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.2553 - val_loss: 10.0151\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 10.2044 - val_loss: 9.9677\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.1527 - val_loss: 9.9209\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 10.1021 - val_loss: 9.8750\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 10.0522 - val_loss: 9.8292\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 10.0023 - val_loss: 9.7829\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 9.9517 - val_loss: 9.7371\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 9.9019 - val_loss: 9.6914\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 9.8526 - val_loss: 9.6464\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.8036 - val_loss: 9.6012\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 9.7546 - val_loss: 9.5573\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 9.7075 - val_loss: 9.5118\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 9.6588 - val_loss: 9.4681\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 9.6118 - val_loss: 9.4233\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 9.5634 - val_loss: 9.3785\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 9.5149 - val_loss: 9.3343\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 134us/sample - loss: 9.4668 - val_loss: 9.2918\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 9.4208 - val_loss: 9.2483\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 195us/sample - loss: 9.3734 - val_loss: 9.2053\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 157us/sample - loss: 9.3260 - val_loss: 9.1626\n",
      "Epoch 90/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 108us/sample - loss: 9.2794 - val_loss: 9.1197\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 9.2328 - val_loss: 9.0772\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 9.1865 - val_loss: 9.0366\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 9.1415 - val_loss: 8.9977\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.0978 - val_loss: 8.9587\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.0537 - val_loss: 8.9205\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.0115 - val_loss: 8.8818\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.9690 - val_loss: 8.8430\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.9265 - val_loss: 8.8052\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.8849 - val_loss: 8.7682\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8445 - val_loss: 8.7307\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.8030 - val_loss: 8.6939\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.7618 - val_loss: 8.6580\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.7212 - val_loss: 8.6239\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.6822 - val_loss: 8.5892\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.6428 - val_loss: 8.5545\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.6036 - val_loss: 8.5214\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.5665 - val_loss: 8.4878\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.5296 - val_loss: 8.4559\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.4943 - val_loss: 8.4236\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4591 - val_loss: 8.3913\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.4242 - val_loss: 8.3604\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.3906 - val_loss: 8.3294\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.3573 - val_loss: 8.2975\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.3234 - val_loss: 8.2666\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.2907 - val_loss: 8.2356\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.2581 - val_loss: 8.2057\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2266 - val_loss: 8.1745\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.1941 - val_loss: 8.1450\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.1637 - val_loss: 8.1150\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.1328 - val_loss: 8.0861\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.1034 - val_loss: 8.0577\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.0744 - val_loss: 8.0307\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 8.0471 - val_loss: 8.0029\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.0192 - val_loss: 7.9758\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 7.9918 - val_loss: 7.9490\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 167us/sample - loss: 7.9645 - val_loss: 7.9225\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 139us/sample - loss: 7.9376 - val_loss: 7.8969\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.9118 - val_loss: 7.8707\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.8853 - val_loss: 7.8452\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.8594 - val_loss: 7.8222\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.8353 - val_loss: 7.8002\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 147us/sample - loss: 7.8123 - val_loss: 7.7760\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 180us/sample - loss: 7.7873 - val_loss: 7.7523\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 242us/sample - loss: 7.7628 - val_loss: 7.7303\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 166us/sample - loss: 7.7403 - val_loss: 7.7069\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.7169 - val_loss: 7.6857\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 144us/sample - loss: 7.6958 - val_loss: 7.6649\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 147us/sample - loss: 7.6750 - val_loss: 7.6438\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 128us/sample - loss: 7.6550 - val_loss: 7.6239\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 118us/sample - loss: 7.6357 - val_loss: 7.6042\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 7.6166 - val_loss: 7.5849\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 7.5976 - val_loss: 7.5668\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 119us/sample - loss: 7.5796 - val_loss: 7.5483\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 125us/sample - loss: 7.5609 - val_loss: 7.5301\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 123us/sample - loss: 7.5427 - val_loss: 7.5123\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 145us/sample - loss: 7.5249 - val_loss: 7.4946\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 166us/sample - loss: 7.5065 - val_loss: 7.4777\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 126us/sample - loss: 7.4891 - val_loss: 7.4622\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 118us/sample - loss: 7.4729 - val_loss: 7.4471\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 112us/sample - loss: 7.4572 - val_loss: 7.4318\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.4417 - val_loss: 7.4173\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 111us/sample - loss: 7.4275 - val_loss: 7.4028\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 7.4132 - val_loss: 7.3894\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.4002 - val_loss: 7.3782\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.3888 - val_loss: 7.3655\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.3758 - val_loss: 7.3532\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3631 - val_loss: 7.3403\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.3498 - val_loss: 7.3295\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.3384 - val_loss: 7.3186\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.3271 - val_loss: 7.3083\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 7.3163 - val_loss: 7.2981\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3053 - val_loss: 7.2882\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 7.2950 - val_loss: 7.2798\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 7.2860 - val_loss: 7.2693\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.2751 - val_loss: 7.2601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.2656 - val_loss: 7.2511\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.2563 - val_loss: 7.2423\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.2473 - val_loss: 7.2330\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 7.2382 - val_loss: 7.2236\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.2290 - val_loss: 7.2155\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 7.2210 - val_loss: 7.2073\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.2127 - val_loss: 7.1995\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.2048 - val_loss: 7.1924\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1973 - val_loss: 7.1851\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1894 - val_loss: 7.1791\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1825 - val_loss: 7.1738\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1761 - val_loss: 7.1676\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.1687 - val_loss: 7.1620\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1618 - val_loss: 7.1562\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1549 - val_loss: 7.1502\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1480 - val_loss: 7.1448\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.1417 - val_loss: 7.1394\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1356 - val_loss: 7.1345\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1300 - val_loss: 7.1295\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1242 - val_loss: 7.1251\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.1193 - val_loss: 7.1203\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.1138 - val_loss: 7.1162\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1092 - val_loss: 7.1123\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 7.1042 - val_loss: 7.1090\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.0998 - val_loss: 7.1052\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.0952 - val_loss: 7.1019\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.0907 - val_loss: 7.0982\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 7.0864 - val_loss: 7.0951\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.0823 - val_loss: 7.0925\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 7.0786 - val_loss: 7.0892\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 7.0745 - val_loss: 7.0868\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.0708 - val_loss: 7.0837\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.0666 - val_loss: 7.0809\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.0621 - val_loss: 7.0781\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.0584 - val_loss: 7.0755\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.0544 - val_loss: 7.0729\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 114us/sample - loss: 7.0504 - val_loss: 7.0705\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 7.0469 - val_loss: 7.0687\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 7.0439 - val_loss: 7.0664\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 7.0404 - val_loss: 7.0643\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.0372 - val_loss: 7.0622\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 7.0337 - val_loss: 7.0602\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 7.0305 - val_loss: 7.0582\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.0272 - val_loss: 7.0565\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 7.0243 - val_loss: 7.0545\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 7.0210 - val_loss: 7.0527\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 7.0180 - val_loss: 7.0507\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.0151 - val_loss: 7.0484\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 104us/sample - loss: 7.0121 - val_loss: 7.0465\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 7.0093 - val_loss: 7.0441\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 104us/sample - loss: 7.0064 - val_loss: 7.0425\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.0034 - val_loss: 7.0401\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 7.0006 - val_loss: 7.0384\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 6.9981 - val_loss: 7.0370\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.9959 - val_loss: 7.0355\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9933 - val_loss: 7.0342\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.9913 - val_loss: 7.0327\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.9887 - val_loss: 7.0313\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9863 - val_loss: 7.0298\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9841 - val_loss: 7.0289\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.9822 - val_loss: 7.0281\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.9805 - val_loss: 7.0274\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.9786 - val_loss: 7.0269\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.9770 - val_loss: 7.0261\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.9754 - val_loss: 7.0254\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.9740 - val_loss: 7.0247\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.9727 - val_loss: 7.0242\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.9711 - val_loss: 7.0237\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.9694 - val_loss: 7.0230\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.9679 - val_loss: 7.0225\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.9665 - val_loss: 7.0219\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.9651 - val_loss: 7.0210\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9636 - val_loss: 7.0207\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.9621 - val_loss: 7.0197\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.9607 - val_loss: 7.0193\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 128us/sample - loss: 6.9594 - val_loss: 7.0187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 6.9580 - val_loss: 7.0179\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 6.9567 - val_loss: 7.0175\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.9551 - val_loss: 7.0170\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 6.9537 - val_loss: 7.0167\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 6.9526 - val_loss: 7.0160\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 6.9513 - val_loss: 7.0156\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 6.9502 - val_loss: 7.0151\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 6.9489 - val_loss: 7.0146\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 6.9477 - val_loss: 7.0141\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 6.9466 - val_loss: 7.0137\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.9454 - val_loss: 7.0135\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 6.9446 - val_loss: 7.0131\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 6.9434 - val_loss: 7.0127\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 110us/sample - loss: 6.9426 - val_loss: 7.0126\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 6.9418 - val_loss: 7.0125\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 6.9409 - val_loss: 7.0123\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 6.9400 - val_loss: 7.0119\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 6.9391 - val_loss: 7.0113\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 6.9382 - val_loss: 7.0108\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.9373 - val_loss: 7.0102\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.9364 - val_loss: 7.0103\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.9356 - val_loss: 7.0100\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9348 - val_loss: 7.0095\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9339 - val_loss: 7.0088\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.9331 - val_loss: 7.0082\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.9321 - val_loss: 7.0076\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.9312 - val_loss: 7.0074\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.9303 - val_loss: 7.0070\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.9296 - val_loss: 7.0064\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.9288 - val_loss: 7.0062\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 6.909 - 0s 82us/sample - loss: 6.9280 - val_loss: 7.0058\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.9273 - val_loss: 7.0058\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 6.9267 - val_loss: 7.0057\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 119us/sample - loss: 6.9258 - val_loss: 7.0052\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 6.9251 - val_loss: 7.0049\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.9244 - val_loss: 7.0048\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 6.9236 - val_loss: 7.0047\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 116us/sample - loss: 6.9229 - val_loss: 7.0047\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.9222 - val_loss: 7.0048\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.9214 - val_loss: 7.0046\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.9207 - val_loss: 7.0044\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.9199 - val_loss: 7.0042\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 6.9192 - val_loss: 7.0038\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 6.9186 - val_loss: 7.0037\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.9179 - val_loss: 7.0035\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 6.9172 - val_loss: 7.0037\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.9167 - val_loss: 7.0034\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.9161 - val_loss: 7.0034\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.9155 - val_loss: 7.0033\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.9148 - val_loss: 7.0034\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9141 - val_loss: 7.0032\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9136 - val_loss: 7.0030\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9130 - val_loss: 7.0027\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9123 - val_loss: 7.0026\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9117 - val_loss: 7.0025\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.9110 - val_loss: 7.0023\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9104 - val_loss: 7.0021\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9096 - val_loss: 7.0018\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.9090 - val_loss: 7.0016\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.9083 - val_loss: 7.0015\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.9078 - val_loss: 7.0011\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9071 - val_loss: 7.0008\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9064 - val_loss: 7.0007\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9059 - val_loss: 7.0007\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9054 - val_loss: 7.0005\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9048 - val_loss: 7.0004\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9042 - val_loss: 7.0004\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9035 - val_loss: 7.0003\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9030 - val_loss: 6.9998\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9023 - val_loss: 6.9997\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.9017 - val_loss: 6.9996\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 6.9012 - val_loss: 6.9994\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.9006 - val_loss: 6.9995\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.9000 - val_loss: 6.9993\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.8994 - val_loss: 6.9991\n",
      "Epoch 317/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.8989 - val_loss: 6.9989\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.8982 - val_loss: 6.9986\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.8977 - val_loss: 6.9984\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.8971 - val_loss: 6.9983\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 113us/sample - loss: 6.8965 - val_loss: 6.9983\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.8960 - val_loss: 6.9980\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.8954 - val_loss: 6.9979\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.8949 - val_loss: 6.9980\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.8942 - val_loss: 6.9980\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8936 - val_loss: 6.9977\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8931 - val_loss: 6.9974\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8925 - val_loss: 6.9970\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.8919 - val_loss: 6.9966\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8914 - val_loss: 6.9964\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8908 - val_loss: 6.9961\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8903 - val_loss: 6.9958\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.8897 - val_loss: 6.9952\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8891 - val_loss: 6.9952\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8885 - val_loss: 6.9954\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8879 - val_loss: 6.9951\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.8874 - val_loss: 6.9950\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.8868 - val_loss: 6.9947\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.8863 - val_loss: 6.9947\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.8857 - val_loss: 6.9942\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.8851 - val_loss: 6.9944\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.8847 - val_loss: 6.9939\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.8841 - val_loss: 6.9937\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8836 - val_loss: 6.9936\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8831 - val_loss: 6.9935\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.8826 - val_loss: 6.9934\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.8821 - val_loss: 6.9932\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.8815 - val_loss: 6.9931\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8812 - val_loss: 6.9929\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.8807 - val_loss: 6.9930\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8800 - val_loss: 6.9929\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8795 - val_loss: 6.9930\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.8790 - val_loss: 6.9929\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.8786 - val_loss: 6.9929\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8781 - val_loss: 6.9928\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8776 - val_loss: 6.9926\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.8771 - val_loss: 6.9925\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8767 - val_loss: 6.9922\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 128us/sample - loss: 6.8762 - val_loss: 6.9923\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.8757 - val_loss: 6.9920\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.8751 - val_loss: 6.9919\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8746 - val_loss: 6.9920\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.8741 - val_loss: 6.9918\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.8735 - val_loss: 6.9914\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.8729 - val_loss: 6.9915\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.8725 - val_loss: 6.9916\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.8719 - val_loss: 6.9914\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8715 - val_loss: 6.9915\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8710 - val_loss: 6.9914\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8704 - val_loss: 6.9912\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8700 - val_loss: 6.9913\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8695 - val_loss: 6.9913\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8690 - val_loss: 6.9912\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.8685 - val_loss: 6.9910\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.8679 - val_loss: 6.9910\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.8675 - val_loss: 6.9915\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.8671 - val_loss: 6.9914\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.8666 - val_loss: 6.9913\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 6.8660 - val_loss: 6.9912\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.8656 - val_loss: 6.9909\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.8651 - val_loss: 6.9910\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.8647 - val_loss: 6.9910\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.8643 - val_loss: 6.9910\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.8638 - val_loss: 6.9908\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 6.8633 - val_loss: 6.9907\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 6.8628 - val_loss: 6.9903\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 6.8624 - val_loss: 6.9903\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.8619 - val_loss: 6.9903\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.8615 - val_loss: 6.9901\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.8610 - val_loss: 6.9904\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.8606 - val_loss: 6.9900\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 142us/sample - loss: 6.8600 - val_loss: 6.9897\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8595 - val_loss: 6.9897\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 6.8591 - val_loss: 6.9898\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.8587 - val_loss: 6.9899\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.8580 - val_loss: 6.9900\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.8577 - val_loss: 6.9897\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8572 - val_loss: 6.9897\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8567 - val_loss: 6.9896\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8563 - val_loss: 6.9899\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8557 - val_loss: 6.9898\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.8553 - val_loss: 6.9899\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.8547 - val_loss: 6.9897\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.8544 - val_loss: 6.9894\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8538 - val_loss: 6.9898\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.8533 - val_loss: 6.9894\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.8530 - val_loss: 6.9892\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8523 - val_loss: 6.9895\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8519 - val_loss: 6.9894\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8515 - val_loss: 6.9893\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.8511 - val_loss: 6.9894\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.8505 - val_loss: 6.9893\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8501 - val_loss: 6.9894\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.8497 - val_loss: 6.9895\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 6.8492 - val_loss: 6.9895\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.8488 - val_loss: 6.9893\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.8484 - val_loss: 6.9888\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.8480 - val_loss: 6.9887\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.8475 - val_loss: 6.9885\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.8471 - val_loss: 6.9888\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8466 - val_loss: 6.9888\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.8461 - val_loss: 6.9887\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8458 - val_loss: 6.9887\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.8452 - val_loss: 6.9887\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.8448 - val_loss: 6.9888\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8445 - val_loss: 6.9886\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8439 - val_loss: 6.9887\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8435 - val_loss: 6.9886\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.8431 - val_loss: 6.9886\n",
      "594/594 [==============================] - 0s 39us/sample - loss: 7.5741\n",
      "[CV]  learning_rate=0.00032983006724298584, n_hidden=1, n_neurons=344, total=  47.6s\n",
      "[CV] learning_rate=0.00032983006724298584, n_hidden=1, n_neurons=344 .\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 1s 525us/sample - loss: 13.8522 - val_loss: 13.6935\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.7957 - val_loss: 13.6371\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.7398 - val_loss: 13.5816\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.6844 - val_loss: 13.5265\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.6292 - val_loss: 13.4716\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.5740 - val_loss: 13.4166\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 13.5195 - val_loss: 13.3623\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.4656 - val_loss: 13.3080\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.4119 - val_loss: 13.2539\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 13.3585 - val_loss: 13.2000\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 13.3052 - val_loss: 13.1458\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 13.2517 - val_loss: 13.0918\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 13.1985 - val_loss: 13.0386\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 13.1463 - val_loss: 12.9862\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 13.0949 - val_loss: 12.9338\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 13.0436 - val_loss: 12.8800\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 12.9911 - val_loss: 12.8267\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 12.9393 - val_loss: 12.7739\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 12.8877 - val_loss: 12.7211\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 12.8360 - val_loss: 12.6685\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.7846 - val_loss: 12.6160\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 12.7335 - val_loss: 12.5647\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 12.6830 - val_loss: 12.5132\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 12.6336 - val_loss: 12.4635\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 12.5857 - val_loss: 12.4134\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.5372 - val_loss: 12.3630\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 12.4884 - val_loss: 12.3127\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 12.4399 - val_loss: 12.2633\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 12.3925 - val_loss: 12.2158\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 12.3464 - val_loss: 12.1654\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 12.2979 - val_loss: 12.1158\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 12.2500 - val_loss: 12.0659\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 12.2014 - val_loss: 12.0159\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 12.1526 - val_loss: 11.9671\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 12.20 - 0s 79us/sample - loss: 12.1052 - val_loss: 11.9175\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 12.0567 - val_loss: 11.8685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 12.0088 - val_loss: 11.8200\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 11.9611 - val_loss: 11.7718\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.9136 - val_loss: 11.7230\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.8655 - val_loss: 11.6747\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 11.88 - 0s 83us/sample - loss: 11.8182 - val_loss: 11.6264\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.7716 - val_loss: 11.5795\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.7261 - val_loss: 11.5327\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 11.6807 - val_loss: 11.4854\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.6353 - val_loss: 11.4382\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.5901 - val_loss: 11.3919\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 11.5459 - val_loss: 11.3448\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 11.5009 - val_loss: 11.2976\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 11.4557 - val_loss: 11.2519\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 11.4117 - val_loss: 11.2048\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.3667 - val_loss: 11.1584\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 11.3221 - val_loss: 11.1111\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.2769 - val_loss: 11.0650\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.2324 - val_loss: 11.0179\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.1872 - val_loss: 10.9715\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.1430 - val_loss: 10.9247\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.0984 - val_loss: 10.8783\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.0540 - val_loss: 10.8313\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 11.0093 - val_loss: 10.7853\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 10.9653 - val_loss: 10.7392\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 10.9215 - val_loss: 10.6937\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 10.8784 - val_loss: 10.6500\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.8363 - val_loss: 10.6056\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.7937 - val_loss: 10.5606\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.7506 - val_loss: 10.5155\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 10.7073 - val_loss: 10.4710\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.6640 - val_loss: 10.4260\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.6205 - val_loss: 10.3818\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.5772 - val_loss: 10.3386\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.5348 - val_loss: 10.2955\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 10.4921 - val_loss: 10.2524\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 10.4494 - val_loss: 10.2090\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 10.4057 - val_loss: 10.1668\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 10.3631 - val_loss: 10.1255\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 10.3216 - val_loss: 10.0828\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 10.2785 - val_loss: 10.0409\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 10.2363 - val_loss: 10.0008\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 10.1955 - val_loss: 9.9591\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 10.1528 - val_loss: 9.9174\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 10.1104 - val_loss: 9.8773\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 10.0698 - val_loss: 9.8356\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 10.0277 - val_loss: 9.7957\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 9.9883 - val_loss: 9.7541\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 9.9473 - val_loss: 9.7133\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 9.9070 - val_loss: 9.6734\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.8675 - val_loss: 9.6335\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.8278 - val_loss: 9.5939\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.7881 - val_loss: 9.5542\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.7485 - val_loss: 9.5138\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.7083 - val_loss: 9.4745\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.6689 - val_loss: 9.4338\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.6282 - val_loss: 9.3952\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5894 - val_loss: 9.3552\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.5491 - val_loss: 9.3155\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5088 - val_loss: 9.2772\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.4699 - val_loss: 9.2398\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.4322 - val_loss: 9.2007\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.3932 - val_loss: 9.1624\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 9.3553 - val_loss: 9.1257\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.3183 - val_loss: 9.0892\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.2813 - val_loss: 9.0519\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.2433 - val_loss: 9.0146\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.2054 - val_loss: 8.9779\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.1679 - val_loss: 8.9428\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.1317 - val_loss: 8.9065\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.0942 - val_loss: 8.8725\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.0592 - val_loss: 8.8372\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.0227 - val_loss: 8.8021\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.9859 - val_loss: 8.7687\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.9503 - val_loss: 8.7358\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 112us/sample - loss: 8.9150 - val_loss: 8.7023\n",
      "Epoch 112/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 105us/sample - loss: 8.8796 - val_loss: 8.6688\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 8.8449 - val_loss: 8.6360\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 126us/sample - loss: 8.8104 - val_loss: 8.6042\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 8.7769 - val_loss: 8.5719\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 8.7429 - val_loss: 8.5407\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 8.7107 - val_loss: 8.5092\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 8.6782 - val_loss: 8.4804\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 8.6490 - val_loss: 8.4507\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 8.6194 - val_loss: 8.4202\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 8.5891 - val_loss: 8.3899\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 8.5594 - val_loss: 8.3612\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 8.5310 - val_loss: 8.3320\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 8.5021 - val_loss: 8.3040\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 8.4743 - val_loss: 8.2758\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 8.4464 - val_loss: 8.2475\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 104us/sample - loss: 8.4183 - val_loss: 8.2207\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 126us/sample - loss: 8.3920 - val_loss: 8.1934\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 8.3646 - val_loss: 8.1669\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 112us/sample - loss: 8.3373 - val_loss: 8.1417\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 8.3116 - val_loss: 8.1173\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 8.2865 - val_loss: 8.0912\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 8.2597 - val_loss: 8.0657\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 8.2330 - val_loss: 8.0406\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 8.2075 - val_loss: 8.0153\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.1817 - val_loss: 7.9913\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.1570 - val_loss: 7.9683\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.1335 - val_loss: 7.9445\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1094 - val_loss: 7.9214\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.0862 - val_loss: 7.8977\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 8.0623 - val_loss: 7.8735\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.0386 - val_loss: 7.8506\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.0164 - val_loss: 7.8273\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.9936 - val_loss: 7.8056\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.9725 - val_loss: 7.7824\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.9507 - val_loss: 7.7614\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.9311 - val_loss: 7.7407\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.9114 - val_loss: 7.7212\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8926 - val_loss: 7.7028\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.8755 - val_loss: 7.6845\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.8583 - val_loss: 7.6679\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.8428 - val_loss: 7.6510\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.8272 - val_loss: 7.6343\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 7.8117 - val_loss: 7.6181\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 7.7964 - val_loss: 7.6000\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.7795 - val_loss: 7.5825\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.7633 - val_loss: 7.5662\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.7480 - val_loss: 7.5504\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.7336 - val_loss: 7.5339\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.7182 - val_loss: 7.5189\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 7.7044 - val_loss: 7.5042\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.6908 - val_loss: 7.4893\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.6775 - val_loss: 7.4754\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.6652 - val_loss: 7.4599\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6514 - val_loss: 7.4463\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.6391 - val_loss: 7.4323\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6266 - val_loss: 7.4193\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.6149 - val_loss: 7.4067\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6036 - val_loss: 7.3936\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.5920 - val_loss: 7.3810\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.5807 - val_loss: 7.3690\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 7.5698 - val_loss: 7.3572\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 7.5589 - val_loss: 7.3470\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.5492 - val_loss: 7.3369\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.5395 - val_loss: 7.3261\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.5293 - val_loss: 7.3168\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 118us/sample - loss: 7.5204 - val_loss: 7.3067\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 7.5105 - val_loss: 7.2974\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 7.5010 - val_loss: 7.2880\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 7.4917 - val_loss: 7.2783\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.4820 - val_loss: 7.2697\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.4738 - val_loss: 7.2603\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.4648 - val_loss: 7.2516\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 7.4564 - val_loss: 7.2423\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 7.4473 - val_loss: 7.2346\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 7.4395 - val_loss: 7.2263\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 129us/sample - loss: 7.4314 - val_loss: 7.2180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 7.4234 - val_loss: 7.2097\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 7.4154 - val_loss: 7.2023\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 7.4081 - val_loss: 7.1949\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 7.4008 - val_loss: 7.1882\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 125us/sample - loss: 7.3942 - val_loss: 7.1811\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 7.3877 - val_loss: 7.1742\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 119us/sample - loss: 7.3812 - val_loss: 7.1679\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 121us/sample - loss: 7.3754 - val_loss: 7.1607\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 114us/sample - loss: 7.3686 - val_loss: 7.1545\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 119us/sample - loss: 7.3629 - val_loss: 7.1475\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 109us/sample - loss: 7.3568 - val_loss: 7.1406\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 7.3507 - val_loss: 7.1348\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 129us/sample - loss: 7.3455 - val_loss: 7.1293\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 7.3407 - val_loss: 7.1244\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 120us/sample - loss: 7.3364 - val_loss: 7.1191\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 7.3320 - val_loss: 7.1150\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.3282 - val_loss: 7.1108\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 7.3244 - val_loss: 7.1064\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 109us/sample - loss: 7.3208 - val_loss: 7.1023\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 110us/sample - loss: 7.3169 - val_loss: 7.0983\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 7.3132 - val_loss: 7.0953\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.3099 - val_loss: 7.0924\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 7.3068 - val_loss: 7.0887\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 7.3030 - val_loss: 7.0854\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 7.2997 - val_loss: 7.0827\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 117us/sample - loss: 7.2970 - val_loss: 7.0795\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 111us/sample - loss: 7.2940 - val_loss: 7.0764\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 135us/sample - loss: 7.2910 - val_loss: 7.0742\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 7.2883 - val_loss: 7.0720\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 115us/sample - loss: 7.2859 - val_loss: 7.0696\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 7.2832 - val_loss: 7.0671\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.2806 - val_loss: 7.0649\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 7.2782 - val_loss: 7.0621\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 132us/sample - loss: 7.2749 - val_loss: 7.0595\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 7.2719 - val_loss: 7.0572\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2693 - val_loss: 7.0549\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2665 - val_loss: 7.0524\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.2639 - val_loss: 7.0511\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2618 - val_loss: 7.0494\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2598 - val_loss: 7.0479\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2577 - val_loss: 7.0468\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2558 - val_loss: 7.0450\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2535 - val_loss: 7.0435\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2515 - val_loss: 7.0425\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2499 - val_loss: 7.0412\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2479 - val_loss: 7.0398\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2460 - val_loss: 7.0384\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 58us/sample - loss: 7.2439 - val_loss: 7.0372\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2419 - val_loss: 7.0361\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2401 - val_loss: 7.0347\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.2384 - val_loss: 7.0335\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.2365 - val_loss: 7.0318\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2344 - val_loss: 7.0310\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2328 - val_loss: 7.0300\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2309 - val_loss: 7.0287\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2291 - val_loss: 7.0277\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2273 - val_loss: 7.0267\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2256 - val_loss: 7.0259\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2241 - val_loss: 7.0251\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2223 - val_loss: 7.0242\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2206 - val_loss: 7.0232\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2188 - val_loss: 7.0221\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2172 - val_loss: 7.0210\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2155 - val_loss: 7.0201\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.2138 - val_loss: 7.0194\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2125 - val_loss: 7.0184\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2108 - val_loss: 7.0178\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2094 - val_loss: 7.0171\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.2079 - val_loss: 7.0165\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2066 - val_loss: 7.0160\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2053 - val_loss: 7.0153\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2036 - val_loss: 7.0145\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2023 - val_loss: 7.0139\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2008 - val_loss: 7.0137\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1994 - val_loss: 7.0135\n",
      "Epoch 263/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1977 - val_loss: 7.0132\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1964 - val_loss: 7.0128\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1948 - val_loss: 7.0122\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1936 - val_loss: 7.0117\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1920 - val_loss: 7.0112\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1905 - val_loss: 7.0113\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1892 - val_loss: 7.0114\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.1881 - val_loss: 7.0114\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1869 - val_loss: 7.0111\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1855 - val_loss: 7.0110\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1844 - val_loss: 7.0108\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1834 - val_loss: 7.0106\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1820 - val_loss: 7.0105\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1811 - val_loss: 7.0102\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1800 - val_loss: 7.0103\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1787 - val_loss: 7.0103\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1776 - val_loss: 7.0106\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1766 - val_loss: 7.0103\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1756 - val_loss: 7.0102\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1746 - val_loss: 7.0103\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1736 - val_loss: 7.0103\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1728 - val_loss: 7.0105\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1719 - val_loss: 7.0106\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1711 - val_loss: 7.0107\n",
      "594/594 [==============================] - 0s 41us/sample - loss: 7.0613\n",
      "[CV]  learning_rate=0.00032983006724298584, n_hidden=1, n_neurons=344, total=  31.2s\n",
      "[CV] learning_rate=0.013867767003062484, n_hidden=1, n_neurons=386 ...\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 304us/sample - loss: 12.9220 - val_loss: 11.5028\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.9030 - val_loss: 9.6232\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 9.1716 - val_loss: 8.1789\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.0157 - val_loss: 7.3868\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.5061 - val_loss: 7.0978\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3127 - val_loss: 7.0285\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2507 - val_loss: 6.9909\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2078 - val_loss: 6.9994\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1847 - val_loss: 7.0032\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1632 - val_loss: 7.0050\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.1439 - val_loss: 7.0024\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1296 - val_loss: 7.0008\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1137 - val_loss: 7.0105\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1070 - val_loss: 7.0100\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.0930 - val_loss: 7.0064\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.0802 - val_loss: 6.9900\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.0704 - val_loss: 7.0165\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.0644 - val_loss: 6.9878\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0576 - val_loss: 6.9871\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0476 - val_loss: 7.0019\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.0453 - val_loss: 7.0020\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0333 - val_loss: 6.9983\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.0257 - val_loss: 7.0039\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.0176 - val_loss: 6.9973\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.0132 - val_loss: 6.9869\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.0108 - val_loss: 6.9597\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.0020 - val_loss: 6.9683\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9962 - val_loss: 6.9674\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9886 - val_loss: 6.9643\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.9833 - val_loss: 6.9711\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9762 - val_loss: 6.9613\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9699 - val_loss: 6.9675\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9700 - val_loss: 6.9820\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9623 - val_loss: 6.9890\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9525 - val_loss: 6.9819\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9469 - val_loss: 6.9702\n",
      "594/594 [==============================] - 0s 39us/sample - loss: 6.9985\n",
      "[CV]  learning_rate=0.013867767003062484, n_hidden=1, n_neurons=386, total=   3.9s\n",
      "[CV] learning_rate=0.013867767003062484, n_hidden=1, n_neurons=386 ...\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 304us/sample - loss: 12.9600 - val_loss: 11.5981\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.8786 - val_loss: 9.6490\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.9734 - val_loss: 8.0758\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.7066 - val_loss: 7.3458\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2065 - val_loss: 7.0865\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0200 - val_loss: 7.0182\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9495 - val_loss: 6.9887\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9103 - val_loss: 6.9968\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 6.8905 - val_loss: 6.9974\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.8666 - val_loss: 7.0025\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 6.8499 - val_loss: 6.9999\n",
      "Epoch 12/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 83us/sample - loss: 6.8292 - val_loss: 7.0045\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.8112 - val_loss: 7.0047\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.7986 - val_loss: 7.0102\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 6.7879 - val_loss: 7.0007\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.7734 - val_loss: 7.0076\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.7636 - val_loss: 7.0014\n",
      "594/594 [==============================] - 0s 36us/sample - loss: 7.5698\n",
      "[CV]  learning_rate=0.013867767003062484, n_hidden=1, n_neurons=386, total=   2.1s\n",
      "[CV] learning_rate=0.013867767003062484, n_hidden=1, n_neurons=386 ...\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 297us/sample - loss: 12.6352 - val_loss: 11.4136\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.7033 - val_loss: 9.5628\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.0207 - val_loss: 8.0814\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.8954 - val_loss: 7.3485\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.4300 - val_loss: 7.0626\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2682 - val_loss: 6.9944\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2139 - val_loss: 6.9707\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1771 - val_loss: 6.9862\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1557 - val_loss: 6.9745\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1408 - val_loss: 6.9761\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.1275 - val_loss: 6.9941\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1159 - val_loss: 6.9931\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1052 - val_loss: 6.9993\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.0948 - val_loss: 6.9888\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.0875 - val_loss: 6.9994\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0758 - val_loss: 6.9867\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0687 - val_loss: 6.9947\n",
      "594/594 [==============================] - 0s 37us/sample - loss: 7.0043\n",
      "[CV]  learning_rate=0.013867767003062484, n_hidden=1, n_neurons=386, total=   2.0s\n",
      "[CV] learning_rate=0.0006930605663535878, n_hidden=0, n_neurons=161 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 274us/sample - loss: 14.1080 - val_loss: 13.8143\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 14.0842 - val_loss: 13.7909\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 14.0606 - val_loss: 13.7675\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 14.0371 - val_loss: 13.7439\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 14.0133 - val_loss: 13.7204\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.9895 - val_loss: 13.6969\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.9658 - val_loss: 13.6735\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.9421 - val_loss: 13.6503\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.9184 - val_loss: 13.6272\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.8949 - val_loss: 13.6040\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.8714 - val_loss: 13.5810\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.8479 - val_loss: 13.5580\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.8246 - val_loss: 13.5353\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.8016 - val_loss: 13.5124\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 13.7783 - val_loss: 13.4896\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.7551 - val_loss: 13.4670\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.7320 - val_loss: 13.4444\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.7090 - val_loss: 13.4217\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.6860 - val_loss: 13.3996\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.6633 - val_loss: 13.3772\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.6403 - val_loss: 13.3547\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.6173 - val_loss: 13.3326\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 13.5946 - val_loss: 13.3102\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.5716 - val_loss: 13.2880\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 13.5488 - val_loss: 13.2659\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.5260 - val_loss: 13.2438\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.5032 - val_loss: 13.2219\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.4805 - val_loss: 13.1999\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.4578 - val_loss: 13.1780\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.4352 - val_loss: 13.1561\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.4126 - val_loss: 13.1345\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.3901 - val_loss: 13.1128\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.3677 - val_loss: 13.0912\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 13.3453 - val_loss: 13.0695\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.3229 - val_loss: 13.0478\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.3005 - val_loss: 13.0260\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.2782 - val_loss: 13.0045\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.2559 - val_loss: 12.9829\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.2337 - val_loss: 12.9615\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.2116 - val_loss: 12.9401\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.1895 - val_loss: 12.9187\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.1675 - val_loss: 12.8972\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 13.1456 - val_loss: 12.8761\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.1240 - val_loss: 12.8548\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.1021 - val_loss: 12.8338\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.0806 - val_loss: 12.8128\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.0590 - val_loss: 12.7919\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 13.0375 - val_loss: 12.7711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.0159 - val_loss: 12.7500\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.9942 - val_loss: 12.7289\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.9725 - val_loss: 12.7080\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.9509 - val_loss: 12.6871\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.9294 - val_loss: 12.6661\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.9080 - val_loss: 12.6453\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.8866 - val_loss: 12.6244\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.8654 - val_loss: 12.6040\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.8446 - val_loss: 12.5836\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.8237 - val_loss: 12.5630\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.8028 - val_loss: 12.5425\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.7820 - val_loss: 12.5219\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.7611 - val_loss: 12.5014\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7403 - val_loss: 12.4810\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.7196 - val_loss: 12.4605\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.6990 - val_loss: 12.4403\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 12.6784 - val_loss: 12.4201\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.6578 - val_loss: 12.4001\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.6374 - val_loss: 12.3800\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.6169 - val_loss: 12.3600\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.5964 - val_loss: 12.3400\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.5761 - val_loss: 12.3201\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.5557 - val_loss: 12.3002\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 12.5353 - val_loss: 12.2802\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.5151 - val_loss: 12.2604\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.4950 - val_loss: 12.2406\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.4748 - val_loss: 12.2210\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.4548 - val_loss: 12.2016\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 12.4350 - val_loss: 12.1824\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.4151 - val_loss: 12.1632\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.3952 - val_loss: 12.1441\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.3754 - val_loss: 12.1248\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.3557 - val_loss: 12.1058\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.3360 - val_loss: 12.0868\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.3163 - val_loss: 12.0682\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.2968 - val_loss: 12.0495\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.2774 - val_loss: 12.0309\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.2581 - val_loss: 12.0121\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.2387 - val_loss: 11.9934\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.2194 - val_loss: 11.9750\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 12.2002 - val_loss: 11.9570\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.1815 - val_loss: 11.9385\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 12.1623 - val_loss: 11.9205\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.1437 - val_loss: 11.9021\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.1246 - val_loss: 11.8840\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.1058 - val_loss: 11.8657\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.0868 - val_loss: 11.8472\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.0678 - val_loss: 11.8291\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.0491 - val_loss: 11.8109\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.0302 - val_loss: 11.7924\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.0114 - val_loss: 11.7749\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.9929 - val_loss: 11.7571\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.9746 - val_loss: 11.7393\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.9565 - val_loss: 11.7219\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.9385 - val_loss: 11.7041\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.9205 - val_loss: 11.6867\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.9027 - val_loss: 11.6691\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.8848 - val_loss: 11.6517\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.8671 - val_loss: 11.6341\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.8491 - val_loss: 11.6165\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.8312 - val_loss: 11.5993\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.8135 - val_loss: 11.5818\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.7956 - val_loss: 11.5647\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.7777 - val_loss: 11.5474\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.7600 - val_loss: 11.5304\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.7424 - val_loss: 11.5138\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.7254 - val_loss: 11.4964\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.7077 - val_loss: 11.4793\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.6901 - val_loss: 11.4623\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.6725 - val_loss: 11.4453\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 11.6549 - val_loss: 11.4284\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.6373 - val_loss: 11.4115\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.6198 - val_loss: 11.3945\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.6024 - val_loss: 11.3777\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.5850 - val_loss: 11.3611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.5680 - val_loss: 11.3442\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.5507 - val_loss: 11.3273\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.5334 - val_loss: 11.3106\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.5163 - val_loss: 11.2939\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.4992 - val_loss: 11.2773\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.4823 - val_loss: 11.2606\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.4653 - val_loss: 11.2439\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.4483 - val_loss: 11.2274\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.4313 - val_loss: 11.2110\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.4145 - val_loss: 11.1950\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.3976 - val_loss: 11.1790\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.3806 - val_loss: 11.1630\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.3641 - val_loss: 11.1474\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.3480 - val_loss: 11.1314\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.3315 - val_loss: 11.1155\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.3150 - val_loss: 11.1001\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 11.2988 - val_loss: 11.0844\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 11.2824 - val_loss: 11.0689\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.2663 - val_loss: 11.0533\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.2501 - val_loss: 11.0381\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.2342 - val_loss: 11.0228\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.2181 - val_loss: 11.0077\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.2023 - val_loss: 10.9925\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.1863 - val_loss: 10.9773\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.1706 - val_loss: 10.9625\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.1551 - val_loss: 10.9477\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.1397 - val_loss: 10.9330\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.1242 - val_loss: 10.9184\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.1088 - val_loss: 10.9038\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.0933 - val_loss: 10.8894\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.0781 - val_loss: 10.8750\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.0629 - val_loss: 10.8604\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.0476 - val_loss: 10.8460\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.0324 - val_loss: 10.8316\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.0172 - val_loss: 10.8174\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 11.0021 - val_loss: 10.8032\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.9869 - val_loss: 10.7892\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.9721 - val_loss: 10.7752\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.9573 - val_loss: 10.7608\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.9423 - val_loss: 10.7470\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.9279 - val_loss: 10.7331\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.9132 - val_loss: 10.7195\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.8989 - val_loss: 10.7058\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.8843 - val_loss: 10.6919\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 10.8695 - val_loss: 10.6781\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.8548 - val_loss: 10.6641\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.8401 - val_loss: 10.6503\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.8257 - val_loss: 10.6366\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.8113 - val_loss: 10.6230\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.7970 - val_loss: 10.6094\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.7827 - val_loss: 10.5957\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.7682 - val_loss: 10.5819\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.7537 - val_loss: 10.5685\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 10.7395 - val_loss: 10.5552\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.7255 - val_loss: 10.5420\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.7114 - val_loss: 10.5285\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.6970 - val_loss: 10.5153\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.6829 - val_loss: 10.5019\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.6687 - val_loss: 10.4886\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.6545 - val_loss: 10.4755\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.6406 - val_loss: 10.4624\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.6267 - val_loss: 10.4492\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.6128 - val_loss: 10.4363\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.5990 - val_loss: 10.4233\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.5853 - val_loss: 10.4101\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.5714 - val_loss: 10.3969\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.5576 - val_loss: 10.3840\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.5441 - val_loss: 10.3711\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.5305 - val_loss: 10.3583\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 55us/sample - loss: 10.5170 - val_loss: 10.3456\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.5035 - val_loss: 10.3326\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.4899 - val_loss: 10.3196\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.4762 - val_loss: 10.3073\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.4629 - val_loss: 10.2945\n",
      "Epoch 198/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 63us/sample - loss: 10.4494 - val_loss: 10.2817\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.4359 - val_loss: 10.2692\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.4226 - val_loss: 10.2567\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4094 - val_loss: 10.2440\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.3960 - val_loss: 10.2313\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.3825 - val_loss: 10.2190\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.3696 - val_loss: 10.2064\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.3563 - val_loss: 10.1940\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.3433 - val_loss: 10.1817\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.3305 - val_loss: 10.1695\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 10.3177 - val_loss: 10.1570\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.3046 - val_loss: 10.1453\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.2919 - val_loss: 10.1333\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.2791 - val_loss: 10.1210\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.2660 - val_loss: 10.1089\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.2533 - val_loss: 10.0969\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.2407 - val_loss: 10.0846\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.2278 - val_loss: 10.0722\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.2149 - val_loss: 10.0601\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.2022 - val_loss: 10.0478\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1896 - val_loss: 10.0357\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.1769 - val_loss: 10.0237\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.1646 - val_loss: 10.0117\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.1521 - val_loss: 10.0001\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.1402 - val_loss: 9.9882\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.1278 - val_loss: 9.9767\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1160 - val_loss: 9.9649\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.1039 - val_loss: 9.9530\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.0916 - val_loss: 9.9411\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.0793 - val_loss: 9.9293\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.0671 - val_loss: 9.9174\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.0549 - val_loss: 9.9055\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0428 - val_loss: 9.8939\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.0309 - val_loss: 9.8824\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.0190 - val_loss: 9.8708\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.0072 - val_loss: 9.8592\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.9951 - val_loss: 9.8474\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.9831 - val_loss: 9.8361\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.9714 - val_loss: 9.8251\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.9598 - val_loss: 9.8137\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.9480 - val_loss: 9.8024\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.9363 - val_loss: 9.7917\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.9252 - val_loss: 9.7805\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.9136 - val_loss: 9.7695\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.9021 - val_loss: 9.7587\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.8909 - val_loss: 9.7475\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.8793 - val_loss: 9.7366\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.8679 - val_loss: 9.7258\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8568 - val_loss: 9.7148\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.8454 - val_loss: 9.7039\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.8341 - val_loss: 9.6931\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.8227 - val_loss: 9.6825\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.8117 - val_loss: 9.6719\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.8006 - val_loss: 9.6614\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7896 - val_loss: 9.6508\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.7786 - val_loss: 9.6402\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7675 - val_loss: 9.6298\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.7566 - val_loss: 9.6197\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.7461 - val_loss: 9.6092\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.7352 - val_loss: 9.5988\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.7246 - val_loss: 9.5886\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.7140 - val_loss: 9.5784\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.7035 - val_loss: 9.5682\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.6929 - val_loss: 9.5577\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.6822 - val_loss: 9.5474\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.6716 - val_loss: 9.5371\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.6611 - val_loss: 9.5272\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.6508 - val_loss: 9.5169\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.6403 - val_loss: 9.5069\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.6300 - val_loss: 9.4967\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6195 - val_loss: 9.4863\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.6090 - val_loss: 9.4760\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5986 - val_loss: 9.4658\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.5882 - val_loss: 9.4556\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.5779 - val_loss: 9.4458\n",
      "Epoch 273/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5678 - val_loss: 9.4362\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.5579 - val_loss: 9.4261\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.5475 - val_loss: 9.4165\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.5376 - val_loss: 9.4070\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.5277 - val_loss: 9.3973\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.5174 - val_loss: 9.3876\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.5076 - val_loss: 9.3778\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4975 - val_loss: 9.3681\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.4875 - val_loss: 9.3585\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 157us/sample - loss: 9.4777 - val_loss: 9.3490\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 9.4680 - val_loss: 9.3395\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.4583 - val_loss: 9.3302\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.4486 - val_loss: 9.3206\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4388 - val_loss: 9.3114\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.4294 - val_loss: 9.3022\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4200 - val_loss: 9.2929\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.4106 - val_loss: 9.2834\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.4009 - val_loss: 9.2739\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.3912 - val_loss: 9.2645\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.3817 - val_loss: 9.2550\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.3721 - val_loss: 9.2458\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.3628 - val_loss: 9.2368\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 9.3536 - val_loss: 9.2276\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.3444 - val_loss: 9.2186\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 9.3353 - val_loss: 9.2095\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.3263 - val_loss: 9.2003\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.3171 - val_loss: 9.1913\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.3080 - val_loss: 9.1823\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.2989 - val_loss: 9.1732\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.2897 - val_loss: 9.1644\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.2809 - val_loss: 9.1553\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.2720 - val_loss: 9.1464\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.2632 - val_loss: 9.1375\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 9.2544 - val_loss: 9.1285\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 9.2456 - val_loss: 9.1199\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.2370 - val_loss: 9.1110\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.2282 - val_loss: 9.1024\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.2197 - val_loss: 9.0936\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.2110 - val_loss: 9.0847\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.2022 - val_loss: 9.0762\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.1937 - val_loss: 9.0675\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.1851 - val_loss: 9.0589\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.1765 - val_loss: 9.0503\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.1681 - val_loss: 9.0421\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.1599 - val_loss: 9.0333\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.1513 - val_loss: 9.0247\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.1428 - val_loss: 9.0161\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1345 - val_loss: 9.0079\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1263 - val_loss: 8.9996\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.1182 - val_loss: 8.9914\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.1101 - val_loss: 8.9833\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.1019 - val_loss: 8.9750\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.0934 - val_loss: 8.9666\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.0850 - val_loss: 8.9584\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0768 - val_loss: 8.9502\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.0686 - val_loss: 8.9423\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.0607 - val_loss: 8.9340\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.0524 - val_loss: 8.9258\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0442 - val_loss: 8.9179\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.0365 - val_loss: 8.9100\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.0286 - val_loss: 8.9018\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 9.0206 - val_loss: 8.8939\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.0127 - val_loss: 8.8860\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.0049 - val_loss: 8.8782\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.9970 - val_loss: 8.8702\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.9892 - val_loss: 8.8622\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.9813 - val_loss: 8.8543\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.9734 - val_loss: 8.8466\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.9657 - val_loss: 8.8390\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.9582 - val_loss: 8.8311\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.9503 - val_loss: 8.8234\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.9427 - val_loss: 8.8156\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9350 - val_loss: 8.8083\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9276 - val_loss: 8.8007\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 8.9200 - val_loss: 8.7934\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.9127 - val_loss: 8.7855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.9050 - val_loss: 8.7780\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.8975 - val_loss: 8.7703\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.8899 - val_loss: 8.7627\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8824 - val_loss: 8.7554\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.8753 - val_loss: 8.7479\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.8680 - val_loss: 8.7405\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8606 - val_loss: 8.7329\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.8531 - val_loss: 8.7254\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.8456 - val_loss: 8.7178\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.8381 - val_loss: 8.7102\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 8.8306 - val_loss: 8.7026\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 8.796 - 0s 79us/sample - loss: 8.8230 - val_loss: 8.6951\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.8155 - val_loss: 8.6876\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.8081 - val_loss: 8.6801\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.8006 - val_loss: 8.6730\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.7935 - val_loss: 8.6654\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.7860 - val_loss: 8.6583\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7789 - val_loss: 8.6508\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.7715 - val_loss: 8.6436\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.7645 - val_loss: 8.6363\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.7573 - val_loss: 8.6289\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.7499 - val_loss: 8.6216\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.7428 - val_loss: 8.6146\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.7359 - val_loss: 8.6075\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.7288 - val_loss: 8.6004\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 8.7215 - val_loss: 8.5933\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.7144 - val_loss: 8.5862\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.7073 - val_loss: 8.5790\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.7001 - val_loss: 8.5721\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.6933 - val_loss: 8.5654\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6866 - val_loss: 8.5585\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.6797 - val_loss: 8.5517\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 8.6730 - val_loss: 8.5449\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.6662 - val_loss: 8.5380\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.6595 - val_loss: 8.5313\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6527 - val_loss: 8.5245\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.6460 - val_loss: 8.5178\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.6394 - val_loss: 8.5112\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.6329 - val_loss: 8.5044\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.6262 - val_loss: 8.4977\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6195 - val_loss: 8.4908\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.6129 - val_loss: 8.4844\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.6065 - val_loss: 8.4775\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.5998 - val_loss: 8.4709\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.5934 - val_loss: 8.4643\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5867 - val_loss: 8.4579\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.5803 - val_loss: 8.4514\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.5738 - val_loss: 8.4450\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.5674 - val_loss: 8.4387\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.5609 - val_loss: 8.4323\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.5545 - val_loss: 8.4260\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.5482 - val_loss: 8.4198\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.5418 - val_loss: 8.4138\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.5357 - val_loss: 8.4079\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.5296 - val_loss: 8.4016\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.5233 - val_loss: 8.3956\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5171 - val_loss: 8.3895\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5111 - val_loss: 8.3835\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.5051 - val_loss: 8.3775\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.4989 - val_loss: 8.3718\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.4933 - val_loss: 8.3660\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4874 - val_loss: 8.3598\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.4813 - val_loss: 8.3541\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.4755 - val_loss: 8.3484\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.4697 - val_loss: 8.3429\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.4641 - val_loss: 8.3373\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.4585 - val_loss: 8.3315\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.4528 - val_loss: 8.3259\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.4472 - val_loss: 8.3204\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4417 - val_loss: 8.3150\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.4362 - val_loss: 8.3093\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.4305 - val_loss: 8.3036\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.4248 - val_loss: 8.2980\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.4192 - val_loss: 8.2922\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.4134 - val_loss: 8.2866\n",
      "Epoch 424/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.4079 - val_loss: 8.2811\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.4025 - val_loss: 8.2756\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.3970 - val_loss: 8.2701\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.3916 - val_loss: 8.2649\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.3864 - val_loss: 8.2596\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.3811 - val_loss: 8.2544\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.3760 - val_loss: 8.2491\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.3706 - val_loss: 8.2437\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 8.3654 - val_loss: 8.2385\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.3602 - val_loss: 8.2332\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3549 - val_loss: 8.2279\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.3497 - val_loss: 8.2226\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3444 - val_loss: 8.2176\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.3394 - val_loss: 8.2125\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.3345 - val_loss: 8.2073\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3293 - val_loss: 8.2019\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3241 - val_loss: 8.1965\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.3190 - val_loss: 8.1913\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.3138 - val_loss: 8.1863\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.3088 - val_loss: 8.1809\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3037 - val_loss: 8.1759\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.2987 - val_loss: 8.1706\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.2936 - val_loss: 8.1654\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.2886 - val_loss: 8.1601\n",
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.2835 - val_loss: 8.1550\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.2785 - val_loss: 8.1499\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.2736 - val_loss: 8.1447\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.2686 - val_loss: 8.1397\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.2638 - val_loss: 8.1348\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.2592 - val_loss: 8.1298\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.2544 - val_loss: 8.1248\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.2496 - val_loss: 8.1197\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2448 - val_loss: 8.1146\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.2399 - val_loss: 8.1098\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.2352 - val_loss: 8.1049\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.2305 - val_loss: 8.1004\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 8.2261 - val_loss: 8.0958\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 8.2215 - val_loss: 8.0909\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 8.2168 - val_loss: 8.0861\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.2121 - val_loss: 8.0811\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.2072 - val_loss: 8.0764\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.2027 - val_loss: 8.0717\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 8.1980 - val_loss: 8.0671\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 8.1934 - val_loss: 8.0623\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1887 - val_loss: 8.0574\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.1839 - val_loss: 8.0526\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.1791 - val_loss: 8.0479\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.1745 - val_loss: 8.0433\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.1700 - val_loss: 8.0389\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1657 - val_loss: 8.0341\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.1611 - val_loss: 8.0293\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.1564 - val_loss: 8.0247\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.1519 - val_loss: 8.0201\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.1474 - val_loss: 8.0153\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.1427 - val_loss: 8.0104\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.1380 - val_loss: 8.0057\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.1334 - val_loss: 8.0009\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.1287 - val_loss: 7.9964\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1244 - val_loss: 7.9918\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1199 - val_loss: 7.9874\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.1156 - val_loss: 7.9829\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1112 - val_loss: 7.9783\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1070 - val_loss: 7.9737\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1024 - val_loss: 7.9693\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.0980 - val_loss: 7.9650\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.0937 - val_loss: 7.9606\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.0894 - val_loss: 7.9562\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.0851 - val_loss: 7.9519\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.0809 - val_loss: 7.9474\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.0767 - val_loss: 7.9431\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.0724 - val_loss: 7.9387\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.0683 - val_loss: 7.9342\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.0641 - val_loss: 7.9296\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.0597 - val_loss: 7.9254\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.0556 - val_loss: 7.9209\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.0513 - val_loss: 7.9165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.0472 - val_loss: 7.9122\n",
      "594/594 [==============================] - 0s 36us/sample - loss: 7.9372\n",
      "[CV]  learning_rate=0.0006930605663535878, n_hidden=0, n_neurons=161, total=  45.8s\n",
      "[CV] learning_rate=0.0006930605663535878, n_hidden=0, n_neurons=161 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 277us/sample - loss: 14.0931 - val_loss: 13.7542\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 14.0703 - val_loss: 13.7309\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 14.0472 - val_loss: 13.7076\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 14.0241 - val_loss: 13.6843\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 14.0012 - val_loss: 13.6612\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.9784 - val_loss: 13.6381\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.9558 - val_loss: 13.6151\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.9331 - val_loss: 13.5922\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 13.9104 - val_loss: 13.5693\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.8878 - val_loss: 13.5464\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 60us/sample - loss: 13.8652 - val_loss: 13.5236\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.8426 - val_loss: 13.5008\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.8201 - val_loss: 13.4783\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.7977 - val_loss: 13.4560\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.7756 - val_loss: 13.4335\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 120us/sample - loss: 13.7533 - val_loss: 13.4110\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 13.7312 - val_loss: 13.3886\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.7091 - val_loss: 13.3662\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.6872 - val_loss: 13.3440\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 13.6652 - val_loss: 13.3217\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.6433 - val_loss: 13.2994\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 13.6215 - val_loss: 13.2773\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.5996 - val_loss: 13.2556\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.5782 - val_loss: 13.2337\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.5567 - val_loss: 13.2116\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.5350 - val_loss: 13.1897\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.5135 - val_loss: 13.1678\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 13.4919 - val_loss: 13.1459\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.4703 - val_loss: 13.1244\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.4489 - val_loss: 13.1024\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.4274 - val_loss: 13.0805\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.4059 - val_loss: 13.0588\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.3845 - val_loss: 13.0372\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.3632 - val_loss: 13.0158\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.3421 - val_loss: 12.9942\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.3209 - val_loss: 12.9728\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.2998 - val_loss: 12.9516\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.2789 - val_loss: 12.9304\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.2577 - val_loss: 12.9094\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.2366 - val_loss: 12.8885\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 13.2157 - val_loss: 12.8674\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.1946 - val_loss: 12.8463\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.1735 - val_loss: 12.8252\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.1524 - val_loss: 12.8041\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.1312 - val_loss: 12.7830\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.1101 - val_loss: 12.7623\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.0893 - val_loss: 12.7414\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 13.0683 - val_loss: 12.7206\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.0475 - val_loss: 12.6998\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.0267 - val_loss: 12.6791\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.0061 - val_loss: 12.6585\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.9854 - val_loss: 12.6380\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.9649 - val_loss: 12.6177\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.9444 - val_loss: 12.5973\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.9238 - val_loss: 12.5773\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.9035 - val_loss: 12.5570\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.8831 - val_loss: 12.5368\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.8627 - val_loss: 12.5167\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.8425 - val_loss: 12.4966\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 12.8221 - val_loss: 12.4765\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.8019 - val_loss: 12.4564\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.7817 - val_loss: 12.4364\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.7614 - val_loss: 12.4164\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.7411 - val_loss: 12.3965\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7208 - val_loss: 12.3765\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7004 - val_loss: 12.3566\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.6803 - val_loss: 12.3368\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.6604 - val_loss: 12.3171\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.6403 - val_loss: 12.2972\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.6202 - val_loss: 12.2774\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.6000 - val_loss: 12.2576\n",
      "Epoch 72/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.5799 - val_loss: 12.2378\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.5599 - val_loss: 12.2181\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.5398 - val_loss: 12.1982\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.5198 - val_loss: 12.1785\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.4997 - val_loss: 12.1587\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.4797 - val_loss: 12.1392\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.4598 - val_loss: 12.1197\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.4398 - val_loss: 12.1002\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.4198 - val_loss: 12.0813\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.4004 - val_loss: 12.0619\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.3805 - val_loss: 12.0427\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.3609 - val_loss: 12.0233\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.3411 - val_loss: 12.0041\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.3214 - val_loss: 11.9849\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.3017 - val_loss: 11.9658\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.2820 - val_loss: 11.9472\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.2627 - val_loss: 11.9285\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.2435 - val_loss: 11.9099\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.2244 - val_loss: 11.8909\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.2049 - val_loss: 11.8718\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 12.1857 - val_loss: 11.8533\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.1668 - val_loss: 11.8344\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.1477 - val_loss: 11.8157\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.1286 - val_loss: 11.7970\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.1095 - val_loss: 11.7785\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.0906 - val_loss: 11.7600\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.0718 - val_loss: 11.7416\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.0530 - val_loss: 11.7236\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.0345 - val_loss: 11.7055\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.0158 - val_loss: 11.6875\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.9972 - val_loss: 11.6694\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.9786 - val_loss: 11.6515\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.9601 - val_loss: 11.6338\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.9419 - val_loss: 11.6159\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.9237 - val_loss: 11.5981\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 11.9055 - val_loss: 11.5805\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.8873 - val_loss: 11.5628\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.8692 - val_loss: 11.5451\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.8510 - val_loss: 11.5275\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.8330 - val_loss: 11.5101\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.8151 - val_loss: 11.4927\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.7972 - val_loss: 11.4753\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.7795 - val_loss: 11.4580\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.7618 - val_loss: 11.4407\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.7441 - val_loss: 11.4234\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.7264 - val_loss: 11.4064\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.7087 - val_loss: 11.3896\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.6912 - val_loss: 11.3724\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.6736 - val_loss: 11.3553\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.6560 - val_loss: 11.3382\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.6385 - val_loss: 11.3214\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.6212 - val_loss: 11.3046\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.6039 - val_loss: 11.2877\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.5865 - val_loss: 11.2708\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.5691 - val_loss: 11.2538\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.5518 - val_loss: 11.2370\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.5345 - val_loss: 11.2200\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.5173 - val_loss: 11.2030\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.5000 - val_loss: 11.1863\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.4828 - val_loss: 11.1697\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.4659 - val_loss: 11.1531\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.4488 - val_loss: 11.1366\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.4317 - val_loss: 11.1203\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.4149 - val_loss: 11.1036\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.3978 - val_loss: 11.0874\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.3811 - val_loss: 11.0710\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.3644 - val_loss: 11.0544\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 11.3475 - val_loss: 11.0382\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.3308 - val_loss: 11.0220\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 11.3142 - val_loss: 11.0058\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.2976 - val_loss: 10.9894\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.2808 - val_loss: 10.9732\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.2641 - val_loss: 10.9573\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.2476 - val_loss: 10.9411\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.2308 - val_loss: 10.9250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.2142 - val_loss: 10.9090\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.1977 - val_loss: 10.8932\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.1813 - val_loss: 10.8779\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.1651 - val_loss: 10.8623\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.1489 - val_loss: 10.8468\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.1327 - val_loss: 10.8310\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.1162 - val_loss: 10.8153\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.1000 - val_loss: 10.8003\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.0843 - val_loss: 10.7845\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.0680 - val_loss: 10.7689\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.0516 - val_loss: 10.7533\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.0354 - val_loss: 10.7383\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.0196 - val_loss: 10.7229\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.0034 - val_loss: 10.7076\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.9873 - val_loss: 10.6925\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 10.9715 - val_loss: 10.6771\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 10.9555 - val_loss: 10.6622\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 10.9399 - val_loss: 10.6470\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.9240 - val_loss: 10.6320\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.9084 - val_loss: 10.6174\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.8928 - val_loss: 10.6026\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.8770 - val_loss: 10.5880\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.8613 - val_loss: 10.5733\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.8456 - val_loss: 10.5588\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 10.8301 - val_loss: 10.5441\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 10.8144 - val_loss: 10.5297\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 10.7989 - val_loss: 10.5154\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.7836 - val_loss: 10.5011\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 10.7680 - val_loss: 10.4869\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.7526 - val_loss: 10.4731\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.7375 - val_loss: 10.4592\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.7223 - val_loss: 10.4453\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.7070 - val_loss: 10.4313\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.6916 - val_loss: 10.4172\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 10.6763 - val_loss: 10.4035\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.6611 - val_loss: 10.3894\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.6458 - val_loss: 10.3754\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.6303 - val_loss: 10.3614\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.6150 - val_loss: 10.3475\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.5996 - val_loss: 10.3337\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.5844 - val_loss: 10.3203\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 10.5697 - val_loss: 10.3066\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.5548 - val_loss: 10.2933\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.5401 - val_loss: 10.2800\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.5255 - val_loss: 10.2666\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.5108 - val_loss: 10.2531\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.4958 - val_loss: 10.2399\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.4811 - val_loss: 10.2266\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.4665 - val_loss: 10.2133\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.4520 - val_loss: 10.2001\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4376 - val_loss: 10.1868\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.4230 - val_loss: 10.1736\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.4085 - val_loss: 10.1605\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 10.3941 - val_loss: 10.1476\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 10.3801 - val_loss: 10.1347\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.3659 - val_loss: 10.1220\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.3517 - val_loss: 10.1095\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 10.3380 - val_loss: 10.0968\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 10.3240 - val_loss: 10.0842\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.3099 - val_loss: 10.0716\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.2959 - val_loss: 10.0590\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.2819 - val_loss: 10.0464\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 10.2680 - val_loss: 10.0342\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2543 - val_loss: 10.0219\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2405 - val_loss: 10.0097\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.2269 - val_loss: 9.9977\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2133 - val_loss: 9.9856\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.1999 - val_loss: 9.9737\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1864 - val_loss: 9.9614\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.1728 - val_loss: 9.9491\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.1590 - val_loss: 9.9370\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.1454 - val_loss: 9.9249\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.1318 - val_loss: 9.9128\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1182 - val_loss: 9.9008\n",
      "Epoch 221/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.1047 - val_loss: 9.8891\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.0917 - val_loss: 9.8771\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.0783 - val_loss: 9.8654\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0652 - val_loss: 9.8538\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0522 - val_loss: 9.8420\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.0389 - val_loss: 9.8302\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.0257 - val_loss: 9.8185\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.0127 - val_loss: 9.8071\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.0000 - val_loss: 9.7953\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.9870 - val_loss: 9.7841\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.9746 - val_loss: 9.7728\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.9621 - val_loss: 9.7613\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.9494 - val_loss: 9.7499\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.9367 - val_loss: 9.7383\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.9241 - val_loss: 9.7266\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.9112 - val_loss: 9.7153\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.8985 - val_loss: 9.7039\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.8857 - val_loss: 9.6927\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.8731 - val_loss: 9.6816\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8605 - val_loss: 9.6704\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.8479 - val_loss: 9.6592\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.8353 - val_loss: 9.6482\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.8228 - val_loss: 9.6368\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.8102 - val_loss: 9.6256\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.7975 - val_loss: 9.6146\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.7851 - val_loss: 9.6034\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.7725 - val_loss: 9.5928\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.7604 - val_loss: 9.5818\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.7479 - val_loss: 9.5711\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.7355 - val_loss: 9.5603\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.7233 - val_loss: 9.5495\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.7110 - val_loss: 9.5387\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.6988 - val_loss: 9.5278\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.6865 - val_loss: 9.5172\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.6745 - val_loss: 9.5069\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.6627 - val_loss: 9.4962\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.6509 - val_loss: 9.4855\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.6389 - val_loss: 9.4751\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.6271 - val_loss: 9.4649\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.6155 - val_loss: 9.4543\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.6035 - val_loss: 9.4437\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.5917 - val_loss: 9.4334\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.5800 - val_loss: 9.4231\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.5685 - val_loss: 9.4127\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.5567 - val_loss: 9.4024\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.5451 - val_loss: 9.3922\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.5336 - val_loss: 9.3819\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.5219 - val_loss: 9.3716\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.5103 - val_loss: 9.3613\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.4987 - val_loss: 9.3509\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.4871 - val_loss: 9.3406\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 9.4755 - val_loss: 9.3305\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 9.4641 - val_loss: 9.3205\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.4527 - val_loss: 9.3102\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.4412 - val_loss: 9.3002\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 9.4298 - val_loss: 9.2902\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 9.4186 - val_loss: 9.2800\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 9.4072 - val_loss: 9.2701\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 9.3964 - val_loss: 9.2602\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.3852 - val_loss: 9.2501\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.3741 - val_loss: 9.2404\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 113us/sample - loss: 9.3633 - val_loss: 9.2308\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 137us/sample - loss: 9.3525 - val_loss: 9.2210\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 118us/sample - loss: 9.3415 - val_loss: 9.2112\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 9.3306 - val_loss: 9.2014\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 9.3196 - val_loss: 9.1923\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 9.3094 - val_loss: 9.1831\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.2989 - val_loss: 9.1735\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.2881 - val_loss: 9.1638\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 9.3538 - 0s 85us/sample - loss: 9.2775 - val_loss: 9.1545\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.2669 - val_loss: 9.1454\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.2568 - val_loss: 9.1362\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.2464 - val_loss: 9.1270\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.2360 - val_loss: 9.1180\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 60us/sample - loss: 9.2260 - val_loss: 9.1088\n",
      "Epoch 296/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 61us/sample - loss: 9.2159 - val_loss: 9.0997\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.2059 - val_loss: 9.0906\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.1958 - val_loss: 9.0815\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.1859 - val_loss: 9.0725\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1760 - val_loss: 9.0636\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.1661 - val_loss: 9.0546\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.1562 - val_loss: 9.0456\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.1462 - val_loss: 9.0366\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.1362 - val_loss: 9.0278\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.1264 - val_loss: 9.0189\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.1163 - val_loss: 9.0101\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.1065 - val_loss: 9.0014\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.0969 - val_loss: 8.9927\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.0870 - val_loss: 8.9837\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 9.0773 - val_loss: 8.9750\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.0676 - val_loss: 8.9661\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.0579 - val_loss: 8.9572\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 9.0483 - val_loss: 8.9486\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.0386 - val_loss: 8.9399\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.0290 - val_loss: 8.9311\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 9.0195 - val_loss: 8.9230\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.0106 - val_loss: 8.9142\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.0009 - val_loss: 8.9054\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.9912 - val_loss: 8.8965\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.9816 - val_loss: 8.8880\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 8.9720 - val_loss: 8.8797\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.9628 - val_loss: 8.8715\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.9537 - val_loss: 8.8633\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 8.9446 - val_loss: 8.8552\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 8.9356 - val_loss: 8.8468\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 8.9262 - val_loss: 8.8384\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.9168 - val_loss: 8.8301\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.9076 - val_loss: 8.8219\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 8.8985 - val_loss: 8.8135\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 117us/sample - loss: 8.8892 - val_loss: 8.8051\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 147us/sample - loss: 8.8799 - val_loss: 8.7968\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 109us/sample - loss: 8.8708 - val_loss: 8.7885\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 8.8615 - val_loss: 8.7802\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 174us/sample - loss: 8.8525 - val_loss: 8.7720\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 120us/sample - loss: 8.8434 - val_loss: 8.7637\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 136us/sample - loss: 8.8342 - val_loss: 8.7556\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 112us/sample - loss: 8.8252 - val_loss: 8.7474\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 8.8160 - val_loss: 8.7392\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 8.8069 - val_loss: 8.7312\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.7979 - val_loss: 8.7234\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.7892 - val_loss: 8.7155\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.7804 - val_loss: 8.7076\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7715 - val_loss: 8.6998\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.7626 - val_loss: 8.6920\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7539 - val_loss: 8.6843\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 8.7453 - val_loss: 8.6765\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 8.7366 - val_loss: 8.6688\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.7279 - val_loss: 8.6611\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 8.7193 - val_loss: 8.6532\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.7105 - val_loss: 8.6454\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.7017 - val_loss: 8.6381\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.6934 - val_loss: 8.6308\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.6852 - val_loss: 8.6232\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.6767 - val_loss: 8.6160\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 59us/sample - loss: 8.6687 - val_loss: 8.6084\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.6601 - val_loss: 8.6010\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.6518 - val_loss: 8.5937\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 8.6436 - val_loss: 8.5862\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.6351 - val_loss: 8.5790\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.6269 - val_loss: 8.5716\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 115us/sample - loss: 8.6183 - val_loss: 8.5641\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.6099 - val_loss: 8.5570\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6016 - val_loss: 8.5500\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.5935 - val_loss: 8.5428\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5853 - val_loss: 8.5361\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.5776 - val_loss: 8.5294\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.5697 - val_loss: 8.5226\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.5619 - val_loss: 8.5158\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.5540 - val_loss: 8.5087\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.5460 - val_loss: 8.5016\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.5381 - val_loss: 8.4947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.5302 - val_loss: 8.4878\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.5223 - val_loss: 8.4808\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.5144 - val_loss: 8.4740\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.5067 - val_loss: 8.4673\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.4991 - val_loss: 8.4607\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.4919 - val_loss: 8.4540\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4845 - val_loss: 8.4475\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.4772 - val_loss: 8.4407\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.4696 - val_loss: 8.4341\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4621 - val_loss: 8.4275\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.4549 - val_loss: 8.4208\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.4475 - val_loss: 8.4143\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.4403 - val_loss: 8.4080\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.4333 - val_loss: 8.4014\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.4260 - val_loss: 8.3949\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.4189 - val_loss: 8.3886\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4120 - val_loss: 8.3821\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4048 - val_loss: 8.3757\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 8.3975 - val_loss: 8.3696\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.3908 - val_loss: 8.3634\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.3838 - val_loss: 8.3570\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.3766 - val_loss: 8.3508\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.3697 - val_loss: 8.3447\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 8.3629 - val_loss: 8.3385\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.3560 - val_loss: 8.3321\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.3490 - val_loss: 8.3258\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.3420 - val_loss: 8.3196\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 8.3352 - val_loss: 8.3133\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.3282 - val_loss: 8.3072\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.3213 - val_loss: 8.3012\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.3147 - val_loss: 8.2952\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.3079 - val_loss: 8.2891\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.3011 - val_loss: 8.2830\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.2942 - val_loss: 8.2772\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.2877 - val_loss: 8.2713\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.2810 - val_loss: 8.2654\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2743 - val_loss: 8.2596\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2678 - val_loss: 8.2537\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.2612 - val_loss: 8.2475\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.2544 - val_loss: 8.2415\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.2477 - val_loss: 8.2355\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2410 - val_loss: 8.2297\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.2345 - val_loss: 8.2240\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2282 - val_loss: 8.2182\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.2218 - val_loss: 8.2123\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.2152 - val_loss: 8.2064\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.2088 - val_loss: 8.2006\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.2025 - val_loss: 8.1949\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.1961 - val_loss: 8.1892\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1898 - val_loss: 8.1834\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.1834 - val_loss: 8.1774\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 8.1770 - val_loss: 8.1715\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.1706 - val_loss: 8.1656\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.1641 - val_loss: 8.1600\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.1579 - val_loss: 8.1543\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.1517 - val_loss: 8.1485\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.1454 - val_loss: 8.1427\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1391 - val_loss: 8.1371\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.1330 - val_loss: 8.1315\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.1267 - val_loss: 8.1258\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.1206 - val_loss: 8.1205\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1148 - val_loss: 8.1149\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.1087 - val_loss: 8.1093\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.1027 - val_loss: 8.1036\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 8.0965 - val_loss: 8.0981\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.0906 - val_loss: 8.0927\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 8.0849 - val_loss: 8.0874\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.0792 - val_loss: 8.0817\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 8.0732 - val_loss: 8.0765\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 200us/sample - loss: 8.0676 - val_loss: 8.0711\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 201us/sample - loss: 8.0617 - val_loss: 8.0656\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 212us/sample - loss: 8.0560 - val_loss: 8.0603\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 168us/sample - loss: 8.0505 - val_loss: 8.0553\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 139us/sample - loss: 8.0451 - val_loss: 8.0504\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 158us/sample - loss: 8.0398 - val_loss: 8.0452\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 145us/sample - loss: 8.0342 - val_loss: 8.0402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 138us/sample - loss: 8.0287 - val_loss: 8.0352\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 112us/sample - loss: 8.0233 - val_loss: 8.0301\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 8.0177 - val_loss: 8.0250\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 127us/sample - loss: 8.0123 - val_loss: 8.0199\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 126us/sample - loss: 8.0069 - val_loss: 8.0149\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 134us/sample - loss: 8.0014 - val_loss: 8.0100\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 126us/sample - loss: 7.9961 - val_loss: 8.0050\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 113us/sample - loss: 7.9908 - val_loss: 8.0002\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 125us/sample - loss: 7.9857 - val_loss: 7.9953\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 7.9805 - val_loss: 7.9906\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 168us/sample - loss: 7.9754 - val_loss: 7.9857\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 146us/sample - loss: 7.9702 - val_loss: 7.9809\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 124us/sample - loss: 7.9652 - val_loss: 7.9763\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 136us/sample - loss: 7.9602 - val_loss: 7.9717\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 179us/sample - loss: 7.9552 - val_loss: 7.9667\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 120us/sample - loss: 7.9500 - val_loss: 7.9620\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 154us/sample - loss: 7.9449 - val_loss: 7.9573\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 160us/sample - loss: 7.9400 - val_loss: 7.9524\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 135us/sample - loss: 7.9348 - val_loss: 7.9478\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 7.9299 - val_loss: 7.9430\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.9247 - val_loss: 7.9382\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.9196 - val_loss: 7.9335\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.9146 - val_loss: 7.9288\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 7.9096 - val_loss: 7.9241\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 173us/sample - loss: 7.9048 - val_loss: 7.9195\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 112us/sample - loss: 7.8999 - val_loss: 7.9149\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 140us/sample - loss: 7.8950 - val_loss: 7.9102\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 116us/sample - loss: 7.8900 - val_loss: 7.9058\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 167us/sample - loss: 7.8853 - val_loss: 7.9012\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 124us/sample - loss: 7.8803 - val_loss: 7.8969\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 7.8757 - val_loss: 7.8923\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 7.8708 - val_loss: 7.8881\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 7.8663 - val_loss: 7.8835\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 116us/sample - loss: 7.8616 - val_loss: 7.8790\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 132us/sample - loss: 7.8568 - val_loss: 7.8745\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 109us/sample - loss: 7.8520 - val_loss: 7.8701\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 115us/sample - loss: 7.8474 - val_loss: 7.8659\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 134us/sample - loss: 7.8429 - val_loss: 7.8616\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 115us/sample - loss: 7.8382 - val_loss: 7.8572\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 163us/sample - loss: 7.8336 - val_loss: 7.8532\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 126us/sample - loss: 7.8293 - val_loss: 7.8490\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 7.8248 - val_loss: 7.8447\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.8203 - val_loss: 7.8405\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.8158 - val_loss: 7.8365\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.8116 - val_loss: 7.8322\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.8071 - val_loss: 7.8279\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.8026 - val_loss: 7.8239\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.7984 - val_loss: 7.8198\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.7941 - val_loss: 7.8156\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.7899 - val_loss: 7.8115\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.7856 - val_loss: 7.8074\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.7813 - val_loss: 7.8033\n",
      "Epoch 500/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.7769 - val_loss: 7.7992\n",
      "594/594 [==============================] - 0s 43us/sample - loss: 8.2716\n",
      "[CV]  learning_rate=0.0006930605663535878, n_hidden=0, n_neurons=161, total=  50.0s\n",
      "[CV] learning_rate=0.0006930605663535878, n_hidden=0, n_neurons=161 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 341us/sample - loss: 13.9772 - val_loss: 13.8418\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 13.9533 - val_loss: 13.8184\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 13.9294 - val_loss: 13.7949\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 13.9056 - val_loss: 13.7714\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 13.8819 - val_loss: 13.7481\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 13.8582 - val_loss: 13.7244\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 13.8346 - val_loss: 13.7011\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 13.8110 - val_loss: 13.6777\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 124us/sample - loss: 13.7877 - val_loss: 13.6545\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 13.7644 - val_loss: 13.6315\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 13.7414 - val_loss: 13.6083\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 13.7184 - val_loss: 13.5853\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.6954 - val_loss: 13.5624\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.6726 - val_loss: 13.5393\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.6497 - val_loss: 13.5162\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.6270 - val_loss: 13.4933\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.6044 - val_loss: 13.4705\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.5819 - val_loss: 13.4480\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.5596 - val_loss: 13.4254\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 13.5373 - val_loss: 13.4028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 13.5150 - val_loss: 13.3802\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 13.4927 - val_loss: 13.3577\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.4705 - val_loss: 13.3351\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.4482 - val_loss: 13.3132\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.4266 - val_loss: 13.2908\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.4044 - val_loss: 13.2685\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.3822 - val_loss: 13.2462\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.3601 - val_loss: 13.2241\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.3383 - val_loss: 13.2018\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.3162 - val_loss: 13.1796\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.2941 - val_loss: 13.1578\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.2723 - val_loss: 13.1358\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.2503 - val_loss: 13.1138\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 13.2284 - val_loss: 13.0924\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.2070 - val_loss: 13.0707\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.1852 - val_loss: 13.0489\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 13.1634 - val_loss: 13.0270\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 13.1416 - val_loss: 13.0053\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.1202 - val_loss: 12.9840\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.0990 - val_loss: 12.9628\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.0782 - val_loss: 12.9415\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.0572 - val_loss: 12.9202\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.0363 - val_loss: 12.8992\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.0157 - val_loss: 12.8781\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.9948 - val_loss: 12.8568\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.9741 - val_loss: 12.8360\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.9537 - val_loss: 12.8149\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.9331 - val_loss: 12.7939\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 12.9125 - val_loss: 12.7729\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 12.8919 - val_loss: 12.7521\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.8714 - val_loss: 12.7318\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.8512 - val_loss: 12.7112\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.8308 - val_loss: 12.6907\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.8105 - val_loss: 12.6705\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.7904 - val_loss: 12.6504\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.7705 - val_loss: 12.6302\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 12.7502 - val_loss: 12.6103\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.7302 - val_loss: 12.5901\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7101 - val_loss: 12.5702\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.6903 - val_loss: 12.5504\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.6706 - val_loss: 12.5306\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 12.6511 - val_loss: 12.5109\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 12.6315 - val_loss: 12.4915\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.6120 - val_loss: 12.4720\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.5925 - val_loss: 12.4523\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 12.5729 - val_loss: 12.4326\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.5534 - val_loss: 12.4127\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.5338 - val_loss: 12.3932\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.5142 - val_loss: 12.3739\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.4948 - val_loss: 12.3542\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 12.4753 - val_loss: 12.3350\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 12.4560 - val_loss: 12.3156\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.4367 - val_loss: 12.2964\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 12.4176 - val_loss: 12.2773\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.3985 - val_loss: 12.2580\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.3791 - val_loss: 12.2387\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 12.3599 - val_loss: 12.2197\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.3410 - val_loss: 12.2005\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.3219 - val_loss: 12.1812\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.3028 - val_loss: 12.1626\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 12.2843 - val_loss: 12.1435\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 12.2653 - val_loss: 12.1247\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.2468 - val_loss: 12.1055\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 12.2280 - val_loss: 12.0864\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 12.2092 - val_loss: 12.0674\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 122us/sample - loss: 12.1906 - val_loss: 12.0483\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 12.1719 - val_loss: 12.0295\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 12.1532 - val_loss: 12.0107\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 12.1346 - val_loss: 11.9922\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 104us/sample - loss: 12.1162 - val_loss: 11.9739\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 102us/sample - loss: 12.0982 - val_loss: 11.9552\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 154us/sample - loss: 12.0801 - val_loss: 11.9372\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 12.0622 - val_loss: 11.9188\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 160us/sample - loss: 12.0442 - val_loss: 11.9005\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 130us/sample - loss: 12.0264 - val_loss: 11.8823\n",
      "Epoch 96/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 150us/sample - loss: 12.0086 - val_loss: 11.8645\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 11.9913 - val_loss: 11.8465\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.9735 - val_loss: 11.8285\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.9559 - val_loss: 11.8106\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.9382 - val_loss: 11.7927\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 134us/sample - loss: 11.9206 - val_loss: 11.7747\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.9031 - val_loss: 11.7567\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 11.8856 - val_loss: 11.7388\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 11.8681 - val_loss: 11.7211\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.8507 - val_loss: 11.7033\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 11.8334 - val_loss: 11.6860\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 11.8164 - val_loss: 11.6687\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.7992 - val_loss: 11.6512\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 11.7818 - val_loss: 11.6338\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 11.7646 - val_loss: 11.6167\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.7476 - val_loss: 11.5993\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.7305 - val_loss: 11.5822\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.7136 - val_loss: 11.5650\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.6967 - val_loss: 11.5480\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.6801 - val_loss: 11.5309\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 11.6633 - val_loss: 11.5140\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.6465 - val_loss: 11.4970\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 11.6298 - val_loss: 11.4802\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.6134 - val_loss: 11.4637\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 11.5970 - val_loss: 11.4470\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.5804 - val_loss: 11.4303\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 11.5640 - val_loss: 11.4137\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 11.5477 - val_loss: 11.3969\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.5312 - val_loss: 11.3807\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 125us/sample - loss: 11.5151 - val_loss: 11.3642\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 125us/sample - loss: 11.4987 - val_loss: 11.3476\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 11.4825 - val_loss: 11.3317\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.4669 - val_loss: 11.3152\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.4507 - val_loss: 11.2989\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.4346 - val_loss: 11.2828\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.4186 - val_loss: 11.2669\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.4029 - val_loss: 11.2510\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.3872 - val_loss: 11.2352\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.3714 - val_loss: 11.2196\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.3558 - val_loss: 11.2037\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.3400 - val_loss: 11.1880\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.3243 - val_loss: 11.1726\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.3091 - val_loss: 11.1571\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.2936 - val_loss: 11.1419\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.2787 - val_loss: 11.1264\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.2633 - val_loss: 11.1111\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.2480 - val_loss: 11.0957\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.2327 - val_loss: 11.0805\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.2175 - val_loss: 11.0656\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.2025 - val_loss: 11.0506\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.1874 - val_loss: 11.0359\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.1725 - val_loss: 11.0208\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.1574 - val_loss: 11.0061\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.1426 - val_loss: 10.9916\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.1282 - val_loss: 10.9770\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.1137 - val_loss: 10.9624\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.0991 - val_loss: 10.9476\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.0844 - val_loss: 10.9330\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.0699 - val_loss: 10.9191\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.0560 - val_loss: 10.9043\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.0414 - val_loss: 10.8897\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.0269 - val_loss: 10.8751\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 11.0125 - val_loss: 10.8609\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.9985 - val_loss: 10.8462\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 10.9843 - val_loss: 10.8318\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.9701 - val_loss: 10.8178\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.9564 - val_loss: 10.8033\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.9424 - val_loss: 10.7892\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.9288 - val_loss: 10.7749\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.9149 - val_loss: 10.7609\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.9013 - val_loss: 10.7468\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.8875 - val_loss: 10.7326\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.8737 - val_loss: 10.7186\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.8599 - val_loss: 10.7046\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.8463 - val_loss: 10.6906\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.8327 - val_loss: 10.6765\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.8191 - val_loss: 10.6627\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 10.8057 - val_loss: 10.6490\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 10.7923 - val_loss: 10.6351\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.7789 - val_loss: 10.6214\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.7656 - val_loss: 10.6081\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 10.7526 - val_loss: 10.5944\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 10.7392 - val_loss: 10.5808\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 10.7260 - val_loss: 10.5675\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.7129 - val_loss: 10.5541\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.6998 - val_loss: 10.5407\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 10.6867 - val_loss: 10.5270\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.6734 - val_loss: 10.5134\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.6602 - val_loss: 10.4997\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.6471 - val_loss: 10.4865\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.6340 - val_loss: 10.4731\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.6210 - val_loss: 10.4598\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.6081 - val_loss: 10.4465\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.5952 - val_loss: 10.4336\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.5825 - val_loss: 10.4207\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.5698 - val_loss: 10.4078\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.5573 - val_loss: 10.3950\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.5445 - val_loss: 10.3819\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.5318 - val_loss: 10.3694\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.5195 - val_loss: 10.3568\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.5071 - val_loss: 10.3442\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.4947 - val_loss: 10.3314\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.4822 - val_loss: 10.3186\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.4696 - val_loss: 10.3060\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.4572 - val_loss: 10.2933\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.4446 - val_loss: 10.2810\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 10.4323 - val_loss: 10.2686\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.4199 - val_loss: 10.2568\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.4082 - val_loss: 10.2448\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.3962 - val_loss: 10.2325\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.3838 - val_loss: 10.2204\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.3716 - val_loss: 10.2084\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.3596 - val_loss: 10.1964\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.3475 - val_loss: 10.1847\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.3358 - val_loss: 10.1725\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.3235 - val_loss: 10.1606\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.3117 - val_loss: 10.1487\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 10.2997 - val_loss: 10.1370\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.2879 - val_loss: 10.1250\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.2760 - val_loss: 10.1132\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.2642 - val_loss: 10.1010\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.2523 - val_loss: 10.0894\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.2407 - val_loss: 10.0775\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.2288 - val_loss: 10.0659\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.2173 - val_loss: 10.0542\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.2056 - val_loss: 10.0424\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.1939 - val_loss: 10.0310\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.1824 - val_loss: 10.0196\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.1711 - val_loss: 10.0080\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.1594 - val_loss: 9.9967\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1481 - val_loss: 9.9852\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.1365 - val_loss: 9.9741\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.1253 - val_loss: 9.9632\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.1142 - val_loss: 9.9518\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 10.1028 - val_loss: 9.9409\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.0917 - val_loss: 9.9300\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.0806 - val_loss: 9.9190\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0695 - val_loss: 9.9084\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.0586 - val_loss: 9.8974\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.0477 - val_loss: 9.8865\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.0367 - val_loss: 9.8758\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.0259 - val_loss: 9.8653\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.0151 - val_loss: 9.8550\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.0046 - val_loss: 9.8443\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.9937 - val_loss: 9.8339\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.9830 - val_loss: 9.8233\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.9722 - val_loss: 9.8129\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.9614 - val_loss: 9.8024\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.9507 - val_loss: 9.7920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.9401 - val_loss: 9.7815\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.9295 - val_loss: 9.7710\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.9190 - val_loss: 9.7608\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.9088 - val_loss: 9.7505\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.8984 - val_loss: 9.7401\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 9.8879 - val_loss: 9.7297\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.8776 - val_loss: 9.7193\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.8672 - val_loss: 9.7090\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 9.8570 - val_loss: 9.6989\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.8469 - val_loss: 9.6888\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.8368 - val_loss: 9.6786\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.8265 - val_loss: 9.6683\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 9.8165 - val_loss: 9.6581\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.8063 - val_loss: 9.6478\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.7961 - val_loss: 9.6377\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.7861 - val_loss: 9.6275\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.7761 - val_loss: 9.6174\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.7661 - val_loss: 9.6074\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 9.7562 - val_loss: 9.5976\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.7465 - val_loss: 9.5876\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.7366 - val_loss: 9.5777\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.7267 - val_loss: 9.5678\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 9.7168 - val_loss: 9.5580\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.7069 - val_loss: 9.5483\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.6973 - val_loss: 9.5384\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.6877 - val_loss: 9.5290\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.6782 - val_loss: 9.5193\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.6685 - val_loss: 9.5101\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6594 - val_loss: 9.5005\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.6499 - val_loss: 9.4908\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.6403 - val_loss: 9.4812\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.6307 - val_loss: 9.4715\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.6212 - val_loss: 9.4618\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.6115 - val_loss: 9.4523\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.6020 - val_loss: 9.4429\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.5926 - val_loss: 9.4333\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.5832 - val_loss: 9.4240\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.5739 - val_loss: 9.4148\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.5648 - val_loss: 9.4057\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.5557 - val_loss: 9.3962\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.5464 - val_loss: 9.3869\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.5372 - val_loss: 9.3776\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.5281 - val_loss: 9.3685\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.5192 - val_loss: 9.3593\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.5100 - val_loss: 9.3500\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.5009 - val_loss: 9.3407\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.4917 - val_loss: 9.3319\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.4829 - val_loss: 9.3228\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.4738 - val_loss: 9.3137\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.4647 - val_loss: 9.3044\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.4554 - val_loss: 9.2952\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.4463 - val_loss: 9.2863\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.4375 - val_loss: 9.2772\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.4285 - val_loss: 9.2679\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.4193 - val_loss: 9.2588\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.4103 - val_loss: 9.2498\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.4013 - val_loss: 9.2408\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.3923 - val_loss: 9.2319\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.3834 - val_loss: 9.2231\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3747 - val_loss: 9.2145\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.3661 - val_loss: 9.2054\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.3571 - val_loss: 9.1966\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.3482 - val_loss: 9.1879\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.3395 - val_loss: 9.1791\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.3306 - val_loss: 9.1702\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.3217 - val_loss: 9.1616\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.3130 - val_loss: 9.1535\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.3046 - val_loss: 9.1448\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.2959 - val_loss: 9.1367\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.2876 - val_loss: 9.1280\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.2788 - val_loss: 9.1194\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.2700 - val_loss: 9.1109\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.2614 - val_loss: 9.1022\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.2526 - val_loss: 9.0939\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.2441 - val_loss: 9.0853\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.2354 - val_loss: 9.0767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.2267 - val_loss: 9.0681\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.2181 - val_loss: 9.0598\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.2098 - val_loss: 9.0517\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.2017 - val_loss: 9.0436\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 9.1936 - val_loss: 9.0351\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.1851 - val_loss: 9.0270\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.1769 - val_loss: 9.0189\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.1688 - val_loss: 9.0107\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.1608 - val_loss: 9.0027\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.1529 - val_loss: 8.9948\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 9.1451 - val_loss: 8.9869\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.1375 - val_loss: 8.9789\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.1297 - val_loss: 8.9708\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.1218 - val_loss: 8.9632\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.1143 - val_loss: 8.9551\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.1063 - val_loss: 8.9469\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.0983 - val_loss: 8.9390\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.0903 - val_loss: 8.9309\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.0824 - val_loss: 8.9228\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.0744 - val_loss: 8.9151\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0668 - val_loss: 8.9072\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.0590 - val_loss: 8.8997\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.0515 - val_loss: 8.8919\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.0438 - val_loss: 8.8839\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.0359 - val_loss: 8.8759\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.0279 - val_loss: 8.8679\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.0201 - val_loss: 8.8597\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.0120 - val_loss: 8.8518\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.0043 - val_loss: 8.8440\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.9966 - val_loss: 8.8363\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.9889 - val_loss: 8.8283\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9811 - val_loss: 8.8208\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.9736 - val_loss: 8.8128\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.9658 - val_loss: 8.8052\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.9583 - val_loss: 8.7975\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9505 - val_loss: 8.7897\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.9427 - val_loss: 8.7825\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9355 - val_loss: 8.7747\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.9278 - val_loss: 8.7674\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.9206 - val_loss: 8.7602\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 8.9134 - val_loss: 8.7526\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.9059 - val_loss: 8.7453\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.8986 - val_loss: 8.7379\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.8913 - val_loss: 8.7307\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8842 - val_loss: 8.7235\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.8771 - val_loss: 8.7166\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.8702 - val_loss: 8.7094\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.8632 - val_loss: 8.7023\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.8562 - val_loss: 8.6951\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.8492 - val_loss: 8.6877\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.8420 - val_loss: 8.6806\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.8350 - val_loss: 8.6734\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.8279 - val_loss: 8.6663\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8208 - val_loss: 8.6590\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.8137 - val_loss: 8.6522\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.8069 - val_loss: 8.6456\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.8005 - val_loss: 8.6390\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.7938 - val_loss: 8.6324\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7871 - val_loss: 8.6259\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.7804 - val_loss: 8.6194\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.7739 - val_loss: 8.6128\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.7672 - val_loss: 8.6062\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7605 - val_loss: 8.5999\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.7541 - val_loss: 8.5937\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.7478 - val_loss: 8.5872\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7412 - val_loss: 8.5809\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7348 - val_loss: 8.5745\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.7284 - val_loss: 8.5684\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.7223 - val_loss: 8.5619\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7159 - val_loss: 8.5559\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.7100 - val_loss: 8.5497\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7039 - val_loss: 8.5433\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.6974 - val_loss: 8.5371\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.6912 - val_loss: 8.5311\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 9.021 - 0s 66us/sample - loss: 8.6851 - val_loss: 8.5250\n",
      "Epoch 396/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.6790 - val_loss: 8.5187\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6727 - val_loss: 8.5125\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.6665 - val_loss: 8.5066\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6606 - val_loss: 8.5002\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6541 - val_loss: 8.4942\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.6479 - val_loss: 8.4882\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.6419 - val_loss: 8.4820\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.6358 - val_loss: 8.4758\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.6296 - val_loss: 8.4695\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.6233 - val_loss: 8.4634\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.6171 - val_loss: 8.4572\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.6109 - val_loss: 8.4510\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.6048 - val_loss: 8.4448\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5985 - val_loss: 8.4386\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.5924 - val_loss: 8.4327\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.5865 - val_loss: 8.4266\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.5805 - val_loss: 8.4207\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.5745 - val_loss: 8.4147\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 8.5686 - val_loss: 8.4087\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.5627 - val_loss: 8.4027\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.5568 - val_loss: 8.3967\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.5508 - val_loss: 8.3908\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.5450 - val_loss: 8.3850\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.5391 - val_loss: 8.3789\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5331 - val_loss: 8.3730\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.5272 - val_loss: 8.3671\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.5213 - val_loss: 8.3611\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.5154 - val_loss: 8.3553\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.5095 - val_loss: 8.3495\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.5037 - val_loss: 8.3438\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.4980 - val_loss: 8.3378\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.4922 - val_loss: 8.3323\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.4867 - val_loss: 8.3266\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4810 - val_loss: 8.3210\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4753 - val_loss: 8.3153\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4695 - val_loss: 8.3097\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4640 - val_loss: 8.3042\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.4587 - val_loss: 8.2986\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.4531 - val_loss: 8.2930\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.4475 - val_loss: 8.2873\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.4418 - val_loss: 8.2817\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.4363 - val_loss: 8.2761\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.4307 - val_loss: 8.2707\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.4255 - val_loss: 8.2653\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.4200 - val_loss: 8.2601\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.4148 - val_loss: 8.2546\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.4094 - val_loss: 8.2491\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.4039 - val_loss: 8.2439\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.3987 - val_loss: 8.2387\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.3934 - val_loss: 8.2336\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.3883 - val_loss: 8.2284\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.3831 - val_loss: 8.2234\n",
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.3780 - val_loss: 8.2182\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 98us/sample - loss: 8.3728 - val_loss: 8.2131\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 8.378 - 0s 69us/sample - loss: 8.3676 - val_loss: 8.2077\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.3623 - val_loss: 8.2024\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.3569 - val_loss: 8.1973\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.3518 - val_loss: 8.1919\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.3464 - val_loss: 8.1870\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.3415 - val_loss: 8.1819\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.3363 - val_loss: 8.1766\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 52us/sample - loss: 8.3310 - val_loss: 8.1715\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.3260 - val_loss: 8.1663\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.3208 - val_loss: 8.1611\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.3156 - val_loss: 8.1561\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.3106 - val_loss: 8.1511\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.3058 - val_loss: 8.1460\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.3007 - val_loss: 8.1409\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.2957 - val_loss: 8.1360\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.2909 - val_loss: 8.1309\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.2859 - val_loss: 8.1259\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.2809 - val_loss: 8.1208\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.2759 - val_loss: 8.1157\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 8.2709 - val_loss: 8.1108\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.2660 - val_loss: 8.1057\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.2611 - val_loss: 8.1006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2563 - val_loss: 8.0957\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 8.927 - 0s 66us/sample - loss: 8.2516 - val_loss: 8.0910\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.2470 - val_loss: 8.0860\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.2423 - val_loss: 8.0812\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.2377 - val_loss: 8.0765\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.2332 - val_loss: 8.0720\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.2290 - val_loss: 8.0673\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.2246 - val_loss: 8.0629\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.2204 - val_loss: 8.0582\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.2159 - val_loss: 8.0533\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.2114 - val_loss: 8.0486\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.2070 - val_loss: 8.0439\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2026 - val_loss: 8.0394\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.1984 - val_loss: 8.0347\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1940 - val_loss: 8.0301\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.1898 - val_loss: 8.0257\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.1856 - val_loss: 8.0211\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.1812 - val_loss: 8.0165\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.1770 - val_loss: 8.0122\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 8.1729 - val_loss: 8.0074\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.1684 - val_loss: 8.0027\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1640 - val_loss: 7.9982\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.1598 - val_loss: 7.9939\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.1558 - val_loss: 7.9895\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.1516 - val_loss: 7.9851\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.1475 - val_loss: 7.9805\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1432 - val_loss: 7.9760\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.1390 - val_loss: 7.9715\n",
      "Epoch 500/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.1348 - val_loss: 7.9673\n",
      "594/594 [==============================] - 0s 34us/sample - loss: 8.0008\n",
      "[CV]  learning_rate=0.0006930605663535878, n_hidden=0, n_neurons=161, total=  44.9s\n",
      "[CV] learning_rate=0.0012178834831452913, n_hidden=1, n_neurons=253 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 310us/sample - loss: 14.0673 - val_loss: 13.6565\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.8497 - val_loss: 13.4506\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.6500 - val_loss: 13.2534\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 13.4582 - val_loss: 13.0607\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.2748 - val_loss: 12.8689\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 13.0912 - val_loss: 12.6796\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.9103 - val_loss: 12.4907\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 12.7294 - val_loss: 12.3029\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.5484 - val_loss: 12.1166\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.3670 - val_loss: 11.9311\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.1867 - val_loss: 11.7479\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.0091 - val_loss: 11.5668\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.8354 - val_loss: 11.3940\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.6663 - val_loss: 11.2216\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.4992 - val_loss: 11.0469\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.3274 - val_loss: 10.8691\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 11.1549 - val_loss: 10.6946\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.9861 - val_loss: 10.5191\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.8138 - val_loss: 10.3531\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.6471 - val_loss: 10.1873\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.4805 - val_loss: 10.0275\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 10.3205 - val_loss: 9.8720\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.1599 - val_loss: 9.7181\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 9.9980 - val_loss: 9.5610\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.8331 - val_loss: 9.4092\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.6745 - val_loss: 9.2603\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5194 - val_loss: 9.1256\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.3793 - val_loss: 8.9940\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.2423 - val_loss: 8.8619\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.1080 - val_loss: 8.7357\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9767 - val_loss: 8.6110\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8445 - val_loss: 8.4937\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.7193 - val_loss: 8.3834\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6017 - val_loss: 8.2690\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.4815 - val_loss: 8.1570\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.3674 - val_loss: 8.0553\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2666 - val_loss: 7.9690\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.1811 - val_loss: 7.8833\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.0996 - val_loss: 7.8027\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.0231 - val_loss: 7.7308\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.9573 - val_loss: 7.6579\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.8892 - val_loss: 7.5859\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.8231 - val_loss: 7.5253\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.7664 - val_loss: 7.4731\n",
      "Epoch 45/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.7159 - val_loss: 7.4232\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.6666 - val_loss: 7.3755\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.6190 - val_loss: 7.3329\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5787 - val_loss: 7.2977\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.5435 - val_loss: 7.2668\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5137 - val_loss: 7.2352\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.4838 - val_loss: 7.2068\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.4563 - val_loss: 7.1815\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.4330 - val_loss: 7.1606\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4110 - val_loss: 7.1391\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3878 - val_loss: 7.1213\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3667 - val_loss: 7.1063\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.3504 - val_loss: 7.0915\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3347 - val_loss: 7.0799\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3206 - val_loss: 7.0679\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3066 - val_loss: 7.0574\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2944 - val_loss: 7.0483\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2838 - val_loss: 7.0421\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2752 - val_loss: 7.0358\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2660 - val_loss: 7.0295\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2562 - val_loss: 7.0259\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2490 - val_loss: 7.0195\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2404 - val_loss: 7.0163\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2344 - val_loss: 7.0147\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2284 - val_loss: 7.0106\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2224 - val_loss: 7.0079\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2173 - val_loss: 7.0067\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2111 - val_loss: 7.0042\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2059 - val_loss: 7.0019\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.2011 - val_loss: 6.9989\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1964 - val_loss: 6.9976\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 104us/sample - loss: 7.1924 - val_loss: 6.9977\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 130us/sample - loss: 7.1886 - val_loss: 6.9953\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 112us/sample - loss: 7.1845 - val_loss: 6.9944\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 104us/sample - loss: 7.1814 - val_loss: 6.9931\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 129us/sample - loss: 7.1780 - val_loss: 6.9935\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 113us/sample - loss: 7.1744 - val_loss: 6.9935\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 131us/sample - loss: 7.1711 - val_loss: 6.9945\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 110us/sample - loss: 7.1679 - val_loss: 6.9952\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 109us/sample - loss: 7.1650 - val_loss: 6.9950\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 121us/sample - loss: 7.1618 - val_loss: 6.9952\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 115us/sample - loss: 7.1597 - val_loss: 6.9955\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 111us/sample - loss: 7.1574 - val_loss: 6.9956\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 115us/sample - loss: 7.1542 - val_loss: 6.9963\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 132us/sample - loss: 7.1523 - val_loss: 6.9973\n",
      "594/594 [==============================] - 0s 43us/sample - loss: 6.9377\n",
      "[CV]  learning_rate=0.0012178834831452913, n_hidden=1, n_neurons=253, total=   9.3s\n",
      "[CV] learning_rate=0.0012178834831452913, n_hidden=1, n_neurons=253 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 381us/sample - loss: 14.1579 - val_loss: 13.7910\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 13.9318 - val_loss: 13.5743\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 13.7193 - val_loss: 13.3638\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 13.5117 - val_loss: 13.1593\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 13.3077 - val_loss: 12.9511\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 111us/sample - loss: 13.1012 - val_loss: 12.7466\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 136us/sample - loss: 12.8987 - val_loss: 12.5474\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 12.7010 - val_loss: 12.3517\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 116us/sample - loss: 12.5064 - val_loss: 12.1540\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 138us/sample - loss: 12.3108 - val_loss: 11.9565\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 112us/sample - loss: 12.1165 - val_loss: 11.7622\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 141us/sample - loss: 11.9233 - val_loss: 11.5740\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 119us/sample - loss: 11.7370 - val_loss: 11.3855\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 11.5466 - val_loss: 11.2012\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 11.3613 - val_loss: 11.0157\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 11.1744 - val_loss: 10.8295\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.9890 - val_loss: 10.6441\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.8029 - val_loss: 10.4573\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.6122 - val_loss: 10.2764\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 10.4196 - val_loss: 10.0975\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.2240 - val_loss: 9.9219\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 10.0316 - val_loss: 9.7474\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 122us/sample - loss: 9.8418 - val_loss: 9.5802\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 112us/sample - loss: 9.6569 - val_loss: 9.4130\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 9.4754 - val_loss: 9.2494\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 130us/sample - loss: 9.2962 - val_loss: 9.0921\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 159us/sample - loss: 9.1284 - val_loss: 8.9379\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 130us/sample - loss: 8.9653 - val_loss: 8.7864\n",
      "Epoch 29/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.8062 - val_loss: 8.6416\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 8.6537 - val_loss: 8.5017\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.5053 - val_loss: 8.3693\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.3639 - val_loss: 8.2436\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.2292 - val_loss: 8.1307\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.1110 - val_loss: 8.0240\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.9991 - val_loss: 7.9271\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.8975 - val_loss: 7.8317\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.8026 - val_loss: 7.7422\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.7182 - val_loss: 7.6635\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6412 - val_loss: 7.5837\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5620 - val_loss: 7.5147\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4930 - val_loss: 7.4481\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.4255 - val_loss: 7.3905\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.3700 - val_loss: 7.3382\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3210 - val_loss: 7.2904\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2765 - val_loss: 7.2492\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2389 - val_loss: 7.2135\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2047 - val_loss: 7.1793\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1716 - val_loss: 7.1520\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 7.1422 - val_loss: 7.1286\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1162 - val_loss: 7.1052\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0906 - val_loss: 7.0835\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.0676 - val_loss: 7.0651\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 122us/sample - loss: 7.0480 - val_loss: 7.0507\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 107us/sample - loss: 7.0314 - val_loss: 7.0388\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 105us/sample - loss: 7.0174 - val_loss: 7.0289\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 7.0034 - val_loss: 7.0208\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 113us/sample - loss: 6.9918 - val_loss: 7.0147\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 162us/sample - loss: 6.9820 - val_loss: 7.0103\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 140us/sample - loss: 6.9729 - val_loss: 7.0050\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 114us/sample - loss: 6.9654 - val_loss: 7.0010\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 6.9585 - val_loss: 6.9979\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.9523 - val_loss: 6.9955\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.9466 - val_loss: 6.9938\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 104us/sample - loss: 6.9419 - val_loss: 6.9914\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 115us/sample - loss: 6.9365 - val_loss: 6.9909\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.9330 - val_loss: 6.9891\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.9275 - val_loss: 6.9884\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.9231 - val_loss: 6.9880\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.9195 - val_loss: 6.9857\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9160 - val_loss: 6.9846\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.9129 - val_loss: 6.9838\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.9091 - val_loss: 6.9830\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.9056 - val_loss: 6.9814\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.9019 - val_loss: 6.9801\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.8984 - val_loss: 6.9777\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.8955 - val_loss: 6.9781\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.8923 - val_loss: 6.9778\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.8893 - val_loss: 6.9776\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.8868 - val_loss: 6.9760\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.8844 - val_loss: 6.9754\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.8818 - val_loss: 6.9756\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.8794 - val_loss: 6.9757\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 95us/sample - loss: 6.8774 - val_loss: 6.9764\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.8754 - val_loss: 6.9755\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 6.8727 - val_loss: 6.9752\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 6.8707 - val_loss: 6.9756\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.8687 - val_loss: 6.9754\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.8668 - val_loss: 6.9747\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.8649 - val_loss: 6.9748\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 6.8624 - val_loss: 6.9745\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.8603 - val_loss: 6.9740\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 103us/sample - loss: 6.8582 - val_loss: 6.9739\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.8562 - val_loss: 6.9731\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.8545 - val_loss: 6.9740\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 6.8529 - val_loss: 6.9743\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.8507 - val_loss: 6.9736\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.8489 - val_loss: 6.9735\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 6.8474 - val_loss: 6.9738\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.8457 - val_loss: 6.9748\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.8436 - val_loss: 6.9734\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 6.8418 - val_loss: 6.9743\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 6.8404 - val_loss: 6.9749\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 6.8388 - val_loss: 6.9744\n",
      "594/594 [==============================] - 0s 39us/sample - loss: 7.5591\n",
      "[CV]  learning_rate=0.0012178834831452913, n_hidden=1, n_neurons=253, total=  12.2s\n",
      "[CV] learning_rate=0.0012178834831452913, n_hidden=1, n_neurons=253 ..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 355us/sample - loss: 13.8569 - val_loss: 13.6055\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 143us/sample - loss: 13.6493 - val_loss: 13.4019\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 123us/sample - loss: 13.4493 - val_loss: 13.2028\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 13.2503 - val_loss: 13.0047\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 13.0546 - val_loss: 12.8081\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 104us/sample - loss: 12.8605 - val_loss: 12.6121\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.6737 - val_loss: 12.4264\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.4936 - val_loss: 12.2433\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 12.3175 - val_loss: 12.0634\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 12.1444 - val_loss: 11.8886\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 11.9754 - val_loss: 11.7111\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 11.8033 - val_loss: 11.5398\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.6348 - val_loss: 11.3668\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.4695 - val_loss: 11.2011\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 11.3099 - val_loss: 11.0333\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.1497 - val_loss: 10.8631\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 10.9878 - val_loss: 10.6942\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.8264 - val_loss: 10.5306\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 10.6656 - val_loss: 10.3700\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.5055 - val_loss: 10.2083\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.3452 - val_loss: 10.0509\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1891 - val_loss: 9.8967\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.0357 - val_loss: 9.7445\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.8862 - val_loss: 9.6042\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.7487 - val_loss: 9.4583\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.6044 - val_loss: 9.3138\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.4627 - val_loss: 9.1681\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.3187 - val_loss: 9.0335\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.1828 - val_loss: 8.9060\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 9.0508 - val_loss: 8.7763\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 8.9192 - val_loss: 8.6594\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8020 - val_loss: 8.5427\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.6813 - val_loss: 8.4334\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.5681 - val_loss: 8.3299\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.4615 - val_loss: 8.2323\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.3615 - val_loss: 8.1353\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2633 - val_loss: 8.0449\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.1724 - val_loss: 7.9587\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.0871 - val_loss: 7.8706\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.0054 - val_loss: 7.7924\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.9332 - val_loss: 7.7206\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.8660 - val_loss: 7.6616\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.8118 - val_loss: 7.6029\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.7578 - val_loss: 7.5473\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 55us/sample - loss: 7.7089 - val_loss: 7.4893\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.6597 - val_loss: 7.4450\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6209 - val_loss: 7.3962\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5789 - val_loss: 7.3542\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.5437 - val_loss: 7.3190\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.5117 - val_loss: 7.2858\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4813 - val_loss: 7.2564\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.4541 - val_loss: 7.2299\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4293 - val_loss: 7.2045\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4055 - val_loss: 7.1833\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3844 - val_loss: 7.1644\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3650 - val_loss: 7.1439\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.3444 - val_loss: 7.1279\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 161us/sample - loss: 7.3273 - val_loss: 7.1096\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.3092 - val_loss: 7.0935\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.2928 - val_loss: 7.0786\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.2781 - val_loss: 7.0684\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 7.2667 - val_loss: 7.0607\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2566 - val_loss: 7.0534\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2492 - val_loss: 7.0487\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2419 - val_loss: 7.0422\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.2338 - val_loss: 7.0371\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.2259 - val_loss: 7.0333\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2198 - val_loss: 7.0301\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2137 - val_loss: 7.0266\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2083 - val_loss: 7.0234\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2035 - val_loss: 7.0222\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1985 - val_loss: 7.0200\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1929 - val_loss: 7.0171\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1889 - val_loss: 7.0154\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1856 - val_loss: 7.0118\n",
      "Epoch 76/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1816 - val_loss: 7.0110\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1790 - val_loss: 7.0102\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1755 - val_loss: 7.0082\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1714 - val_loss: 7.0063\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.1684 - val_loss: 7.0051\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1657 - val_loss: 7.0037\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1632 - val_loss: 7.0035\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1607 - val_loss: 7.0023\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1585 - val_loss: 7.0017\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1561 - val_loss: 7.0003\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1539 - val_loss: 7.0003\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1516 - val_loss: 6.9991\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1488 - val_loss: 6.9973\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1464 - val_loss: 6.9966\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1438 - val_loss: 6.9962\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1419 - val_loss: 6.9960\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1399 - val_loss: 6.9948\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1378 - val_loss: 6.9940\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1357 - val_loss: 6.9935\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1344 - val_loss: 6.9939\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1324 - val_loss: 6.9944\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1304 - val_loss: 6.9947\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1286 - val_loss: 6.9937\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1268 - val_loss: 6.9933\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.1249 - val_loss: 6.9935\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1231 - val_loss: 6.9941\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1215 - val_loss: 6.9937\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1204 - val_loss: 6.9944\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1189 - val_loss: 6.9943\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1173 - val_loss: 6.9938\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1161 - val_loss: 6.9944\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1143 - val_loss: 6.9952\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1129 - val_loss: 6.9951\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1118 - val_loss: 6.9951\n",
      "594/594 [==============================] - 0s 37us/sample - loss: 6.9981\n",
      "[CV]  learning_rate=0.0012178834831452913, n_hidden=1, n_neurons=253, total=  10.9s\n",
      "[CV] learning_rate=0.0021928619507738728, n_hidden=0, n_neurons=475 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 295us/sample - loss: 14.1429 - val_loss: 13.6716\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 14.0663 - val_loss: 13.5973\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.9911 - val_loss: 13.5231\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.9159 - val_loss: 13.4488\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.8404 - val_loss: 13.3753\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.7656 - val_loss: 13.3024\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 13.6916 - val_loss: 13.2302\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 13.6177 - val_loss: 13.1586\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.5443 - val_loss: 13.0876\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.4716 - val_loss: 13.0168\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 13.3992 - val_loss: 12.9468\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.3279 - val_loss: 12.8773\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 13.2571 - val_loss: 12.8088\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.1866 - val_loss: 12.7412\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.1172 - val_loss: 12.6741\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.0484 - val_loss: 12.6078\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.9804 - val_loss: 12.5422\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.9131 - val_loss: 12.4770\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 12.8466 - val_loss: 12.4124\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7806 - val_loss: 12.3488\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.7161 - val_loss: 12.2854\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.6520 - val_loss: 12.2238\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.5894 - val_loss: 12.1631\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.5275 - val_loss: 12.1019\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.4650 - val_loss: 12.0410\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 12.4027 - val_loss: 11.9804\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 12.3413 - val_loss: 11.9207\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.2803 - val_loss: 11.8624\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 12.2203 - val_loss: 11.8042\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 12.1604 - val_loss: 11.7455\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.1005 - val_loss: 11.6881\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.0410 - val_loss: 11.6318\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.9826 - val_loss: 11.5755\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.9244 - val_loss: 11.5199\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.8668 - val_loss: 11.4647\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.8100 - val_loss: 11.4109\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.7545 - val_loss: 11.3575\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 11.6989 - val_loss: 11.3048\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.6436 - val_loss: 11.2526\n",
      "Epoch 40/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 73us/sample - loss: 11.5884 - val_loss: 11.2008\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 11.5338 - val_loss: 11.1490\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.4800 - val_loss: 11.0984\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.4271 - val_loss: 11.0491\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.3751 - val_loss: 11.0003\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.3234 - val_loss: 10.9518\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.2723 - val_loss: 10.9038\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.2217 - val_loss: 10.8572\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.1722 - val_loss: 10.8100\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.1219 - val_loss: 10.7625\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.0715 - val_loss: 10.7150\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.0214 - val_loss: 10.6690\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.9725 - val_loss: 10.6233\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.9238 - val_loss: 10.5794\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 10.8771 - val_loss: 10.5347\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 10.8292 - val_loss: 10.4917\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.7825 - val_loss: 10.4490\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.7364 - val_loss: 10.4068\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 10.6906 - val_loss: 10.3658\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.6459 - val_loss: 10.3246\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.6007 - val_loss: 10.2836\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.5562 - val_loss: 10.2434\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.5124 - val_loss: 10.2049\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.4702 - val_loss: 10.1653\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.4275 - val_loss: 10.1262\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.3850 - val_loss: 10.0873\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.3430 - val_loss: 10.0490\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.3016 - val_loss: 10.0118\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.2610 - val_loss: 9.9755\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.2224 - val_loss: 9.9384\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.1826 - val_loss: 9.9016\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 10.1436 - val_loss: 9.8654\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1038 - val_loss: 9.8290\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 10.0653 - val_loss: 9.7941\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.0280 - val_loss: 9.7585\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.9910 - val_loss: 9.7236\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.9539 - val_loss: 9.6894\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.9179 - val_loss: 9.6550\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.8814 - val_loss: 9.6209\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.8454 - val_loss: 9.5879\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.8107 - val_loss: 9.5547\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.7758 - val_loss: 9.5224\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.7416 - val_loss: 9.4907\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.7082 - val_loss: 9.4597\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.6749 - val_loss: 9.4279\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.6412 - val_loss: 9.3966\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.6076 - val_loss: 9.3658\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.5758 - val_loss: 9.3361\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.5442 - val_loss: 9.3063\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5127 - val_loss: 9.2783\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.4827 - val_loss: 9.2496\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.4521 - val_loss: 9.2223\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.4229 - val_loss: 9.1944\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.3937 - val_loss: 9.1671\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.3645 - val_loss: 9.1395\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.3352 - val_loss: 9.1121\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.3060 - val_loss: 9.0854\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2779 - val_loss: 9.0586\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.2491 - val_loss: 9.0318\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.2212 - val_loss: 9.0076\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.1951 - val_loss: 8.9818\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.1675 - val_loss: 8.9562\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.1402 - val_loss: 8.9314\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.1133 - val_loss: 8.9058\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.0863 - val_loss: 8.8813\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0600 - val_loss: 8.8567\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.0333 - val_loss: 8.8333\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.0082 - val_loss: 8.8090\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9826 - val_loss: 8.7859\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.9577 - val_loss: 8.7633\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 8.9334 - val_loss: 8.7400\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.9084 - val_loss: 8.7176\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.8839 - val_loss: 8.6949\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8600 - val_loss: 8.6729\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.8366 - val_loss: 8.6519\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8147 - val_loss: 8.6296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.7915 - val_loss: 8.6085\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.7693 - val_loss: 8.5871\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.7469 - val_loss: 8.5662\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.7251 - val_loss: 8.5454\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7034 - val_loss: 8.5245\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.6817 - val_loss: 8.5037\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.6601 - val_loss: 8.4836\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.6392 - val_loss: 8.4640\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 8.6193 - val_loss: 8.4437\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.5984 - val_loss: 8.4242\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.5784 - val_loss: 8.4047\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.5579 - val_loss: 8.3853\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.5379 - val_loss: 8.3674\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.5196 - val_loss: 8.3486\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 8.5007 - val_loss: 8.3311\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4827 - val_loss: 8.3129\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4648 - val_loss: 8.2946\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.4466 - val_loss: 8.2767\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.4286 - val_loss: 8.2592\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.4115 - val_loss: 8.2413\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.3941 - val_loss: 8.2243\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3773 - val_loss: 8.2067\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.3603 - val_loss: 8.1901\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 8.350 - 0s 70us/sample - loss: 8.3438 - val_loss: 8.1733\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.3277 - val_loss: 8.1565\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.3116 - val_loss: 8.1407\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.2964 - val_loss: 8.1254\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.2815 - val_loss: 8.1100\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2666 - val_loss: 8.0944\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.2514 - val_loss: 8.0796\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.2372 - val_loss: 8.0645\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.2224 - val_loss: 8.0499\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.2080 - val_loss: 8.0352\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.1938 - val_loss: 8.0207\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.1793 - val_loss: 8.0061\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.1654 - val_loss: 7.9921\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1515 - val_loss: 7.9784\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.1382 - val_loss: 7.9651\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.1252 - val_loss: 7.9523\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.1126 - val_loss: 7.9392\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.1001 - val_loss: 7.9265\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.0877 - val_loss: 7.9129\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.0745 - val_loss: 7.8998\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.0618 - val_loss: 7.8867\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.0492 - val_loss: 7.8742\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 8.0371 - val_loss: 7.8619\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0250 - val_loss: 7.8490\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.0127 - val_loss: 7.8377\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0016 - val_loss: 7.8256\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.9898 - val_loss: 7.8147\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.9788 - val_loss: 7.8037\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9677 - val_loss: 7.7924\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.9565 - val_loss: 7.7805\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.9447 - val_loss: 7.7686\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9328 - val_loss: 7.7576\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.9220 - val_loss: 7.7464\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.9110 - val_loss: 7.7360\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.9007 - val_loss: 7.7254\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.8903 - val_loss: 7.7151\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.8799 - val_loss: 7.7053\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.8706 - val_loss: 7.6960\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.8617 - val_loss: 7.6866\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.8527 - val_loss: 7.6777\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.8439 - val_loss: 7.6683\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.8349 - val_loss: 7.6593\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.8260 - val_loss: 7.6505\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.8173 - val_loss: 7.6420\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.8090 - val_loss: 7.6331\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.8003 - val_loss: 7.6250\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7924 - val_loss: 7.6162\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.7839 - val_loss: 7.6077\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7756 - val_loss: 7.5991\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7673 - val_loss: 7.5906\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.7589 - val_loss: 7.5820\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.7509 - val_loss: 7.5738\n",
      "Epoch 191/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.7433 - val_loss: 7.5659\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7357 - val_loss: 7.5577\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.7279 - val_loss: 7.5498\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7201 - val_loss: 7.5417\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.7124 - val_loss: 7.5333\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.7048 - val_loss: 7.5261\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.6978 - val_loss: 7.5184\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.6904 - val_loss: 7.5105\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.6828 - val_loss: 7.5030\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.6757 - val_loss: 7.4953\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.6686 - val_loss: 7.4875\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.6613 - val_loss: 7.4802\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.6545 - val_loss: 7.4732\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.6481 - val_loss: 7.4660\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.6415 - val_loss: 7.4593\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.6352 - val_loss: 7.4526\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.6290 - val_loss: 7.4456\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.6226 - val_loss: 7.4387\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.6164 - val_loss: 7.4326\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.6105 - val_loss: 7.4263\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.6047 - val_loss: 7.4197\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5987 - val_loss: 7.4135\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.5929 - val_loss: 7.4075\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.5875 - val_loss: 7.4013\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.5817 - val_loss: 7.3947\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.5760 - val_loss: 7.3886\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.5704 - val_loss: 7.3823\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.5648 - val_loss: 7.3767\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.5597 - val_loss: 7.3712\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.5548 - val_loss: 7.3656\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.5497 - val_loss: 7.3604\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.5447 - val_loss: 7.3549\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.5396 - val_loss: 7.3495\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.5348 - val_loss: 7.3442\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.5299 - val_loss: 7.3388\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.5249 - val_loss: 7.3332\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.5198 - val_loss: 7.3282\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5153 - val_loss: 7.3235\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.5111 - val_loss: 7.3181\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.5063 - val_loss: 7.3130\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.5018 - val_loss: 7.3080\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4973 - val_loss: 7.3031\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.4932 - val_loss: 7.2982\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.4891 - val_loss: 7.2937\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.4853 - val_loss: 7.2893\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4814 - val_loss: 7.2852\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.4780 - val_loss: 7.2807\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.4741 - val_loss: 7.2758\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.4700 - val_loss: 7.2718\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4666 - val_loss: 7.2676\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.4629 - val_loss: 7.2633\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.4592 - val_loss: 7.2593\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.4557 - val_loss: 7.2549\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.4518 - val_loss: 7.2506\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.4480 - val_loss: 7.2466\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.4443 - val_loss: 7.2428\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4407 - val_loss: 7.2386\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4369 - val_loss: 7.2350\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.4336 - val_loss: 7.2312\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4300 - val_loss: 7.2273\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.4266 - val_loss: 7.2233\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.4229 - val_loss: 7.2196\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4197 - val_loss: 7.2153\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4159 - val_loss: 7.2117\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4125 - val_loss: 7.2085\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.4093 - val_loss: 7.2051\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4061 - val_loss: 7.2018\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.4028 - val_loss: 7.1983\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3995 - val_loss: 7.1947\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3962 - val_loss: 7.1915\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3933 - val_loss: 7.1882\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3900 - val_loss: 7.1847\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3867 - val_loss: 7.1813\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3837 - val_loss: 7.1783\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3809 - val_loss: 7.1749\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3779 - val_loss: 7.1716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3750 - val_loss: 7.1683\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3719 - val_loss: 7.1648\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.3685 - val_loss: 7.1612\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3654 - val_loss: 7.1579\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.3622 - val_loss: 7.1549\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3594 - val_loss: 7.1523\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3566 - val_loss: 7.1496\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3539 - val_loss: 7.1466\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 60us/sample - loss: 7.3509 - val_loss: 7.1438\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.3482 - val_loss: 7.1412\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3455 - val_loss: 7.1387\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3431 - val_loss: 7.1363\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3405 - val_loss: 7.1336\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3379 - val_loss: 7.1311\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3355 - val_loss: 7.1288\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3332 - val_loss: 7.1262\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 52us/sample - loss: 7.3306 - val_loss: 7.1238\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3282 - val_loss: 7.1217\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.3261 - val_loss: 7.1191\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.3237 - val_loss: 7.1167\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.3215 - val_loss: 7.1146\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3194 - val_loss: 7.1124\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3173 - val_loss: 7.1102\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3152 - val_loss: 7.1076\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3130 - val_loss: 7.1053\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3109 - val_loss: 7.1028\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3086 - val_loss: 7.1009\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3066 - val_loss: 7.0988\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.3047 - val_loss: 7.0967\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3029 - val_loss: 7.0947\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3009 - val_loss: 7.0928\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2992 - val_loss: 7.0908\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2972 - val_loss: 7.0889\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2953 - val_loss: 7.0869\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2933 - val_loss: 7.0852\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2915 - val_loss: 7.0836\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2898 - val_loss: 7.0819\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.2881 - val_loss: 7.0800\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2862 - val_loss: 7.0782\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2841 - val_loss: 7.0763\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2821 - val_loss: 7.0747\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2802 - val_loss: 7.0731\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2785 - val_loss: 7.0714\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2768 - val_loss: 7.0696\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2748 - val_loss: 7.0677\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2731 - val_loss: 7.0660\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2713 - val_loss: 7.0644\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2696 - val_loss: 7.0628\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2677 - val_loss: 7.0612\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2661 - val_loss: 7.0596\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2645 - val_loss: 7.0580\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2628 - val_loss: 7.0560\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2610 - val_loss: 7.0543\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2592 - val_loss: 7.0526\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2576 - val_loss: 7.0511\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2559 - val_loss: 7.0495\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2542 - val_loss: 7.0480\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2527 - val_loss: 7.0461\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2506 - val_loss: 7.0445\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2490 - val_loss: 7.0432\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2475 - val_loss: 7.0416\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2459 - val_loss: 7.0401\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2443 - val_loss: 7.0386\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2427 - val_loss: 7.0369\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2410 - val_loss: 7.0355\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2395 - val_loss: 7.0338\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2378 - val_loss: 7.0323\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2362 - val_loss: 7.0306\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.2347 - val_loss: 7.0291\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2333 - val_loss: 7.0277\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.2318 - val_loss: 7.0265\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2305 - val_loss: 7.0251\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2290 - val_loss: 7.0238\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2277 - val_loss: 7.0223\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2263 - val_loss: 7.0211\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2250 - val_loss: 7.0198\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2237 - val_loss: 7.0186\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2224 - val_loss: 7.0174\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2212 - val_loss: 7.0164\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2201 - val_loss: 7.0154\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2189 - val_loss: 7.0144\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2180 - val_loss: 7.0131\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2168 - val_loss: 7.0124\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2157 - val_loss: 7.0113\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2147 - val_loss: 7.0103\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2137 - val_loss: 7.0097\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2127 - val_loss: 7.0090\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2117 - val_loss: 7.0079\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2107 - val_loss: 7.0070\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2095 - val_loss: 7.0060\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2086 - val_loss: 7.0053\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2077 - val_loss: 7.0044\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2068 - val_loss: 7.0037\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.2060 - val_loss: 7.0029\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2048 - val_loss: 7.0021\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2038 - val_loss: 7.0015\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2031 - val_loss: 7.0008\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2023 - val_loss: 7.0002\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2014 - val_loss: 6.9998\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2006 - val_loss: 6.9991\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1997 - val_loss: 6.9984\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1990 - val_loss: 6.9979\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1982 - val_loss: 6.9973\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1974 - val_loss: 6.9967\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1966 - val_loss: 6.9962\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1958 - val_loss: 6.9957\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1950 - val_loss: 6.9951\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1942 - val_loss: 6.9945\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1935 - val_loss: 6.9938\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1929 - val_loss: 6.9931\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1922 - val_loss: 6.9926\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1916 - val_loss: 6.9921\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1908 - val_loss: 6.9916\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1900 - val_loss: 6.9909\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1893 - val_loss: 6.9905\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1886 - val_loss: 6.9900\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1879 - val_loss: 6.9894\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1871 - val_loss: 6.9888\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1864 - val_loss: 6.9882\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1858 - val_loss: 6.9876\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1852 - val_loss: 6.9872\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1848 - val_loss: 6.9869\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1841 - val_loss: 6.9863\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1836 - val_loss: 6.9860\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1829 - val_loss: 6.9854\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1824 - val_loss: 6.9847\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1818 - val_loss: 6.9842\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1813 - val_loss: 6.9839\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1808 - val_loss: 6.9833\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1802 - val_loss: 6.9830\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1797 - val_loss: 6.9829\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1789 - val_loss: 6.9825\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1785 - val_loss: 6.9821\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1779 - val_loss: 6.9817\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1772 - val_loss: 6.9814\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1767 - val_loss: 6.9809\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1762 - val_loss: 6.9803\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1756 - val_loss: 6.9799\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1751 - val_loss: 6.9797\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1747 - val_loss: 6.9792\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1742 - val_loss: 6.9789\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1737 - val_loss: 6.9790\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1733 - val_loss: 6.9788\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.1729 - val_loss: 6.9787\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1724 - val_loss: 6.9788\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1719 - val_loss: 6.9784\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1714 - val_loss: 6.9785\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1710 - val_loss: 6.9782\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.1705 - val_loss: 6.9781\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1702 - val_loss: 6.9778\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1698 - val_loss: 6.9776\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.1694 - val_loss: 6.9776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1690 - val_loss: 6.9773\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1686 - val_loss: 6.9770\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1681 - val_loss: 6.9766\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1678 - val_loss: 6.9762\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1674 - val_loss: 6.9761\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1671 - val_loss: 6.9759\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1666 - val_loss: 6.9760\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1663 - val_loss: 6.9757\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1660 - val_loss: 6.9757\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1657 - val_loss: 6.9754\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1654 - val_loss: 6.9753\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1651 - val_loss: 6.9754\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1647 - val_loss: 6.9752\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1643 - val_loss: 6.9752\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1641 - val_loss: 6.9750\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1637 - val_loss: 6.9749\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1635 - val_loss: 6.9744\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1631 - val_loss: 6.9743\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1628 - val_loss: 6.9742\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1626 - val_loss: 6.9741\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.1623 - val_loss: 6.9736\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1619 - val_loss: 6.9736\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1616 - val_loss: 6.9735\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1613 - val_loss: 6.9735\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1610 - val_loss: 6.9734\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.1607 - val_loss: 6.9732\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.1605 - val_loss: 6.9730\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1602 - val_loss: 6.9728\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1598 - val_loss: 6.9726\n",
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1595 - val_loss: 6.9722\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1593 - val_loss: 6.9723\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.1590 - val_loss: 6.9721\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1586 - val_loss: 6.9718\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1584 - val_loss: 6.9716\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1581 - val_loss: 6.9714\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1578 - val_loss: 6.9712\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1576 - val_loss: 6.9712\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1573 - val_loss: 6.9708\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1571 - val_loss: 6.9708\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1568 - val_loss: 6.9707\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1566 - val_loss: 6.9708\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1564 - val_loss: 6.9708\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1562 - val_loss: 6.9708\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1559 - val_loss: 6.9707\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1557 - val_loss: 6.9704\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1554 - val_loss: 6.9701\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1552 - val_loss: 6.9701\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1549 - val_loss: 6.9700\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1547 - val_loss: 6.9699\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1544 - val_loss: 6.9696\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1541 - val_loss: 6.9694\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1539 - val_loss: 6.9692\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1538 - val_loss: 6.9689\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1534 - val_loss: 6.9687\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1534 - val_loss: 6.9685\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1531 - val_loss: 6.9684\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 7.1529 - val_loss: 6.9684\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1526 - val_loss: 6.9681\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1525 - val_loss: 6.9680\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1521 - val_loss: 6.9677\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1519 - val_loss: 6.9675\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1516 - val_loss: 6.9674\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1515 - val_loss: 6.9673\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1512 - val_loss: 6.9672\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1510 - val_loss: 6.9671\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1508 - val_loss: 6.9669\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1506 - val_loss: 6.9669\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1503 - val_loss: 6.9668\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1501 - val_loss: 6.9666\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1499 - val_loss: 6.9667\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1498 - val_loss: 6.9664\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1495 - val_loss: 6.9663\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1493 - val_loss: 6.9662\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1491 - val_loss: 6.9662\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1490 - val_loss: 6.9660\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1488 - val_loss: 6.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1485 - val_loss: 6.9659\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1483 - val_loss: 6.9659\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1481 - val_loss: 6.9660\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1479 - val_loss: 6.9659\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1477 - val_loss: 6.9660\n",
      "Epoch 500/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1475 - val_loss: 6.9658\n",
      "594/594 [==============================] - 0s 38us/sample - loss: 6.9646\n",
      "[CV]  learning_rate=0.0021928619507738728, n_hidden=0, n_neurons=475, total=  42.0s\n",
      "[CV] learning_rate=0.0021928619507738728, n_hidden=0, n_neurons=475 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 284us/sample - loss: 14.0535 - val_loss: 13.6496\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.9806 - val_loss: 13.5761\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.9075 - val_loss: 13.5032\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 13.8342 - val_loss: 13.4316\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 13.7619 - val_loss: 13.3596\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.6894 - val_loss: 13.2884\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.6179 - val_loss: 13.2181\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.5474 - val_loss: 13.1491\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.4778 - val_loss: 13.0806\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.4088 - val_loss: 13.0133\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.3411 - val_loss: 12.9456\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.2735 - val_loss: 12.8784\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 13.2058 - val_loss: 12.8117\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.1385 - val_loss: 12.7461\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 13.0726 - val_loss: 12.6808\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 13.0067 - val_loss: 12.6157\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.9410 - val_loss: 12.5509\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.8754 - val_loss: 12.4863\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.8101 - val_loss: 12.4225\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.7456 - val_loss: 12.3590\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.6819 - val_loss: 12.2957\n",
      "Epoch 22/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.6187 - val_loss: 12.2331\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.5558 - val_loss: 12.1718\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.4936 - val_loss: 12.1106\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.4322 - val_loss: 12.0488\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.3701 - val_loss: 11.9873\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.3087 - val_loss: 11.9275\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 12.2481 - val_loss: 11.8675\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.1872 - val_loss: 11.8095\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.1270 - val_loss: 11.7506\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.0664 - val_loss: 11.6941\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 12.0075 - val_loss: 11.6368\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.9473 - val_loss: 11.5806\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 11.8877 - val_loss: 11.5256\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.8294 - val_loss: 11.4708\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.7718 - val_loss: 11.4167\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.7145 - val_loss: 11.3629\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 11.6577 - val_loss: 11.3099\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.6015 - val_loss: 11.2570\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.5452 - val_loss: 11.2051\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.4902 - val_loss: 11.1531\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.4352 - val_loss: 11.1014\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 11.3809 - val_loss: 11.0505\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.3269 - val_loss: 10.9998\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.2732 - val_loss: 10.9500\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.2204 - val_loss: 10.9020\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 11.1687 - val_loss: 10.8532\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.1163 - val_loss: 10.8048\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 11.0644 - val_loss: 10.7566\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.0130 - val_loss: 10.7088\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.9626 - val_loss: 10.6617\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.9123 - val_loss: 10.6150\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.8629 - val_loss: 10.5705\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.8147 - val_loss: 10.5253\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 10.7656 - val_loss: 10.4812\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.7175 - val_loss: 10.4380\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.6696 - val_loss: 10.3953\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.6219 - val_loss: 10.3536\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.5754 - val_loss: 10.3122\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.5289 - val_loss: 10.2712\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.4830 - val_loss: 10.2309\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 10.4379 - val_loss: 10.1909\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 10.3927 - val_loss: 10.1517\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.3487 - val_loss: 10.1117\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.3035 - val_loss: 10.0735\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.2602 - val_loss: 10.0349\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.2170 - val_loss: 9.9981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.1746 - val_loss: 9.9607\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 10.1323 - val_loss: 9.9231\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.0895 - val_loss: 9.8857\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.0472 - val_loss: 9.8496\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.0061 - val_loss: 9.8124\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.9646 - val_loss: 9.7764\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.9237 - val_loss: 9.7413\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.8843 - val_loss: 9.7062\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.8446 - val_loss: 9.6721\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.8058 - val_loss: 9.6387\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.7672 - val_loss: 9.6046\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.7283 - val_loss: 9.5717\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 9.6909 - val_loss: 9.5396\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.6545 - val_loss: 9.5068\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 9.6174 - val_loss: 9.4752\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 9.5823 - val_loss: 9.4431\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 9.5466 - val_loss: 9.4109\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.5114 - val_loss: 9.3792\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.4763 - val_loss: 9.3493\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.4434 - val_loss: 9.3191\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.4096 - val_loss: 9.2889\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.3761 - val_loss: 9.2585\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.3432 - val_loss: 9.2279\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.3100 - val_loss: 9.1970\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.2773 - val_loss: 9.1673\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.2454 - val_loss: 9.1382\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.2137 - val_loss: 9.1087\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.1818 - val_loss: 9.0802\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.1508 - val_loss: 9.0511\n",
      "Epoch 97/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.1196 - val_loss: 9.0220\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.0886 - val_loss: 8.9932\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.0581 - val_loss: 8.9662\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.0289 - val_loss: 8.9380\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.9989 - val_loss: 8.9102\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.9693 - val_loss: 8.8826\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.9399 - val_loss: 8.8558\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.9114 - val_loss: 8.8293\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.8836 - val_loss: 8.8031\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.8557 - val_loss: 8.7772\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.8284 - val_loss: 8.7512\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.8007 - val_loss: 8.7261\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.7743 - val_loss: 8.7006\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.7479 - val_loss: 8.6754\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.7220 - val_loss: 8.6508\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6965 - val_loss: 8.6266\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.6708 - val_loss: 8.6017\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 8.6457 - val_loss: 8.5783\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.6214 - val_loss: 8.5547\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.5970 - val_loss: 8.5323\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5736 - val_loss: 8.5094\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.5496 - val_loss: 8.4876\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 159us/sample - loss: 8.5268 - val_loss: 8.4653\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 112us/sample - loss: 8.5032 - val_loss: 8.4431\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 108us/sample - loss: 8.4798 - val_loss: 8.4213\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 101us/sample - loss: 8.4569 - val_loss: 8.4002\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 8.4345 - val_loss: 8.3791\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.4123 - val_loss: 8.3585\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.3904 - val_loss: 8.3377\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.3683 - val_loss: 8.3171\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.3461 - val_loss: 8.2970\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.3242 - val_loss: 8.2769\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 8.3026 - val_loss: 8.2571\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 113us/sample - loss: 8.2811 - val_loss: 8.2384\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 8.2605 - val_loss: 8.2205\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 97us/sample - loss: 8.2408 - val_loss: 8.2017\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.2199 - val_loss: 8.1832\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 8.1993 - val_loss: 8.1660\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 8.1801 - val_loss: 8.1482\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 8.1601 - val_loss: 8.1314\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 106us/sample - loss: 8.1412 - val_loss: 8.1140\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 8.1223 - val_loss: 8.0974\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 8.1037 - val_loss: 8.0815\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.0857 - val_loss: 8.0656\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0676 - val_loss: 8.0496\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0498 - val_loss: 8.0339\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.0325 - val_loss: 8.0180\n",
      "Epoch 144/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.0151 - val_loss: 8.0023\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.9978 - val_loss: 7.9865\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9807 - val_loss: 7.9709\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.9635 - val_loss: 7.9550\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.9465 - val_loss: 7.9405\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.9306 - val_loss: 7.9268\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.9147 - val_loss: 7.9121\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.8985 - val_loss: 7.8983\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.8829 - val_loss: 7.8840\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.8670 - val_loss: 7.8702\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.8521 - val_loss: 7.8576\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.8379 - val_loss: 7.8439\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.8230 - val_loss: 7.8303\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.8080 - val_loss: 7.8171\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.7933 - val_loss: 7.8051\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.7799 - val_loss: 7.7926\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.7663 - val_loss: 7.7808\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.7531 - val_loss: 7.7687\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.7397 - val_loss: 7.7562\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.7263 - val_loss: 7.7452\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7144 - val_loss: 7.7329\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7011 - val_loss: 7.7217\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6888 - val_loss: 7.7106\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.6768 - val_loss: 7.6997\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.6650 - val_loss: 7.6883\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.6529 - val_loss: 7.6770\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.6408 - val_loss: 7.6664\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6297 - val_loss: 7.6555\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6183 - val_loss: 7.6450\n",
      "Epoch 173/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6075 - val_loss: 7.6352\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.5973 - val_loss: 7.6252\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.5865 - val_loss: 7.6152\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5762 - val_loss: 7.6061\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5667 - val_loss: 7.5966\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5565 - val_loss: 7.5875\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.5465 - val_loss: 7.5783\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 7.231 - 0s 71us/sample - loss: 7.5363 - val_loss: 7.5692\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.5263 - val_loss: 7.5605\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.5165 - val_loss: 7.5516\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.5070 - val_loss: 7.5432\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.4980 - val_loss: 7.5349\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 92us/sample - loss: 7.4889 - val_loss: 7.5270\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4803 - val_loss: 7.5192\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.4717 - val_loss: 7.5118\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.4633 - val_loss: 7.5045\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4550 - val_loss: 7.4973\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.4468 - val_loss: 7.4898\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.4384 - val_loss: 7.4822\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.4300 - val_loss: 7.4748\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.4216 - val_loss: 7.4683\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4141 - val_loss: 7.4618\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.4068 - val_loss: 7.4553\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.3993 - val_loss: 7.4493\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.3923 - val_loss: 7.4430\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3848 - val_loss: 7.4363\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.3770 - val_loss: 7.4300\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.3695 - val_loss: 7.4235\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3622 - val_loss: 7.4171\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3549 - val_loss: 7.4106\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3476 - val_loss: 7.4049\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3412 - val_loss: 7.3987\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.3343 - val_loss: 7.3926\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3277 - val_loss: 7.3869\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3213 - val_loss: 7.3811\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.3148 - val_loss: 7.3756\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3085 - val_loss: 7.3702\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.3025 - val_loss: 7.3645\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2961 - val_loss: 7.3591\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.2901 - val_loss: 7.3536\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2840 - val_loss: 7.3478\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2780 - val_loss: 7.3424\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2720 - val_loss: 7.3364\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2658 - val_loss: 7.3308\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2596 - val_loss: 7.3249\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2534 - val_loss: 7.3199\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2480 - val_loss: 7.3147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.2426 - val_loss: 7.3094\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2368 - val_loss: 7.3043\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2313 - val_loss: 7.2990\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2255 - val_loss: 7.2942\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2200 - val_loss: 7.2891\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2147 - val_loss: 7.2845\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2098 - val_loss: 7.2799\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2047 - val_loss: 7.2754\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1999 - val_loss: 7.2709\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1951 - val_loss: 7.2658\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1901 - val_loss: 7.2616\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1858 - val_loss: 7.2573\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1816 - val_loss: 7.2531\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1773 - val_loss: 7.2487\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1728 - val_loss: 7.2441\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1683 - val_loss: 7.2401\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1643 - val_loss: 7.2364\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1601 - val_loss: 7.2322\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 100us/sample - loss: 7.1559 - val_loss: 7.2280\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1516 - val_loss: 7.2239\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1475 - val_loss: 7.2200\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1435 - val_loss: 7.2161\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1396 - val_loss: 7.2119\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1357 - val_loss: 7.2077\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.1315 - val_loss: 7.2039\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1279 - val_loss: 7.1999\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1243 - val_loss: 7.1956\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1203 - val_loss: 7.1919\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1168 - val_loss: 7.1878\n",
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1130 - val_loss: 7.1840\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.1094 - val_loss: 7.1799\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1058 - val_loss: 7.1761\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.1023 - val_loss: 7.1725\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.0991 - val_loss: 7.1686\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.0953 - val_loss: 7.1650\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.0921 - val_loss: 7.1619\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.0890 - val_loss: 7.1584\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.0856 - val_loss: 7.1553\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.0825 - val_loss: 7.1519\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.0791 - val_loss: 7.1485\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.0760 - val_loss: 7.1451\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.0725 - val_loss: 7.1419\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0694 - val_loss: 7.1389\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.0663 - val_loss: 7.1359\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.0635 - val_loss: 7.1329\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.0606 - val_loss: 7.1297\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.0576 - val_loss: 7.1267\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.0546 - val_loss: 7.1236\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.0516 - val_loss: 7.1204\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.0486 - val_loss: 7.1175\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.0458 - val_loss: 7.1144\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0429 - val_loss: 7.1117\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.0403 - val_loss: 7.1090\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.0377 - val_loss: 7.1066\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.0353 - val_loss: 7.1038\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.0324 - val_loss: 7.1014\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.0301 - val_loss: 7.0989\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.0275 - val_loss: 7.0965\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.0249 - val_loss: 7.0942\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.0224 - val_loss: 7.0920\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.0199 - val_loss: 7.0900\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.0175 - val_loss: 7.0878\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.0149 - val_loss: 7.0855\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.0123 - val_loss: 7.0833\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.0098 - val_loss: 7.0810\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.0074 - val_loss: 7.0790\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.0051 - val_loss: 7.0771\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.0031 - val_loss: 7.0753\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.0009 - val_loss: 7.0733\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9987 - val_loss: 7.0712\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9965 - val_loss: 7.0692\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9942 - val_loss: 7.0679\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9925 - val_loss: 7.0658\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9902 - val_loss: 7.0641\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9883 - val_loss: 7.0624\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.9865 - val_loss: 7.0608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.9846 - val_loss: 7.0593\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9829 - val_loss: 7.0578\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.9812 - val_loss: 7.0562\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9793 - val_loss: 7.0546\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9777 - val_loss: 7.0530\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9759 - val_loss: 7.0515\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9741 - val_loss: 7.0498\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.9725 - val_loss: 7.0484\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.9709 - val_loss: 7.0470\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 6.9695 - val_loss: 7.0456\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9678 - val_loss: 7.0442\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9663 - val_loss: 7.0429\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.9647 - val_loss: 7.0417\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 6.9633 - val_loss: 7.0406\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9619 - val_loss: 7.0392\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9605 - val_loss: 7.0379\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9589 - val_loss: 7.0366\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9574 - val_loss: 7.0355\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.9560 - val_loss: 7.0344\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.9547 - val_loss: 7.0329\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9530 - val_loss: 7.0318\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9519 - val_loss: 7.0308\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 6.9505 - val_loss: 7.0297\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 96us/sample - loss: 6.9491 - val_loss: 7.0285\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 6.9476 - val_loss: 7.0275\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9463 - val_loss: 7.0266\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9453 - val_loss: 7.0254\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 85us/sample - loss: 6.9440 - val_loss: 7.0243\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9428 - val_loss: 7.0234\n",
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 6.9415 - val_loss: 7.0225\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 6.9402 - val_loss: 7.0215\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9389 - val_loss: 7.0204\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9376 - val_loss: 7.0193\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.9364 - val_loss: 7.0183\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.9353 - val_loss: 7.0173\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9340 - val_loss: 7.0162\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.9328 - val_loss: 7.0150\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.9316 - val_loss: 7.0138\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9304 - val_loss: 7.0127\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9293 - val_loss: 7.0121\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.9281 - val_loss: 7.0112\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.9270 - val_loss: 7.0104\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.9258 - val_loss: 7.0096\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9246 - val_loss: 7.0090\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9236 - val_loss: 7.0081\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9225 - val_loss: 7.0077\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9218 - val_loss: 7.0067\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.9207 - val_loss: 7.0061\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.9197 - val_loss: 7.0054\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9187 - val_loss: 7.0048\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9178 - val_loss: 7.0041\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.9168 - val_loss: 7.0033\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.9159 - val_loss: 7.0027\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9152 - val_loss: 7.0021\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9141 - val_loss: 7.0015\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.9132 - val_loss: 7.0009\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.9124 - val_loss: 7.0003\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9117 - val_loss: 6.9998\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.9110 - val_loss: 6.9992\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9104 - val_loss: 6.9986\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9094 - val_loss: 6.9981\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.9085 - val_loss: 6.9976\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9079 - val_loss: 6.9968\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9071 - val_loss: 6.9962\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.9063 - val_loss: 6.9953\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9055 - val_loss: 6.9943\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.9046 - val_loss: 6.9940\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.9042 - val_loss: 6.9934\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9034 - val_loss: 6.9926\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.9027 - val_loss: 6.9922\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.9021 - val_loss: 6.9917\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.9016 - val_loss: 6.9911\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.9010 - val_loss: 6.9907\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.9004 - val_loss: 6.9902\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8996 - val_loss: 6.9895\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8990 - val_loss: 6.9891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8983 - val_loss: 6.9887\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8978 - val_loss: 6.9881\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8971 - val_loss: 6.9875\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8963 - val_loss: 6.9870\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8958 - val_loss: 6.9869\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.8954 - val_loss: 6.9865\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8947 - val_loss: 6.9859\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8940 - val_loss: 6.9852\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8931 - val_loss: 6.9845\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8925 - val_loss: 6.9842\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8918 - val_loss: 6.9837\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8913 - val_loss: 6.9834\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.8906 - val_loss: 6.9829\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8900 - val_loss: 6.9823\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8893 - val_loss: 6.9817\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8887 - val_loss: 6.9812\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8882 - val_loss: 6.9810\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8876 - val_loss: 6.9805\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8870 - val_loss: 6.9804\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8866 - val_loss: 6.9799\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8860 - val_loss: 6.9796\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8852 - val_loss: 6.9793\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8847 - val_loss: 6.9791\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.8843 - val_loss: 6.9789\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8836 - val_loss: 6.9784\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.8829 - val_loss: 6.9779\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8821 - val_loss: 6.9778\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8817 - val_loss: 6.9772\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8810 - val_loss: 6.9772\n",
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8802 - val_loss: 6.9769\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.8797 - val_loss: 6.9766\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8792 - val_loss: 6.9762\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8788 - val_loss: 6.9757\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8781 - val_loss: 6.9757\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8775 - val_loss: 6.9751\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8770 - val_loss: 6.9747\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8764 - val_loss: 6.9746\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 6.8761 - val_loss: 6.9743\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8754 - val_loss: 6.9741\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8748 - val_loss: 6.9737\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.8741 - val_loss: 6.9732\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8736 - val_loss: 6.9731\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8731 - val_loss: 6.9730\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8727 - val_loss: 6.9728\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8721 - val_loss: 6.9725\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8716 - val_loss: 6.9719\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8712 - val_loss: 6.9716\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 6.8706 - val_loss: 6.9713\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8700 - val_loss: 6.9715\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8694 - val_loss: 6.9712\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8688 - val_loss: 6.9708\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8683 - val_loss: 6.9706\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 6.8678 - val_loss: 6.9704\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8671 - val_loss: 6.9704\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8666 - val_loss: 6.9701\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8662 - val_loss: 6.9702\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8659 - val_loss: 6.9699\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8654 - val_loss: 6.9700\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8650 - val_loss: 6.9701\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 6.8646 - val_loss: 6.9696\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.8642 - val_loss: 6.9692\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8640 - val_loss: 6.9691\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8635 - val_loss: 6.9689\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8630 - val_loss: 6.9684\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.8624 - val_loss: 6.9683\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8620 - val_loss: 6.9683\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8616 - val_loss: 6.9683\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8612 - val_loss: 6.9679\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8608 - val_loss: 6.9676\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8609 - val_loss: 6.9672\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8603 - val_loss: 6.9671\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8598 - val_loss: 6.9670\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8596 - val_loss: 6.9667\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 6.8593 - val_loss: 6.9666\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8589 - val_loss: 6.9667\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8586 - val_loss: 6.9666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8582 - val_loss: 6.9662\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 6.8579 - val_loss: 6.9660\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8576 - val_loss: 6.9656\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.8574 - val_loss: 6.9655\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 6.8571 - val_loss: 6.9653\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 6.8569 - val_loss: 6.9651\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8565 - val_loss: 6.9650\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8562 - val_loss: 6.9647\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8559 - val_loss: 6.9645\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8557 - val_loss: 6.9647\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8555 - val_loss: 6.9645\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 6.8552 - val_loss: 6.9644\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8549 - val_loss: 6.9644\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8548 - val_loss: 6.9642\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8546 - val_loss: 6.9641\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8543 - val_loss: 6.9640\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8541 - val_loss: 6.9640\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8540 - val_loss: 6.9638\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8538 - val_loss: 6.9639\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8536 - val_loss: 6.9637\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8535 - val_loss: 6.9634\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8533 - val_loss: 6.9633\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8529 - val_loss: 6.9633\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8528 - val_loss: 6.9629\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8525 - val_loss: 6.9629\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8524 - val_loss: 6.9631\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8522 - val_loss: 6.9631\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8520 - val_loss: 6.9630\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 6.8519 - val_loss: 6.9630\n",
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 6.8517 - val_loss: 6.9630\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 6.8515 - val_loss: 6.9628\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 55us/sample - loss: 6.8514 - val_loss: 6.9627\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.8512 - val_loss: 6.9626\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8511 - val_loss: 6.9625\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 6.8508 - val_loss: 6.9626\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8507 - val_loss: 6.9627\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 6.8505 - val_loss: 6.9624\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8504 - val_loss: 6.9624\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8506 - val_loss: 6.9620\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8504 - val_loss: 6.9616\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8504 - val_loss: 6.9616\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8501 - val_loss: 6.9615\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8499 - val_loss: 6.9617\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 6.8496 - val_loss: 6.9616\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 6.8495 - val_loss: 6.9616\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8493 - val_loss: 6.9616\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.8493 - val_loss: 6.9618\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 6.8491 - val_loss: 6.9620\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 6.8490 - val_loss: 6.9620\n",
      "Epoch 497/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 6.8489 - val_loss: 6.9621\n",
      "Epoch 498/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 6.8487 - val_loss: 6.9621\n",
      "Epoch 499/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 6.8486 - val_loss: 6.9623\n",
      "594/594 [==============================] - 0s 38us/sample - loss: 7.5471\n",
      "[CV]  learning_rate=0.0021928619507738728, n_hidden=0, n_neurons=475, total=  43.5s\n",
      "[CV] learning_rate=0.0021928619507738728, n_hidden=0, n_neurons=475 ..\n",
      "Train on 1188 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1188/1188 [==============================] - 0s 285us/sample - loss: 13.9425 - val_loss: 13.8112\n",
      "Epoch 2/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.8709 - val_loss: 13.7378\n",
      "Epoch 3/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.7991 - val_loss: 13.6653\n",
      "Epoch 4/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.7284 - val_loss: 13.5935\n",
      "Epoch 5/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.6581 - val_loss: 13.5226\n",
      "Epoch 6/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.5882 - val_loss: 13.4511\n",
      "Epoch 7/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 13.5188 - val_loss: 13.3805\n",
      "Epoch 8/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 13.4502 - val_loss: 13.3108\n",
      "Epoch 9/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 13.3828 - val_loss: 13.2421\n",
      "Epoch 10/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 13.3161 - val_loss: 13.1743\n",
      "Epoch 11/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.2506 - val_loss: 13.1053\n",
      "Epoch 12/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 13.1846 - val_loss: 13.0372\n",
      "Epoch 13/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 13.1194 - val_loss: 12.9701\n",
      "Epoch 14/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 13.0550 - val_loss: 12.9027\n",
      "Epoch 15/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.9907 - val_loss: 12.8372\n",
      "Epoch 16/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 12.9284 - val_loss: 12.7727\n",
      "Epoch 17/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 12.8662 - val_loss: 12.7087\n",
      "Epoch 18/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.8040 - val_loss: 12.6455\n",
      "Epoch 19/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.7423 - val_loss: 12.5826\n",
      "Epoch 20/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.6814 - val_loss: 12.5196\n",
      "Epoch 21/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 12.6205 - val_loss: 12.4570\n",
      "Epoch 22/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.5599 - val_loss: 12.3957\n",
      "Epoch 23/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 12.5003 - val_loss: 12.3343\n",
      "Epoch 24/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.4411 - val_loss: 12.2765\n",
      "Epoch 25/500\n",
      "1188/1188 [==============================] - ETA: 0s - loss: 12.37 - 0s 69us/sample - loss: 12.3850 - val_loss: 12.2169\n",
      "Epoch 26/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 12.3270 - val_loss: 12.1582\n",
      "Epoch 27/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 12.2698 - val_loss: 12.1005\n",
      "Epoch 28/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 12.2139 - val_loss: 12.0438\n",
      "Epoch 29/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 12.1593 - val_loss: 11.9887\n",
      "Epoch 30/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.1051 - val_loss: 11.9323\n",
      "Epoch 31/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 12.0503 - val_loss: 11.8792\n",
      "Epoch 32/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.9983 - val_loss: 11.8249\n",
      "Epoch 33/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.9445 - val_loss: 11.7706\n",
      "Epoch 34/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 11.8911 - val_loss: 11.7181\n",
      "Epoch 35/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.8394 - val_loss: 11.6653\n",
      "Epoch 36/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.7874 - val_loss: 11.6134\n",
      "Epoch 37/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.7361 - val_loss: 11.5624\n",
      "Epoch 38/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.6857 - val_loss: 11.5114\n",
      "Epoch 39/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.6351 - val_loss: 11.4606\n",
      "Epoch 40/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.5849 - val_loss: 11.4107\n",
      "Epoch 41/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.5357 - val_loss: 11.3604\n",
      "Epoch 42/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 11.4864 - val_loss: 11.3111\n",
      "Epoch 43/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 11.4382 - val_loss: 11.2627\n",
      "Epoch 44/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 11.3906 - val_loss: 11.2141\n",
      "Epoch 45/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.3425 - val_loss: 11.1655\n",
      "Epoch 46/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 11.2951 - val_loss: 11.1191\n",
      "Epoch 47/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.2498 - val_loss: 11.0720\n",
      "Epoch 48/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 11.2033 - val_loss: 11.0251\n",
      "Epoch 49/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 11.1580 - val_loss: 10.9804\n",
      "Epoch 50/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 11.1144 - val_loss: 10.9351\n",
      "Epoch 51/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.0704 - val_loss: 10.8916\n",
      "Epoch 52/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 11.0277 - val_loss: 10.8471\n",
      "Epoch 53/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.9841 - val_loss: 10.8027\n",
      "Epoch 54/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.9407 - val_loss: 10.7597\n",
      "Epoch 55/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.8986 - val_loss: 10.7172\n",
      "Epoch 56/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.8567 - val_loss: 10.6742\n",
      "Epoch 57/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.8145 - val_loss: 10.6314\n",
      "Epoch 58/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.7724 - val_loss: 10.5888\n",
      "Epoch 59/500\n",
      "1188/1188 [==============================] - 0s 84us/sample - loss: 10.7306 - val_loss: 10.5474\n",
      "Epoch 60/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.6899 - val_loss: 10.5061\n",
      "Epoch 61/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.6495 - val_loss: 10.4655\n",
      "Epoch 62/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.6100 - val_loss: 10.4272\n",
      "Epoch 63/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.5722 - val_loss: 10.3878\n",
      "Epoch 64/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 10.5337 - val_loss: 10.3488\n",
      "Epoch 65/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.4957 - val_loss: 10.3103\n",
      "Epoch 66/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 10.4582 - val_loss: 10.2721\n",
      "Epoch 67/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 10.4211 - val_loss: 10.2338\n",
      "Epoch 68/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.3838 - val_loss: 10.1965\n",
      "Epoch 69/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 10.3469 - val_loss: 10.1602\n",
      "Epoch 70/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.3117 - val_loss: 10.1236\n",
      "Epoch 71/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 10.2765 - val_loss: 10.0882\n",
      "Epoch 72/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 10.2425 - val_loss: 10.0515\n",
      "Epoch 73/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 10.2076 - val_loss: 10.0164\n",
      "Epoch 74/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.1738 - val_loss: 9.9819\n",
      "Epoch 75/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.1408 - val_loss: 9.9468\n",
      "Epoch 76/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 10.1066 - val_loss: 9.9130\n",
      "Epoch 77/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 10.0739 - val_loss: 9.8798\n",
      "Epoch 78/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 10.0417 - val_loss: 9.8467\n",
      "Epoch 79/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 10.0093 - val_loss: 9.8134\n",
      "Epoch 80/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.9770 - val_loss: 9.7815\n",
      "Epoch 81/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.9463 - val_loss: 9.7492\n",
      "Epoch 82/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.9147 - val_loss: 9.7187\n",
      "Epoch 83/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 9.8851 - val_loss: 9.6866\n",
      "Epoch 84/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.8539 - val_loss: 9.6551\n",
      "Epoch 85/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 9.8233 - val_loss: 9.6235\n",
      "Epoch 86/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.7923 - val_loss: 9.5926\n",
      "Epoch 87/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.7620 - val_loss: 9.5619\n",
      "Epoch 88/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.7318 - val_loss: 9.5315\n",
      "Epoch 89/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 9.7020 - val_loss: 9.5008\n",
      "Epoch 90/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.6716 - val_loss: 9.4706\n",
      "Epoch 91/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.6422 - val_loss: 9.4395\n",
      "Epoch 92/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 9.6122 - val_loss: 9.4102\n",
      "Epoch 93/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.5834 - val_loss: 9.3809\n",
      "Epoch 94/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 9.5546 - val_loss: 9.3517\n",
      "Epoch 95/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.5257 - val_loss: 9.3234\n",
      "Epoch 96/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.4975 - val_loss: 9.2957\n",
      "Epoch 97/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.4700 - val_loss: 9.2669\n",
      "Epoch 98/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 9.4416 - val_loss: 9.2387\n",
      "Epoch 99/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.4140 - val_loss: 9.2106\n",
      "Epoch 100/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 9.3865 - val_loss: 9.1833\n",
      "Epoch 101/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.3599 - val_loss: 9.1555\n",
      "Epoch 102/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 9.3328 - val_loss: 9.1278\n",
      "Epoch 103/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 9.3058 - val_loss: 9.1005\n",
      "Epoch 104/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.2791 - val_loss: 9.0745\n",
      "Epoch 105/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.2540 - val_loss: 9.0477\n",
      "Epoch 106/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.2280 - val_loss: 9.0221\n",
      "Epoch 107/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.2031 - val_loss: 8.9961\n",
      "Epoch 108/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.1776 - val_loss: 8.9704\n",
      "Epoch 109/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.1521 - val_loss: 8.9458\n",
      "Epoch 110/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 9.1279 - val_loss: 8.9210\n",
      "Epoch 111/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 9.1037 - val_loss: 8.8961\n",
      "Epoch 112/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 9.0794 - val_loss: 8.8718\n",
      "Epoch 113/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 9.0554 - val_loss: 8.8475\n",
      "Epoch 114/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 9.0313 - val_loss: 8.8243\n",
      "Epoch 115/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 9.0084 - val_loss: 8.8012\n",
      "Epoch 116/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.9852 - val_loss: 8.7785\n",
      "Epoch 117/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.9621 - val_loss: 8.7558\n",
      "Epoch 118/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.9393 - val_loss: 8.7347\n",
      "Epoch 119/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.9180 - val_loss: 8.7131\n",
      "Epoch 120/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.8960 - val_loss: 8.6907\n",
      "Epoch 121/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8738 - val_loss: 8.6689\n",
      "Epoch 122/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.8523 - val_loss: 8.6477\n",
      "Epoch 123/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.8312 - val_loss: 8.6258\n",
      "Epoch 124/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.8095 - val_loss: 8.6050\n",
      "Epoch 125/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7885 - val_loss: 8.5839\n",
      "Epoch 126/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.7675 - val_loss: 8.5629\n",
      "Epoch 127/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.7467 - val_loss: 8.5432\n",
      "Epoch 128/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.7273 - val_loss: 8.5227\n",
      "Epoch 129/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.7072 - val_loss: 8.5022\n",
      "Epoch 130/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 8.6871 - val_loss: 8.4828\n",
      "Epoch 131/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.6680 - val_loss: 8.4637\n",
      "Epoch 132/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.6494 - val_loss: 8.4440\n",
      "Epoch 133/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.6302 - val_loss: 8.4243\n",
      "Epoch 134/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.6111 - val_loss: 8.4053\n",
      "Epoch 135/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.5925 - val_loss: 8.3859\n",
      "Epoch 136/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 8.5737 - val_loss: 8.3677\n",
      "Epoch 137/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.5556 - val_loss: 8.3501\n",
      "Epoch 138/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 8.5382 - val_loss: 8.3315\n",
      "Epoch 139/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.5198 - val_loss: 8.3142\n",
      "Epoch 140/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.5030 - val_loss: 8.2967\n",
      "Epoch 141/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.4856 - val_loss: 8.2793\n",
      "Epoch 142/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 8.4683 - val_loss: 8.2625\n",
      "Epoch 143/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.4517 - val_loss: 8.2455\n",
      "Epoch 144/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.4347 - val_loss: 8.2297\n",
      "Epoch 145/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.4187 - val_loss: 8.2134\n",
      "Epoch 146/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.4022 - val_loss: 8.1983\n",
      "Epoch 147/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.3867 - val_loss: 8.1826\n",
      "Epoch 148/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 8.3704 - val_loss: 8.1678\n",
      "Epoch 149/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.3552 - val_loss: 8.1538\n",
      "Epoch 150/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.3406 - val_loss: 8.1389\n",
      "Epoch 151/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.3254 - val_loss: 8.1249\n",
      "Epoch 152/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.3108 - val_loss: 8.1106\n",
      "Epoch 153/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.2958 - val_loss: 8.0962\n",
      "Epoch 154/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.2808 - val_loss: 8.0824\n",
      "Epoch 155/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 8.2662 - val_loss: 8.0675\n",
      "Epoch 156/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 8.2506 - val_loss: 8.0531\n",
      "Epoch 157/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.2355 - val_loss: 8.0388\n",
      "Epoch 158/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.2205 - val_loss: 8.0249\n",
      "Epoch 159/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.2064 - val_loss: 8.0104\n",
      "Epoch 160/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.1915 - val_loss: 7.9970\n",
      "Epoch 161/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.1776 - val_loss: 7.9838\n",
      "Epoch 162/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 8.1640 - val_loss: 7.9699\n",
      "Epoch 163/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 8.1501 - val_loss: 7.9564\n",
      "Epoch 164/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 8.1365 - val_loss: 7.9425\n",
      "Epoch 165/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1225 - val_loss: 7.9299\n",
      "Epoch 166/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.1100 - val_loss: 7.9169\n",
      "Epoch 167/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.0973 - val_loss: 7.9043\n",
      "Epoch 168/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 8.0849 - val_loss: 7.8919\n",
      "Epoch 169/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 8.0727 - val_loss: 7.8792\n",
      "Epoch 170/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0605 - val_loss: 7.8663\n",
      "Epoch 171/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.0480 - val_loss: 7.8540\n",
      "Epoch 172/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0363 - val_loss: 7.8418\n",
      "Epoch 173/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188/1188 [==============================] - 0s 73us/sample - loss: 8.0245 - val_loss: 7.8304\n",
      "Epoch 174/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 8.0136 - val_loss: 7.8188\n",
      "Epoch 175/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 8.0026 - val_loss: 7.8074\n",
      "Epoch 176/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.9915 - val_loss: 7.7966\n",
      "Epoch 177/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.9808 - val_loss: 7.7853\n",
      "Epoch 178/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9698 - val_loss: 7.7740\n",
      "Epoch 179/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.9586 - val_loss: 7.7631\n",
      "Epoch 180/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.9481 - val_loss: 7.7522\n",
      "Epoch 181/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.9373 - val_loss: 7.7417\n",
      "Epoch 182/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.9269 - val_loss: 7.7307\n",
      "Epoch 183/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.9162 - val_loss: 7.7198\n",
      "Epoch 184/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.9058 - val_loss: 7.7086\n",
      "Epoch 185/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.8949 - val_loss: 7.6990\n",
      "Epoch 186/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.8853 - val_loss: 7.6888\n",
      "Epoch 187/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.8752 - val_loss: 7.6788\n",
      "Epoch 188/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8654 - val_loss: 7.6689\n",
      "Epoch 189/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.8556 - val_loss: 7.6598\n",
      "Epoch 190/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.8465 - val_loss: 7.6508\n",
      "Epoch 191/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.8374 - val_loss: 7.6417\n",
      "Epoch 192/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.8285 - val_loss: 7.6326\n",
      "Epoch 193/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.8194 - val_loss: 7.6235\n",
      "Epoch 194/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.8102 - val_loss: 7.6151\n",
      "Epoch 195/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.8019 - val_loss: 7.6060\n",
      "Epoch 196/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7931 - val_loss: 7.5975\n",
      "Epoch 197/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.7850 - val_loss: 7.5884\n",
      "Epoch 198/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.7765 - val_loss: 7.5789\n",
      "Epoch 199/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.7680 - val_loss: 7.5705\n",
      "Epoch 200/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.7601 - val_loss: 7.5613\n",
      "Epoch 201/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.7518 - val_loss: 7.5528\n",
      "Epoch 202/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.7438 - val_loss: 7.5443\n",
      "Epoch 203/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.7362 - val_loss: 7.5369\n",
      "Epoch 204/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.7293 - val_loss: 7.5292\n",
      "Epoch 205/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.7223 - val_loss: 7.5213\n",
      "Epoch 206/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.7154 - val_loss: 7.5134\n",
      "Epoch 207/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.7083 - val_loss: 7.5054\n",
      "Epoch 208/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.7013 - val_loss: 7.4978\n",
      "Epoch 209/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.6945 - val_loss: 7.4904\n",
      "Epoch 210/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.6880 - val_loss: 7.4825\n",
      "Epoch 211/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6807 - val_loss: 7.4750\n",
      "Epoch 212/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.6740 - val_loss: 7.4682\n",
      "Epoch 213/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.6682 - val_loss: 7.4610\n",
      "Epoch 214/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.6619 - val_loss: 7.4539\n",
      "Epoch 215/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.6559 - val_loss: 7.4472\n",
      "Epoch 216/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.6500 - val_loss: 7.4398\n",
      "Epoch 217/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.6437 - val_loss: 7.4330\n",
      "Epoch 218/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6381 - val_loss: 7.4265\n",
      "Epoch 219/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.6327 - val_loss: 7.4201\n",
      "Epoch 220/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.6273 - val_loss: 7.4134\n",
      "Epoch 221/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6215 - val_loss: 7.4067\n",
      "Epoch 222/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.6157 - val_loss: 7.4002\n",
      "Epoch 223/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.6102 - val_loss: 7.3937\n",
      "Epoch 224/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.6047 - val_loss: 7.3870\n",
      "Epoch 225/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5991 - val_loss: 7.3816\n",
      "Epoch 226/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5943 - val_loss: 7.3756\n",
      "Epoch 227/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.5893 - val_loss: 7.3698\n",
      "Epoch 228/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.5843 - val_loss: 7.3642\n",
      "Epoch 229/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.5793 - val_loss: 7.3579\n",
      "Epoch 230/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.5738 - val_loss: 7.3522\n",
      "Epoch 231/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5688 - val_loss: 7.3467\n",
      "Epoch 232/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5640 - val_loss: 7.3410\n",
      "Epoch 233/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.5594 - val_loss: 7.3355\n",
      "Epoch 234/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.5547 - val_loss: 7.3299\n",
      "Epoch 235/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.5500 - val_loss: 7.3243\n",
      "Epoch 236/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5450 - val_loss: 7.3192\n",
      "Epoch 237/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5405 - val_loss: 7.3141\n",
      "Epoch 238/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.5360 - val_loss: 7.3092\n",
      "Epoch 239/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.5314 - val_loss: 7.3039\n",
      "Epoch 240/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.5268 - val_loss: 7.2994\n",
      "Epoch 241/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.5224 - val_loss: 7.2947\n",
      "Epoch 242/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5179 - val_loss: 7.2898\n",
      "Epoch 243/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.5133 - val_loss: 7.2850\n",
      "Epoch 244/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.5089 - val_loss: 7.2802\n",
      "Epoch 245/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.5045 - val_loss: 7.2758\n",
      "Epoch 246/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.5000 - val_loss: 7.2709\n",
      "Epoch 247/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.4955 - val_loss: 7.2664\n",
      "Epoch 248/500\n",
      "1188/1188 [==============================] - 0s 89us/sample - loss: 7.4912 - val_loss: 7.2620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4866 - val_loss: 7.2574\n",
      "Epoch 250/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.4824 - val_loss: 7.2529\n",
      "Epoch 251/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4780 - val_loss: 7.2484\n",
      "Epoch 252/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.4737 - val_loss: 7.2445\n",
      "Epoch 253/500\n",
      "1188/1188 [==============================] - 0s 88us/sample - loss: 7.4701 - val_loss: 7.2401\n",
      "Epoch 254/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.4661 - val_loss: 7.2361\n",
      "Epoch 255/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4621 - val_loss: 7.2320\n",
      "Epoch 256/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.4581 - val_loss: 7.2281\n",
      "Epoch 257/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4545 - val_loss: 7.2246\n",
      "Epoch 258/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4510 - val_loss: 7.2207\n",
      "Epoch 259/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.4473 - val_loss: 7.2168\n",
      "Epoch 260/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.4436 - val_loss: 7.2128\n",
      "Epoch 261/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4397 - val_loss: 7.2092\n",
      "Epoch 262/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.4365 - val_loss: 7.2055\n",
      "Epoch 263/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.4330 - val_loss: 7.2019\n",
      "Epoch 264/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.4296 - val_loss: 7.1982\n",
      "Epoch 265/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.4264 - val_loss: 7.1949\n",
      "Epoch 266/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.4233 - val_loss: 7.1912\n",
      "Epoch 267/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.4199 - val_loss: 7.1876\n",
      "Epoch 268/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.4166 - val_loss: 7.1843\n",
      "Epoch 269/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.4135 - val_loss: 7.1811\n",
      "Epoch 270/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4104 - val_loss: 7.1780\n",
      "Epoch 271/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.4074 - val_loss: 7.1745\n",
      "Epoch 272/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.4040 - val_loss: 7.1716\n",
      "Epoch 273/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.4011 - val_loss: 7.1683\n",
      "Epoch 274/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3980 - val_loss: 7.1650\n",
      "Epoch 275/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.3945 - val_loss: 7.1621\n",
      "Epoch 276/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3917 - val_loss: 7.1588\n",
      "Epoch 277/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.3886 - val_loss: 7.1553\n",
      "Epoch 278/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3853 - val_loss: 7.1518\n",
      "Epoch 279/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3821 - val_loss: 7.1488\n",
      "Epoch 280/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3790 - val_loss: 7.1457\n",
      "Epoch 281/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3763 - val_loss: 7.1429\n",
      "Epoch 282/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3731 - val_loss: 7.1398\n",
      "Epoch 283/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.3701 - val_loss: 7.1370\n",
      "Epoch 284/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.3674 - val_loss: 7.1342\n",
      "Epoch 285/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3645 - val_loss: 7.1315\n",
      "Epoch 286/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3617 - val_loss: 7.1287\n",
      "Epoch 287/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3591 - val_loss: 7.1261\n",
      "Epoch 288/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3564 - val_loss: 7.1235\n",
      "Epoch 289/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3539 - val_loss: 7.1209\n",
      "Epoch 290/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.3514 - val_loss: 7.1182\n",
      "Epoch 291/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3486 - val_loss: 7.1160\n",
      "Epoch 292/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3466 - val_loss: 7.1136\n",
      "Epoch 293/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3442 - val_loss: 7.1109\n",
      "Epoch 294/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3416 - val_loss: 7.1081\n",
      "Epoch 295/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3392 - val_loss: 7.1055\n",
      "Epoch 296/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3369 - val_loss: 7.1031\n",
      "Epoch 297/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3349 - val_loss: 7.1008\n",
      "Epoch 298/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.3328 - val_loss: 7.0984\n",
      "Epoch 299/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3307 - val_loss: 7.0958\n",
      "Epoch 300/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.3285 - val_loss: 7.0936\n",
      "Epoch 301/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.3264 - val_loss: 7.0912\n",
      "Epoch 302/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3243 - val_loss: 7.0887\n",
      "Epoch 303/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.3221 - val_loss: 7.0865\n",
      "Epoch 304/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.3204 - val_loss: 7.0846\n",
      "Epoch 305/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3189 - val_loss: 7.0822\n",
      "Epoch 306/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3166 - val_loss: 7.0800\n",
      "Epoch 307/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3148 - val_loss: 7.0779\n",
      "Epoch 308/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3129 - val_loss: 7.0759\n",
      "Epoch 309/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3113 - val_loss: 7.0738\n",
      "Epoch 310/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3096 - val_loss: 7.0717\n",
      "Epoch 311/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.3078 - val_loss: 7.0700\n",
      "Epoch 312/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.3064 - val_loss: 7.0680\n",
      "Epoch 313/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3045 - val_loss: 7.0663\n",
      "Epoch 314/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.3030 - val_loss: 7.0643\n",
      "Epoch 315/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.3012 - val_loss: 7.0623\n",
      "Epoch 316/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.2995 - val_loss: 7.0603\n",
      "Epoch 317/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2976 - val_loss: 7.0582\n",
      "Epoch 318/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2959 - val_loss: 7.0565\n",
      "Epoch 319/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2943 - val_loss: 7.0548\n",
      "Epoch 320/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2925 - val_loss: 7.0531\n",
      "Epoch 321/500\n",
      "1188/1188 [==============================] - 0s 56us/sample - loss: 7.2909 - val_loss: 7.0517\n",
      "Epoch 322/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2895 - val_loss: 7.0500\n",
      "Epoch 323/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2881 - val_loss: 7.0483\n",
      "Epoch 324/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2864 - val_loss: 7.0466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 325/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2850 - val_loss: 7.0449\n",
      "Epoch 326/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2833 - val_loss: 7.0432\n",
      "Epoch 327/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2815 - val_loss: 7.0415\n",
      "Epoch 328/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2800 - val_loss: 7.0397\n",
      "Epoch 329/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2785 - val_loss: 7.0380\n",
      "Epoch 330/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2768 - val_loss: 7.0364\n",
      "Epoch 331/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2755 - val_loss: 7.0349\n",
      "Epoch 332/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2741 - val_loss: 7.0332\n",
      "Epoch 333/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2724 - val_loss: 7.0317\n",
      "Epoch 334/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2709 - val_loss: 7.0303\n",
      "Epoch 335/500\n",
      "1188/1188 [==============================] - 1s 1ms/sample - loss: 7.2694 - val_loss: 7.0291\n",
      "Epoch 336/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.2682 - val_loss: 7.0274\n",
      "Epoch 337/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2664 - val_loss: 7.0258\n",
      "Epoch 338/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2649 - val_loss: 7.0243\n",
      "Epoch 339/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2634 - val_loss: 7.0228\n",
      "Epoch 340/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.2620 - val_loss: 7.0215\n",
      "Epoch 341/500\n",
      "1188/1188 [==============================] - 0s 122us/sample - loss: 7.2606 - val_loss: 7.0205\n",
      "Epoch 342/500\n",
      "1188/1188 [==============================] - 0s 110us/sample - loss: 7.2593 - val_loss: 7.0193\n",
      "Epoch 343/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.2582 - val_loss: 7.0181\n",
      "Epoch 344/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.2568 - val_loss: 7.0167\n",
      "Epoch 345/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2554 - val_loss: 7.0155\n",
      "Epoch 346/500\n",
      "1188/1188 [==============================] - 0s 99us/sample - loss: 7.2542 - val_loss: 7.0142\n",
      "Epoch 347/500\n",
      "1188/1188 [==============================] - 0s 109us/sample - loss: 7.2530 - val_loss: 7.0129\n",
      "Epoch 348/500\n",
      "1188/1188 [==============================] - 0s 114us/sample - loss: 7.2516 - val_loss: 7.0118\n",
      "Epoch 349/500\n",
      "1188/1188 [==============================] - 0s 81us/sample - loss: 7.2505 - val_loss: 7.0104\n",
      "Epoch 350/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2494 - val_loss: 7.0090\n",
      "Epoch 351/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2480 - val_loss: 7.0078\n",
      "Epoch 352/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2471 - val_loss: 7.0067\n",
      "Epoch 353/500\n",
      "1188/1188 [==============================] - 0s 80us/sample - loss: 7.2460 - val_loss: 7.0053\n",
      "Epoch 354/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.2446 - val_loss: 7.0044\n",
      "Epoch 355/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2435 - val_loss: 7.0032\n",
      "Epoch 356/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2425 - val_loss: 7.0018\n",
      "Epoch 357/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2412 - val_loss: 7.0011\n",
      "Epoch 358/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2404 - val_loss: 6.9998\n",
      "Epoch 359/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2393 - val_loss: 6.9989\n",
      "Epoch 360/500\n",
      "1188/1188 [==============================] - 0s 60us/sample - loss: 7.2382 - val_loss: 6.9979\n",
      "Epoch 361/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.2371 - val_loss: 6.9967\n",
      "Epoch 362/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.2362 - val_loss: 6.9956\n",
      "Epoch 363/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2350 - val_loss: 6.9944\n",
      "Epoch 364/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2339 - val_loss: 6.9933\n",
      "Epoch 365/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.2327 - val_loss: 6.9924\n",
      "Epoch 366/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2318 - val_loss: 6.9914\n",
      "Epoch 367/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.2309 - val_loss: 6.9903\n",
      "Epoch 368/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.2298 - val_loss: 6.9893\n",
      "Epoch 369/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2288 - val_loss: 6.9885\n",
      "Epoch 370/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.2278 - val_loss: 6.9875\n",
      "Epoch 371/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2268 - val_loss: 6.9867\n",
      "Epoch 372/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2258 - val_loss: 6.9860\n",
      "Epoch 373/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2251 - val_loss: 6.9851\n",
      "Epoch 374/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2240 - val_loss: 6.9844\n",
      "Epoch 375/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2232 - val_loss: 6.9839\n",
      "Epoch 376/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2223 - val_loss: 6.9835\n",
      "Epoch 377/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2217 - val_loss: 6.9827\n",
      "Epoch 378/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2209 - val_loss: 6.9820\n",
      "Epoch 379/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.2201 - val_loss: 6.9814\n",
      "Epoch 380/500\n",
      "1188/1188 [==============================] - 0s 93us/sample - loss: 7.2193 - val_loss: 6.9807\n",
      "Epoch 381/500\n",
      "1188/1188 [==============================] - 0s 78us/sample - loss: 7.2187 - val_loss: 6.9800\n",
      "Epoch 382/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.2180 - val_loss: 6.9792\n",
      "Epoch 383/500\n",
      "1188/1188 [==============================] - 0s 90us/sample - loss: 7.2173 - val_loss: 6.9785\n",
      "Epoch 384/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2166 - val_loss: 6.9778\n",
      "Epoch 385/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2161 - val_loss: 6.9771\n",
      "Epoch 386/500\n",
      "1188/1188 [==============================] - 0s 87us/sample - loss: 7.2155 - val_loss: 6.9763\n",
      "Epoch 387/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.2150 - val_loss: 6.9757\n",
      "Epoch 388/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2143 - val_loss: 6.9752\n",
      "Epoch 389/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.2138 - val_loss: 6.9747\n",
      "Epoch 390/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2133 - val_loss: 6.9744\n",
      "Epoch 391/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.2127 - val_loss: 6.9738\n",
      "Epoch 392/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2124 - val_loss: 6.9733\n",
      "Epoch 393/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2116 - val_loss: 6.9729\n",
      "Epoch 394/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.2111 - val_loss: 6.9722\n",
      "Epoch 395/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2105 - val_loss: 6.9717\n",
      "Epoch 396/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.2100 - val_loss: 6.9711\n",
      "Epoch 397/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2093 - val_loss: 6.9704\n",
      "Epoch 398/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2087 - val_loss: 6.9698\n",
      "Epoch 399/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2082 - val_loss: 6.9694\n",
      "Epoch 400/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2076 - val_loss: 6.9691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 401/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.2069 - val_loss: 6.9685\n",
      "Epoch 402/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.2065 - val_loss: 6.9681\n",
      "Epoch 403/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.2059 - val_loss: 6.9676\n",
      "Epoch 404/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2054 - val_loss: 6.9670\n",
      "Epoch 405/500\n",
      "1188/1188 [==============================] - 0s 77us/sample - loss: 7.2049 - val_loss: 6.9665\n",
      "Epoch 406/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.2042 - val_loss: 6.9656\n",
      "Epoch 407/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2035 - val_loss: 6.9653\n",
      "Epoch 408/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2033 - val_loss: 6.9649\n",
      "Epoch 409/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2026 - val_loss: 6.9643\n",
      "Epoch 410/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.2021 - val_loss: 6.9639\n",
      "Epoch 411/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.2014 - val_loss: 6.9633\n",
      "Epoch 412/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2009 - val_loss: 6.9626\n",
      "Epoch 413/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.2002 - val_loss: 6.9621\n",
      "Epoch 414/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1998 - val_loss: 6.9616\n",
      "Epoch 415/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1993 - val_loss: 6.9610\n",
      "Epoch 416/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1987 - val_loss: 6.9605\n",
      "Epoch 417/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1984 - val_loss: 6.9598\n",
      "Epoch 418/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1978 - val_loss: 6.9593\n",
      "Epoch 419/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1973 - val_loss: 6.9589\n",
      "Epoch 420/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1966 - val_loss: 6.9586\n",
      "Epoch 421/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1961 - val_loss: 6.9582\n",
      "Epoch 422/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1955 - val_loss: 6.9576\n",
      "Epoch 423/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.1948 - val_loss: 6.9572\n",
      "Epoch 424/500\n",
      "1188/1188 [==============================] - 0s 60us/sample - loss: 7.1944 - val_loss: 6.9570\n",
      "Epoch 425/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1937 - val_loss: 6.9565\n",
      "Epoch 426/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1931 - val_loss: 6.9559\n",
      "Epoch 427/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.1926 - val_loss: 6.9557\n",
      "Epoch 428/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1923 - val_loss: 6.9552\n",
      "Epoch 429/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1917 - val_loss: 6.9546\n",
      "Epoch 430/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.1914 - val_loss: 6.9544\n",
      "Epoch 431/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1910 - val_loss: 6.9540\n",
      "Epoch 432/500\n",
      "1188/1188 [==============================] - 0s 60us/sample - loss: 7.1906 - val_loss: 6.9535\n",
      "Epoch 433/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1901 - val_loss: 6.9533\n",
      "Epoch 434/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1897 - val_loss: 6.9530\n",
      "Epoch 435/500\n",
      "1188/1188 [==============================] - 0s 60us/sample - loss: 7.1896 - val_loss: 6.9524\n",
      "Epoch 436/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.1888 - val_loss: 6.9521\n",
      "Epoch 437/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1882 - val_loss: 6.9516\n",
      "Epoch 438/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1876 - val_loss: 6.9513\n",
      "Epoch 439/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.1873 - val_loss: 6.9511\n",
      "Epoch 440/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.1868 - val_loss: 6.9508\n",
      "Epoch 441/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1863 - val_loss: 6.9505\n",
      "Epoch 442/500\n",
      "1188/1188 [==============================] - 0s 62us/sample - loss: 7.1858 - val_loss: 6.9502\n",
      "Epoch 443/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.1854 - val_loss: 6.9502\n",
      "Epoch 444/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1849 - val_loss: 6.9499\n",
      "Epoch 445/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1846 - val_loss: 6.9497\n",
      "Epoch 446/500\n",
      "1188/1188 [==============================] - 0s 61us/sample - loss: 7.1840 - val_loss: 6.9495\n",
      "Epoch 447/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1836 - val_loss: 6.9493\n",
      "Epoch 448/500\n",
      "1188/1188 [==============================] - 0s 66us/sample - loss: 7.1831 - val_loss: 6.9490\n",
      "Epoch 449/500\n",
      "1188/1188 [==============================] - 0s 59us/sample - loss: 7.1828 - val_loss: 6.9487\n",
      "Epoch 450/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1824 - val_loss: 6.9482\n",
      "Epoch 451/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1819 - val_loss: 6.9480\n",
      "Epoch 452/500\n",
      "1188/1188 [==============================] - 0s 76us/sample - loss: 7.1818 - val_loss: 6.9476\n",
      "Epoch 453/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1811 - val_loss: 6.9471\n",
      "Epoch 454/500\n",
      "1188/1188 [==============================] - 0s 57us/sample - loss: 7.1807 - val_loss: 6.9470\n",
      "Epoch 455/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1803 - val_loss: 6.9469\n",
      "Epoch 456/500\n",
      "1188/1188 [==============================] - 0s 69us/sample - loss: 7.1799 - val_loss: 6.9466\n",
      "Epoch 457/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1797 - val_loss: 6.9465\n",
      "Epoch 458/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1793 - val_loss: 6.9463\n",
      "Epoch 459/500\n",
      "1188/1188 [==============================] - 0s 71us/sample - loss: 7.1790 - val_loss: 6.9461\n",
      "Epoch 460/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1786 - val_loss: 6.9463\n",
      "Epoch 461/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1781 - val_loss: 6.9459\n",
      "Epoch 462/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1780 - val_loss: 6.9459\n",
      "Epoch 463/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1776 - val_loss: 6.9458\n",
      "Epoch 464/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1772 - val_loss: 6.9458\n",
      "Epoch 465/500\n",
      "1188/1188 [==============================] - 0s 83us/sample - loss: 7.1769 - val_loss: 6.9455\n",
      "Epoch 466/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1767 - val_loss: 6.9456\n",
      "Epoch 467/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1764 - val_loss: 6.9454\n",
      "Epoch 468/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1762 - val_loss: 6.9453\n",
      "Epoch 469/500\n",
      "1188/1188 [==============================] - 0s 65us/sample - loss: 7.1758 - val_loss: 6.9451\n",
      "Epoch 470/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1754 - val_loss: 6.9449\n",
      "Epoch 471/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1751 - val_loss: 6.9447\n",
      "Epoch 472/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1747 - val_loss: 6.9447\n",
      "Epoch 473/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1745 - val_loss: 6.9447\n",
      "Epoch 474/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1742 - val_loss: 6.9445\n",
      "Epoch 475/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1739 - val_loss: 6.9444\n",
      "Epoch 476/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1737 - val_loss: 6.9444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 477/500\n",
      "1188/1188 [==============================] - 0s 94us/sample - loss: 7.1735 - val_loss: 6.9447\n",
      "Epoch 478/500\n",
      "1188/1188 [==============================] - 0s 91us/sample - loss: 7.1732 - val_loss: 6.9444\n",
      "Epoch 479/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1730 - val_loss: 6.9444\n",
      "Epoch 480/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1728 - val_loss: 6.9443\n",
      "Epoch 481/500\n",
      "1188/1188 [==============================] - 0s 68us/sample - loss: 7.1724 - val_loss: 6.9442\n",
      "Epoch 482/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1721 - val_loss: 6.9441\n",
      "Epoch 483/500\n",
      "1188/1188 [==============================] - 0s 73us/sample - loss: 7.1718 - val_loss: 6.9440\n",
      "Epoch 484/500\n",
      "1188/1188 [==============================] - 0s 74us/sample - loss: 7.1716 - val_loss: 6.9439\n",
      "Epoch 485/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1714 - val_loss: 6.9438\n",
      "Epoch 486/500\n",
      "1188/1188 [==============================] - 0s 63us/sample - loss: 7.1710 - val_loss: 6.9436\n",
      "Epoch 487/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1710 - val_loss: 6.9439\n",
      "Epoch 488/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1708 - val_loss: 6.9439\n",
      "Epoch 489/500\n",
      "1188/1188 [==============================] - 0s 72us/sample - loss: 7.1703 - val_loss: 6.9438\n",
      "Epoch 490/500\n",
      "1188/1188 [==============================] - 0s 64us/sample - loss: 7.1703 - val_loss: 6.9438\n",
      "Epoch 491/500\n",
      "1188/1188 [==============================] - 0s 70us/sample - loss: 7.1704 - val_loss: 6.9440\n",
      "Epoch 492/500\n",
      "1188/1188 [==============================] - 0s 67us/sample - loss: 7.1701 - val_loss: 6.9438\n",
      "Epoch 493/500\n",
      "1188/1188 [==============================] - 0s 82us/sample - loss: 7.1697 - val_loss: 6.9438\n",
      "Epoch 494/500\n",
      "1188/1188 [==============================] - 0s 86us/sample - loss: 7.1695 - val_loss: 6.9439\n",
      "Epoch 495/500\n",
      "1188/1188 [==============================] - 0s 79us/sample - loss: 7.1693 - val_loss: 6.9439\n",
      "Epoch 496/500\n",
      "1188/1188 [==============================] - 0s 75us/sample - loss: 7.1691 - val_loss: 6.9439\n",
      "594/594 [==============================] - 0s 41us/sample - loss: 6.9051\n",
      "[CV]  learning_rate=0.0021928619507738728, n_hidden=0, n_neurons=475, total=  44.6s\n",
      "Train on 1782 samples, validate on 594 samples\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  30 out of  30 | elapsed: 14.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782/1782 [==============================] - 1s 368us/sample - loss: 13.9969 - val_loss: 13.7090\n",
      "Epoch 2/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 13.8872 - val_loss: 13.6012\n",
      "Epoch 3/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 13.7783 - val_loss: 13.4945\n",
      "Epoch 4/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 13.6713 - val_loss: 13.3895\n",
      "Epoch 5/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 13.5655 - val_loss: 13.2859\n",
      "Epoch 6/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 13.4607 - val_loss: 13.1839\n",
      "Epoch 7/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 13.3571 - val_loss: 13.0832\n",
      "Epoch 8/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 13.2548 - val_loss: 12.9839\n",
      "Epoch 9/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 13.1541 - val_loss: 12.8855\n",
      "Epoch 10/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 13.0544 - val_loss: 12.7882\n",
      "Epoch 11/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 12.9560 - val_loss: 12.6915\n",
      "Epoch 12/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 12.8582 - val_loss: 12.5954\n",
      "Epoch 13/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 12.7617 - val_loss: 12.5008\n",
      "Epoch 14/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 12.6670 - val_loss: 12.4078\n",
      "Epoch 15/500\n",
      "1782/1782 [==============================] - 0s 98us/sample - loss: 12.5738 - val_loss: 12.3158\n",
      "Epoch 16/500\n",
      "1782/1782 [==============================] - 0s 107us/sample - loss: 12.4819 - val_loss: 12.2243\n",
      "Epoch 17/500\n",
      "1782/1782 [==============================] - 0s 96us/sample - loss: 12.3911 - val_loss: 12.1348\n",
      "Epoch 18/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 12.3022 - val_loss: 12.0463\n",
      "Epoch 19/500\n",
      "1782/1782 [==============================] - 0s 69us/sample - loss: 12.2147 - val_loss: 11.9588\n",
      "Epoch 20/500\n",
      "1782/1782 [==============================] - 0s 89us/sample - loss: 12.1282 - val_loss: 11.8733\n",
      "Epoch 21/500\n",
      "1782/1782 [==============================] - 0s 78us/sample - loss: 12.0431 - val_loss: 11.7892\n",
      "Epoch 22/500\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 11.9594 - val_loss: 11.7067\n",
      "Epoch 23/500\n",
      "1782/1782 [==============================] - 0s 86us/sample - loss: 11.8774 - val_loss: 11.6251\n",
      "Epoch 24/500\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 11.7971 - val_loss: 11.5450\n",
      "Epoch 25/500\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 11.7185 - val_loss: 11.4662\n",
      "Epoch 26/500\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 11.6401 - val_loss: 11.3880\n",
      "Epoch 27/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 11.5627 - val_loss: 11.3111\n",
      "Epoch 28/500\n",
      "1782/1782 [==============================] - 0s 69us/sample - loss: 11.4864 - val_loss: 11.2351\n",
      "Epoch 29/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 11.4110 - val_loss: 11.1598\n",
      "Epoch 30/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 11.3364 - val_loss: 11.0859\n",
      "Epoch 31/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 11.2627 - val_loss: 11.0141\n",
      "Epoch 32/500\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 11.1898 - val_loss: 10.9426\n",
      "Epoch 33/500\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 11.1181 - val_loss: 10.8726\n",
      "Epoch 34/500\n",
      "1782/1782 [==============================] - 0s 69us/sample - loss: 11.0477 - val_loss: 10.8035\n",
      "Epoch 35/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 10.9785 - val_loss: 10.7361\n",
      "Epoch 36/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 10.9102 - val_loss: 10.6700\n",
      "Epoch 37/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 10.8430 - val_loss: 10.6047\n",
      "Epoch 38/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 10.7762 - val_loss: 10.5408\n",
      "Epoch 39/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 10.7101 - val_loss: 10.4778\n",
      "Epoch 40/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 10.6445 - val_loss: 10.4162\n",
      "Epoch 41/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 10.5799 - val_loss: 10.3551\n",
      "Epoch 42/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 10.5158 - val_loss: 10.2950\n",
      "Epoch 43/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 10.4528 - val_loss: 10.2359\n",
      "Epoch 44/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 10.3905 - val_loss: 10.1776\n",
      "Epoch 45/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 10.3291 - val_loss: 10.1201\n",
      "Epoch 46/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 10.2681 - val_loss: 10.0631\n",
      "Epoch 47/500\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 10.2080 - val_loss: 10.0067\n",
      "Epoch 48/500\n",
      "1782/1782 [==============================] - 0s 130us/sample - loss: 10.1489 - val_loss: 9.9516\n",
      "Epoch 49/500\n",
      "1782/1782 [==============================] - 0s 83us/sample - loss: 10.0910 - val_loss: 9.8972\n",
      "Epoch 50/500\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 10.0335 - val_loss: 9.8433\n",
      "Epoch 51/500\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 9.9764 - val_loss: 9.7902\n",
      "Epoch 52/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 9.9200 - val_loss: 9.7374\n",
      "Epoch 53/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 9.8649 - val_loss: 9.6859\n",
      "Epoch 54/500\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 9.8114 - val_loss: 9.6357\n",
      "Epoch 55/500\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 9.7590 - val_loss: 9.5864\n",
      "Epoch 56/500\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 9.7079 - val_loss: 9.5380\n",
      "Epoch 57/500\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 9.6575 - val_loss: 9.4905\n",
      "Epoch 58/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 9.6080 - val_loss: 9.4438\n",
      "Epoch 59/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 9.5592 - val_loss: 9.3979\n",
      "Epoch 60/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 9.5111 - val_loss: 9.3526\n",
      "Epoch 61/500\n",
      "1782/1782 [==============================] - 0s 69us/sample - loss: 9.4640 - val_loss: 9.3078\n",
      "Epoch 62/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 9.4175 - val_loss: 9.2636\n",
      "Epoch 63/500\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 9.3722 - val_loss: 9.2206\n",
      "Epoch 64/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 9.3282 - val_loss: 9.1785\n",
      "Epoch 65/500\n",
      "1782/1782 [==============================] - 0s 85us/sample - loss: 9.2853 - val_loss: 9.1378\n",
      "Epoch 66/500\n",
      "1782/1782 [==============================] - 0s 135us/sample - loss: 9.2437 - val_loss: 9.0970\n",
      "Epoch 67/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 9.2024 - val_loss: 9.0570\n",
      "Epoch 68/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 9.1620 - val_loss: 9.0177\n",
      "Epoch 69/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 9.1221 - val_loss: 8.9789\n",
      "Epoch 70/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 9.0830 - val_loss: 8.9405\n",
      "Epoch 71/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 9.0444 - val_loss: 8.9025\n",
      "Epoch 72/500\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 9.0063 - val_loss: 8.8650\n",
      "Epoch 73/500\n",
      "1782/1782 [==============================] - 0s 69us/sample - loss: 8.9691 - val_loss: 8.8276\n",
      "Epoch 74/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 8.9320 - val_loss: 8.7907\n",
      "Epoch 75/500\n",
      "1782/1782 [==============================] - 0s 68us/sample - loss: 8.8958 - val_loss: 8.7541\n",
      "Epoch 76/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 8.8598 - val_loss: 8.7180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 8.8246 - val_loss: 8.6828\n",
      "Epoch 78/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 8.7898 - val_loss: 8.6482\n",
      "Epoch 79/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 8.7556 - val_loss: 8.6141\n",
      "Epoch 80/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 8.7221 - val_loss: 8.5806\n",
      "Epoch 81/500\n",
      "1782/1782 [==============================] - 0s 75us/sample - loss: 8.6892 - val_loss: 8.5479\n",
      "Epoch 82/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 8.6571 - val_loss: 8.5161\n",
      "Epoch 83/500\n",
      "1782/1782 [==============================] - 0s 74us/sample - loss: 8.6253 - val_loss: 8.4845\n",
      "Epoch 84/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 8.5936 - val_loss: 8.4538\n",
      "Epoch 85/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 8.5624 - val_loss: 8.4234\n",
      "Epoch 86/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 8.5316 - val_loss: 8.3938\n",
      "Epoch 87/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 8.5016 - val_loss: 8.3652\n",
      "Epoch 88/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 8.4722 - val_loss: 8.3372\n",
      "Epoch 89/500\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 8.4437 - val_loss: 8.3101\n",
      "Epoch 90/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 8.4160 - val_loss: 8.2834\n",
      "Epoch 91/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 8.3888 - val_loss: 8.2574\n",
      "Epoch 92/500\n",
      "1782/1782 [==============================] - 0s 57us/sample - loss: 8.3620 - val_loss: 8.2318\n",
      "Epoch 93/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 8.3359 - val_loss: 8.2071\n",
      "Epoch 94/500\n",
      "1782/1782 [==============================] - 0s 57us/sample - loss: 8.3109 - val_loss: 8.1830\n",
      "Epoch 95/500\n",
      "1782/1782 [==============================] - 0s 55us/sample - loss: 8.2865 - val_loss: 8.1590\n",
      "Epoch 96/500\n",
      "1782/1782 [==============================] - 0s 56us/sample - loss: 8.2624 - val_loss: 8.1354\n",
      "Epoch 97/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 8.2387 - val_loss: 8.1124\n",
      "Epoch 98/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 8.2154 - val_loss: 8.0896\n",
      "Epoch 99/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 8.1922 - val_loss: 8.0673\n",
      "Epoch 100/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 8.1695 - val_loss: 8.0453\n",
      "Epoch 101/500\n",
      "1782/1782 [==============================] - 0s 57us/sample - loss: 8.1470 - val_loss: 8.0238\n",
      "Epoch 102/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 8.1251 - val_loss: 8.0027\n",
      "Epoch 103/500\n",
      "1782/1782 [==============================] - 0s 56us/sample - loss: 8.1037 - val_loss: 7.9817\n",
      "Epoch 104/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 8.0827 - val_loss: 7.9611\n",
      "Epoch 105/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 8.0620 - val_loss: 7.9407\n",
      "Epoch 106/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 8.0418 - val_loss: 7.9210\n",
      "Epoch 107/500\n",
      "1782/1782 [==============================] - 0s 47us/sample - loss: 8.0224 - val_loss: 7.9017\n",
      "Epoch 108/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 8.0034 - val_loss: 7.8833\n",
      "Epoch 109/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.9850 - val_loss: 7.8650\n",
      "Epoch 110/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 7.9669 - val_loss: 7.8469\n",
      "Epoch 111/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.9492 - val_loss: 7.8291\n",
      "Epoch 112/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.9320 - val_loss: 7.8117\n",
      "Epoch 113/500\n",
      "1782/1782 [==============================] - 0s 57us/sample - loss: 7.9152 - val_loss: 7.7946\n",
      "Epoch 114/500\n",
      "1782/1782 [==============================] - 0s 57us/sample - loss: 7.8988 - val_loss: 7.7779\n",
      "Epoch 115/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 7.8826 - val_loss: 7.7616\n",
      "Epoch 116/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.8667 - val_loss: 7.7454\n",
      "Epoch 117/500\n",
      "1782/1782 [==============================] - 0s 56us/sample - loss: 7.8509 - val_loss: 7.7294\n",
      "Epoch 118/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.8353 - val_loss: 7.7135\n",
      "Epoch 119/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.8198 - val_loss: 7.6978\n",
      "Epoch 120/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 7.8045 - val_loss: 7.6824\n",
      "Epoch 121/500\n",
      "1782/1782 [==============================] - 0s 84us/sample - loss: 7.7894 - val_loss: 7.6671\n",
      "Epoch 122/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.7746 - val_loss: 7.6520\n",
      "Epoch 123/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.7600 - val_loss: 7.6373\n",
      "Epoch 124/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 7.7460 - val_loss: 7.6231\n",
      "Epoch 125/500\n",
      "1782/1782 [==============================] - 0s 83us/sample - loss: 7.7323 - val_loss: 7.6091\n",
      "Epoch 126/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 7.7188 - val_loss: 7.5956\n",
      "Epoch 127/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.7058 - val_loss: 7.5822\n",
      "Epoch 128/500\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 7.6931 - val_loss: 7.5693\n",
      "Epoch 129/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.6811 - val_loss: 7.5568\n",
      "Epoch 130/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.6696 - val_loss: 7.5447\n",
      "Epoch 131/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.6582 - val_loss: 7.5327\n",
      "Epoch 132/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.6471 - val_loss: 7.5210\n",
      "Epoch 133/500\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 7.6362 - val_loss: 7.5096\n",
      "Epoch 134/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.6255 - val_loss: 7.4985\n",
      "Epoch 135/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 7.6152 - val_loss: 7.4878\n",
      "Epoch 136/500\n",
      "1782/1782 [==============================] - 0s 57us/sample - loss: 7.6054 - val_loss: 7.4771\n",
      "Epoch 137/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 7.5956 - val_loss: 7.4665\n",
      "Epoch 138/500\n",
      "1782/1782 [==============================] - 0s 57us/sample - loss: 7.5863 - val_loss: 7.4563\n",
      "Epoch 139/500\n",
      "1782/1782 [==============================] - 0s 57us/sample - loss: 7.5772 - val_loss: 7.4461\n",
      "Epoch 140/500\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 7.5682 - val_loss: 7.4359\n",
      "Epoch 141/500\n",
      "1782/1782 [==============================] - 0s 56us/sample - loss: 7.5594 - val_loss: 7.4262\n",
      "Epoch 142/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.5509 - val_loss: 7.4166\n",
      "Epoch 143/500\n",
      "1782/1782 [==============================] - 0s 56us/sample - loss: 7.5425 - val_loss: 7.4071\n",
      "Epoch 144/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.5343 - val_loss: 7.3980\n",
      "Epoch 145/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 7.5262 - val_loss: 7.3888\n",
      "Epoch 146/500\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 7.5182 - val_loss: 7.3801\n",
      "Epoch 147/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 7.5104 - val_loss: 7.3714\n",
      "Epoch 148/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 7.5027 - val_loss: 7.3629\n",
      "Epoch 149/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.4952 - val_loss: 7.3547\n",
      "Epoch 150/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.4877 - val_loss: 7.3467\n",
      "Epoch 151/500\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 7.4805 - val_loss: 7.3386\n",
      "Epoch 152/500\n",
      "1782/1782 [==============================] - 0s 102us/sample - loss: 7.4732 - val_loss: 7.3310\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.4662 - val_loss: 7.3234\n",
      "Epoch 154/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 7.4592 - val_loss: 7.3160\n",
      "Epoch 155/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.4523 - val_loss: 7.3087\n",
      "Epoch 156/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.4455 - val_loss: 7.3014\n",
      "Epoch 157/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 7.4387 - val_loss: 7.2941\n",
      "Epoch 158/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.4319 - val_loss: 7.2870\n",
      "Epoch 159/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.4253 - val_loss: 7.2800\n",
      "Epoch 160/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.4188 - val_loss: 7.2731\n",
      "Epoch 161/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.4123 - val_loss: 7.2662\n",
      "Epoch 162/500\n",
      "1782/1782 [==============================] - 0s 83us/sample - loss: 7.4059 - val_loss: 7.2595\n",
      "Epoch 163/500\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 7.3996 - val_loss: 7.2529\n",
      "Epoch 164/500\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 7.3933 - val_loss: 7.2463\n",
      "Epoch 165/500\n",
      "1782/1782 [==============================] - 0s 82us/sample - loss: 7.3871 - val_loss: 7.2400\n",
      "Epoch 166/500\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 7.3812 - val_loss: 7.2336\n",
      "Epoch 167/500\n",
      "1782/1782 [==============================] - 0s 69us/sample - loss: 7.3752 - val_loss: 7.2276\n",
      "Epoch 168/500\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 7.3692 - val_loss: 7.2214\n",
      "Epoch 169/500\n",
      "1782/1782 [==============================] - 0s 73us/sample - loss: 7.3632 - val_loss: 7.2156\n",
      "Epoch 170/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.3573 - val_loss: 7.2098\n",
      "Epoch 171/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.3515 - val_loss: 7.2042\n",
      "Epoch 172/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.3458 - val_loss: 7.1987\n",
      "Epoch 173/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.3402 - val_loss: 7.1931\n",
      "Epoch 174/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.3347 - val_loss: 7.1877\n",
      "Epoch 175/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.3294 - val_loss: 7.1823\n",
      "Epoch 176/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.3242 - val_loss: 7.1771\n",
      "Epoch 177/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.3192 - val_loss: 7.1720\n",
      "Epoch 178/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.3145 - val_loss: 7.1671\n",
      "Epoch 179/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.3098 - val_loss: 7.1622\n",
      "Epoch 180/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.3051 - val_loss: 7.1574\n",
      "Epoch 181/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.3007 - val_loss: 7.1527\n",
      "Epoch 182/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.2963 - val_loss: 7.1483\n",
      "Epoch 183/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.2921 - val_loss: 7.1441\n",
      "Epoch 184/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 7.2881 - val_loss: 7.1400\n",
      "Epoch 185/500\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 7.2842 - val_loss: 7.1361\n",
      "Epoch 186/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 7.2804 - val_loss: 7.1323\n",
      "Epoch 187/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.2766 - val_loss: 7.1287\n",
      "Epoch 188/500\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 7.2729 - val_loss: 7.1251\n",
      "Epoch 189/500\n",
      "1782/1782 [==============================] - 0s 70us/sample - loss: 7.2693 - val_loss: 7.1218\n",
      "Epoch 190/500\n",
      "1782/1782 [==============================] - 0s 72us/sample - loss: 7.2657 - val_loss: 7.1184\n",
      "Epoch 191/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 7.2622 - val_loss: 7.1151\n",
      "Epoch 192/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 7.2587 - val_loss: 7.1117\n",
      "Epoch 193/500\n",
      "1782/1782 [==============================] - 0s 71us/sample - loss: 7.2553 - val_loss: 7.1084\n",
      "Epoch 194/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 7.2519 - val_loss: 7.1050\n",
      "Epoch 195/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 7.2486 - val_loss: 7.1017\n",
      "Epoch 196/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.2452 - val_loss: 7.0985\n",
      "Epoch 197/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.2418 - val_loss: 7.0951\n",
      "Epoch 198/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.2385 - val_loss: 7.0919\n",
      "Epoch 199/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.2352 - val_loss: 7.0885\n",
      "Epoch 200/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.2318 - val_loss: 7.0853\n",
      "Epoch 201/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.2286 - val_loss: 7.0821\n",
      "Epoch 202/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.2253 - val_loss: 7.0788\n",
      "Epoch 203/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.2221 - val_loss: 7.0757\n",
      "Epoch 204/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.2190 - val_loss: 7.0725\n",
      "Epoch 205/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.2158 - val_loss: 7.0693\n",
      "Epoch 206/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.2126 - val_loss: 7.0661\n",
      "Epoch 207/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.2097 - val_loss: 7.0630\n",
      "Epoch 208/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.2066 - val_loss: 7.0600\n",
      "Epoch 209/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.2036 - val_loss: 7.0569\n",
      "Epoch 210/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.2007 - val_loss: 7.0540\n",
      "Epoch 211/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1978 - val_loss: 7.0511\n",
      "Epoch 212/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1950 - val_loss: 7.0483\n",
      "Epoch 213/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1922 - val_loss: 7.0455\n",
      "Epoch 214/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1894 - val_loss: 7.0428\n",
      "Epoch 215/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1867 - val_loss: 7.0400\n",
      "Epoch 216/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1841 - val_loss: 7.0373\n",
      "Epoch 217/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1814 - val_loss: 7.0346\n",
      "Epoch 218/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1789 - val_loss: 7.0321\n",
      "Epoch 219/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1764 - val_loss: 7.0296\n",
      "Epoch 220/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1740 - val_loss: 7.0273\n",
      "Epoch 221/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1718 - val_loss: 7.0253\n",
      "Epoch 222/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.1695 - val_loss: 7.0234\n",
      "Epoch 223/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1673 - val_loss: 7.0216\n",
      "Epoch 224/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 7.1653 - val_loss: 7.0197\n",
      "Epoch 225/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1632 - val_loss: 7.0179\n",
      "Epoch 226/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1612 - val_loss: 7.0162\n",
      "Epoch 227/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1593 - val_loss: 7.0145\n",
      "Epoch 228/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1573 - val_loss: 7.0129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.1554 - val_loss: 7.0113\n",
      "Epoch 230/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1535 - val_loss: 7.0098\n",
      "Epoch 231/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1517 - val_loss: 7.0083\n",
      "Epoch 232/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1498 - val_loss: 7.0068\n",
      "Epoch 233/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1479 - val_loss: 7.0054\n",
      "Epoch 234/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1461 - val_loss: 7.0039\n",
      "Epoch 235/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1444 - val_loss: 7.0025\n",
      "Epoch 236/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1427 - val_loss: 7.0011\n",
      "Epoch 237/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1410 - val_loss: 6.9997\n",
      "Epoch 238/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1393 - val_loss: 6.9983\n",
      "Epoch 239/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1376 - val_loss: 6.9970\n",
      "Epoch 240/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1359 - val_loss: 6.9957\n",
      "Epoch 241/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1344 - val_loss: 6.9943\n",
      "Epoch 242/500\n",
      "1782/1782 [==============================] - 0s 77us/sample - loss: 7.1328 - val_loss: 6.9930\n",
      "Epoch 243/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1313 - val_loss: 6.9918\n",
      "Epoch 244/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1299 - val_loss: 6.9905\n",
      "Epoch 245/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 7.1285 - val_loss: 6.9892\n",
      "Epoch 246/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1271 - val_loss: 6.9880\n",
      "Epoch 247/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1257 - val_loss: 6.9868\n",
      "Epoch 248/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1243 - val_loss: 6.9857\n",
      "Epoch 249/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 7.1230 - val_loss: 6.9846\n",
      "Epoch 250/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.1217 - val_loss: 6.9836\n",
      "Epoch 251/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1205 - val_loss: 6.9825\n",
      "Epoch 252/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1192 - val_loss: 6.9815\n",
      "Epoch 253/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.1181 - val_loss: 6.9806\n",
      "Epoch 254/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.1169 - val_loss: 6.9796\n",
      "Epoch 255/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.1158 - val_loss: 6.9787\n",
      "Epoch 256/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1147 - val_loss: 6.9778\n",
      "Epoch 257/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1136 - val_loss: 6.9769\n",
      "Epoch 258/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.1125 - val_loss: 6.9761\n",
      "Epoch 259/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1115 - val_loss: 6.9753\n",
      "Epoch 260/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.1105 - val_loss: 6.9744\n",
      "Epoch 261/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.1095 - val_loss: 6.9737\n",
      "Epoch 262/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1085 - val_loss: 6.9729\n",
      "Epoch 263/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.1075 - val_loss: 6.9721\n",
      "Epoch 264/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1065 - val_loss: 6.9714\n",
      "Epoch 265/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1055 - val_loss: 6.9707\n",
      "Epoch 266/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1046 - val_loss: 6.9700\n",
      "Epoch 267/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.1037 - val_loss: 6.9693\n",
      "Epoch 268/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.1027 - val_loss: 6.9688\n",
      "Epoch 269/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.1019 - val_loss: 6.9682\n",
      "Epoch 270/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.1010 - val_loss: 6.9677\n",
      "Epoch 271/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.1001 - val_loss: 6.9673\n",
      "Epoch 272/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0992 - val_loss: 6.9668\n",
      "Epoch 273/500\n",
      "1782/1782 [==============================] - 0s 82us/sample - loss: 7.0983 - val_loss: 6.9663\n",
      "Epoch 274/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0974 - val_loss: 6.9659\n",
      "Epoch 275/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0967 - val_loss: 6.9654\n",
      "Epoch 276/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0958 - val_loss: 6.9649\n",
      "Epoch 277/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0949 - val_loss: 6.9645\n",
      "Epoch 278/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0942 - val_loss: 6.9641\n",
      "Epoch 279/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0934 - val_loss: 6.9637\n",
      "Epoch 280/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0927 - val_loss: 6.9633\n",
      "Epoch 281/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0920 - val_loss: 6.9630\n",
      "Epoch 282/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0912 - val_loss: 6.9626\n",
      "Epoch 283/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0904 - val_loss: 6.9622\n",
      "Epoch 284/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0898 - val_loss: 6.9619\n",
      "Epoch 285/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0891 - val_loss: 6.9615\n",
      "Epoch 286/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0885 - val_loss: 6.9611\n",
      "Epoch 287/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0878 - val_loss: 6.9607\n",
      "Epoch 288/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0872 - val_loss: 6.9604\n",
      "Epoch 289/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0865 - val_loss: 6.9601\n",
      "Epoch 290/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0859 - val_loss: 6.9598\n",
      "Epoch 291/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0853 - val_loss: 6.9595\n",
      "Epoch 292/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0846 - val_loss: 6.9592\n",
      "Epoch 293/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0840 - val_loss: 6.9588\n",
      "Epoch 294/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0834 - val_loss: 6.9586\n",
      "Epoch 295/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0828 - val_loss: 6.9584\n",
      "Epoch 296/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0821 - val_loss: 6.9582\n",
      "Epoch 297/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0816 - val_loss: 6.9579\n",
      "Epoch 298/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0810 - val_loss: 6.9577\n",
      "Epoch 299/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0805 - val_loss: 6.9574\n",
      "Epoch 300/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0800 - val_loss: 6.9572\n",
      "Epoch 301/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0795 - val_loss: 6.9570\n",
      "Epoch 302/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0790 - val_loss: 6.9568\n",
      "Epoch 303/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0784 - val_loss: 6.9566\n",
      "Epoch 304/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0780 - val_loss: 6.9563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0775 - val_loss: 6.9561\n",
      "Epoch 306/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0771 - val_loss: 6.9558\n",
      "Epoch 307/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0766 - val_loss: 6.9556\n",
      "Epoch 308/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0763 - val_loss: 6.9553\n",
      "Epoch 309/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0759 - val_loss: 6.9550\n",
      "Epoch 310/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0754 - val_loss: 6.9547\n",
      "Epoch 311/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0750 - val_loss: 6.9545\n",
      "Epoch 312/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0747 - val_loss: 6.9543\n",
      "Epoch 313/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0743 - val_loss: 6.9541\n",
      "Epoch 314/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0740 - val_loss: 6.9539\n",
      "Epoch 315/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0737 - val_loss: 6.9537\n",
      "Epoch 316/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0734 - val_loss: 6.9535\n",
      "Epoch 317/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0731 - val_loss: 6.9532\n",
      "Epoch 318/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0729 - val_loss: 6.9530\n",
      "Epoch 319/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0726 - val_loss: 6.9528\n",
      "Epoch 320/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0723 - val_loss: 6.9526\n",
      "Epoch 321/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0720 - val_loss: 6.9524\n",
      "Epoch 322/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 7.0718 - val_loss: 6.9522\n",
      "Epoch 323/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0715 - val_loss: 6.9520\n",
      "Epoch 324/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0713 - val_loss: 6.9518\n",
      "Epoch 325/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0711 - val_loss: 6.9515\n",
      "Epoch 326/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0708 - val_loss: 6.9514\n",
      "Epoch 327/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0706 - val_loss: 6.9512\n",
      "Epoch 328/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0704 - val_loss: 6.9510\n",
      "Epoch 329/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0702 - val_loss: 6.9508\n",
      "Epoch 330/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0701 - val_loss: 6.9507\n",
      "Epoch 331/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0698 - val_loss: 6.9504\n",
      "Epoch 332/500\n",
      "1782/1782 [==============================] - 0s 81us/sample - loss: 7.0697 - val_loss: 6.9502\n",
      "Epoch 333/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0695 - val_loss: 6.9500\n",
      "Epoch 334/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0694 - val_loss: 6.9499\n",
      "Epoch 335/500\n",
      "1782/1782 [==============================] - 0s 66us/sample - loss: 7.0692 - val_loss: 6.9497\n",
      "Epoch 336/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0690 - val_loss: 6.9496\n",
      "Epoch 337/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0688 - val_loss: 6.9494\n",
      "Epoch 338/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0686 - val_loss: 6.9492\n",
      "Epoch 339/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0684 - val_loss: 6.9490\n",
      "Epoch 340/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0684 - val_loss: 6.9488\n",
      "Epoch 341/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.0682 - val_loss: 6.9486\n",
      "Epoch 342/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0680 - val_loss: 6.9485\n",
      "Epoch 343/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.0678 - val_loss: 6.9483\n",
      "Epoch 344/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0677 - val_loss: 6.9481\n",
      "Epoch 345/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0675 - val_loss: 6.9480\n",
      "Epoch 346/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0673 - val_loss: 6.9478\n",
      "Epoch 347/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0672 - val_loss: 6.9476\n",
      "Epoch 348/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0670 - val_loss: 6.9474\n",
      "Epoch 349/500\n",
      "1782/1782 [==============================] - 0s 67us/sample - loss: 7.0669 - val_loss: 6.9472\n",
      "Epoch 350/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0667 - val_loss: 6.9470\n",
      "Epoch 351/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0666 - val_loss: 6.9468\n",
      "Epoch 352/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.0664 - val_loss: 6.9467\n",
      "Epoch 353/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0663 - val_loss: 6.9465\n",
      "Epoch 354/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0661 - val_loss: 6.9463\n",
      "Epoch 355/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.0659 - val_loss: 6.9462\n",
      "Epoch 356/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0658 - val_loss: 6.9460\n",
      "Epoch 357/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0657 - val_loss: 6.9459\n",
      "Epoch 358/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0654 - val_loss: 6.9458\n",
      "Epoch 359/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0654 - val_loss: 6.9456\n",
      "Epoch 360/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0653 - val_loss: 6.9454\n",
      "Epoch 361/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.0652 - val_loss: 6.9453\n",
      "Epoch 362/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0650 - val_loss: 6.9451\n",
      "Epoch 363/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0649 - val_loss: 6.9450\n",
      "Epoch 364/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.0648 - val_loss: 6.9449\n",
      "Epoch 365/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0647 - val_loss: 6.9448\n",
      "Epoch 366/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0646 - val_loss: 6.9447\n",
      "Epoch 367/500\n",
      "1782/1782 [==============================] - 0s 50us/sample - loss: 7.0644 - val_loss: 6.9446\n",
      "Epoch 368/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0644 - val_loss: 6.9445\n",
      "Epoch 369/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0642 - val_loss: 6.9444\n",
      "Epoch 370/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0641 - val_loss: 6.9443\n",
      "Epoch 371/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0641 - val_loss: 6.9442\n",
      "Epoch 372/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0640 - val_loss: 6.9441\n",
      "Epoch 373/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0639 - val_loss: 6.9440\n",
      "Epoch 374/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0638 - val_loss: 6.9439\n",
      "Epoch 375/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.0638 - val_loss: 6.9438\n",
      "Epoch 376/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0637 - val_loss: 6.9437\n",
      "Epoch 377/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0636 - val_loss: 6.9437\n",
      "Epoch 378/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0635 - val_loss: 6.9437\n",
      "Epoch 379/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0634 - val_loss: 6.9436\n",
      "Epoch 380/500\n",
      "1782/1782 [==============================] - 0s 58us/sample - loss: 7.0634 - val_loss: 6.9435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0633 - val_loss: 6.9435\n",
      "Epoch 382/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0633 - val_loss: 6.9435\n",
      "Epoch 383/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.0632 - val_loss: 6.9434\n",
      "Epoch 384/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0631 - val_loss: 6.9434\n",
      "Epoch 385/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.0630 - val_loss: 6.9433\n",
      "Epoch 386/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0629 - val_loss: 6.9433\n",
      "Epoch 387/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.0628 - val_loss: 6.9432\n",
      "Epoch 388/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0628 - val_loss: 6.9432\n",
      "Epoch 389/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0627 - val_loss: 6.9431\n",
      "Epoch 390/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0626 - val_loss: 6.9430\n",
      "Epoch 391/500\n",
      "1782/1782 [==============================] - 0s 65us/sample - loss: 7.0626 - val_loss: 6.9430\n",
      "Epoch 392/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0624 - val_loss: 6.9429\n",
      "Epoch 393/500\n",
      "1782/1782 [==============================] - 0s 59us/sample - loss: 7.0624 - val_loss: 6.9428\n",
      "Epoch 394/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.0623 - val_loss: 6.9428\n",
      "Epoch 395/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0623 - val_loss: 6.9428\n",
      "Epoch 396/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0622 - val_loss: 6.9428\n",
      "Epoch 397/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0621 - val_loss: 6.9428\n",
      "Epoch 398/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.0621 - val_loss: 6.9428\n",
      "Epoch 399/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0620 - val_loss: 6.9427\n",
      "Epoch 400/500\n",
      "1782/1782 [==============================] - 0s 64us/sample - loss: 7.0619 - val_loss: 6.9427\n",
      "Epoch 401/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0619 - val_loss: 6.9427\n",
      "Epoch 402/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0618 - val_loss: 6.9428\n",
      "Epoch 403/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0617 - val_loss: 6.9428\n",
      "Epoch 404/500\n",
      "1782/1782 [==============================] - 0s 60us/sample - loss: 7.0617 - val_loss: 6.9429\n",
      "Epoch 405/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0616 - val_loss: 6.9429\n",
      "Epoch 406/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0616 - val_loss: 6.9429\n",
      "Epoch 407/500\n",
      "1782/1782 [==============================] - 0s 62us/sample - loss: 7.0615 - val_loss: 6.9429\n",
      "Epoch 408/500\n",
      "1782/1782 [==============================] - 0s 61us/sample - loss: 7.0615 - val_loss: 6.9430\n",
      "Epoch 409/500\n",
      "1782/1782 [==============================] - 0s 63us/sample - loss: 7.0614 - val_loss: 6.9430\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise-deprecating',\n",
       "                   estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasRegressor object at 0x7fa2780a6910>,\n",
       "                   iid='warn', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x7fa2780a6850>,\n",
       "                                        'n_hidden': [0, 1],\n",
       "                                        'n_neurons': array([  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  1...\n",
       "       937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949,\n",
       "       950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962,\n",
       "       963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 974, 975,\n",
       "       976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988,\n",
       "       989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999])},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(n_hidden=1, n_neurons=30, learning_rate=3e-3, input_shape=[13]):\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(keras.layers.InputLayer(input_shape=input_shape))\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "    model.add(keras.layers.Dense(1))\n",
    "    optimizer = keras.optimizers.SGD(lr=learning_rate)\n",
    "    model.compile(loss=\"mae\", optimizer=optimizer)\n",
    "    return model\n",
    "\n",
    "\n",
    "keras_reg = keras.wrappers.scikit_learn.KerasRegressor(build_model)\n",
    "\n",
    "\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "param_distribs = {\n",
    "    \"n_hidden\": [0, 1],\n",
    "    \"n_neurons\": np.arange(1, 1000),\n",
    "    \"learning_rate\": reciprocal(3e-4, 3e-2),\n",
    "}\n",
    "\n",
    "rnd_search_cv = RandomizedSearchCV(keras_reg, param_distribs, n_iter=10, cv=3, verbose=2)\n",
    "rnd_search_cv.fit(X_train, y_train, epochs=500,\n",
    "                  validation_data=(X_valid, y_valid),\n",
    "                  callbacks=[keras.callbacks.EarlyStopping(patience=10)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0021928619507738728, 'n_hidden': 0, 'n_neurons': 475}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-7.138949251335478"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1782 samples, validate on 594 samples\n",
      "Epoch 1/500\n",
      "1782/1782 [==============================] - 0s 260us/sample - loss: 12.5200 - val_loss: 10.8405\n",
      "Epoch 2/500\n",
      "1782/1782 [==============================] - 0s 96us/sample - loss: 9.8707 - val_loss: 8.5035\n",
      "Epoch 3/500\n",
      "1782/1782 [==============================] - 0s 98us/sample - loss: 8.0065 - val_loss: 7.3497\n",
      "Epoch 4/500\n",
      "1782/1782 [==============================] - 0s 101us/sample - loss: 7.3231 - val_loss: 7.0342\n",
      "Epoch 5/500\n",
      "1782/1782 [==============================] - 0s 102us/sample - loss: 7.1744 - val_loss: 7.0066\n",
      "Epoch 6/500\n",
      "1782/1782 [==============================] - 0s 97us/sample - loss: 7.1254 - val_loss: 6.9885\n",
      "Epoch 7/500\n",
      "1782/1782 [==============================] - 0s 86us/sample - loss: 7.1022 - val_loss: 6.9938\n",
      "Epoch 8/500\n",
      "1782/1782 [==============================] - 0s 110us/sample - loss: 7.0825 - val_loss: 6.9883\n",
      "Epoch 9/500\n",
      "1782/1782 [==============================] - 0s 99us/sample - loss: 7.0606 - val_loss: 6.9854\n",
      "Epoch 10/500\n",
      "1782/1782 [==============================] - 0s 87us/sample - loss: 7.0486 - val_loss: 6.9954\n",
      "Epoch 11/500\n",
      "1782/1782 [==============================] - 0s 88us/sample - loss: 7.0372 - val_loss: 6.9934\n",
      "Epoch 12/500\n",
      "1782/1782 [==============================] - 0s 86us/sample - loss: 7.0265 - val_loss: 7.0003\n",
      "Epoch 13/500\n",
      "1782/1782 [==============================] - 0s 85us/sample - loss: 7.0202 - val_loss: 6.9910\n",
      "Epoch 14/500\n",
      "1782/1782 [==============================] - 0s 87us/sample - loss: 7.0116 - val_loss: 6.9906\n",
      "Epoch 15/500\n",
      "1782/1782 [==============================] - 0s 87us/sample - loss: 7.0011 - val_loss: 6.9925\n",
      "Epoch 16/500\n",
      "1782/1782 [==============================] - 0s 88us/sample - loss: 7.0013 - val_loss: 6.9861\n",
      "Epoch 17/500\n",
      "1782/1782 [==============================] - 0s 89us/sample - loss: 6.9948 - val_loss: 6.9882\n",
      "Epoch 18/500\n",
      "1782/1782 [==============================] - 0s 99us/sample - loss: 6.9859 - val_loss: 6.9823\n",
      "Epoch 19/500\n",
      "1782/1782 [==============================] - 0s 98us/sample - loss: 6.9841 - val_loss: 6.9801\n",
      "Epoch 20/500\n",
      "1782/1782 [==============================] - 0s 87us/sample - loss: 6.9748 - val_loss: 6.9910\n",
      "Epoch 21/500\n",
      "1782/1782 [==============================] - 0s 88us/sample - loss: 6.9741 - val_loss: 6.9823\n",
      "Epoch 22/500\n",
      "1782/1782 [==============================] - 0s 95us/sample - loss: 6.9673 - val_loss: 6.9800\n",
      "Epoch 23/500\n",
      "1782/1782 [==============================] - 0s 88us/sample - loss: 6.9660 - val_loss: 6.9809\n",
      "Epoch 24/500\n",
      "1782/1782 [==============================] - 0s 110us/sample - loss: 6.9589 - val_loss: 6.9877\n",
      "Epoch 25/500\n",
      "1782/1782 [==============================] - 0s 106us/sample - loss: 6.9546 - val_loss: 6.9852\n",
      "Epoch 26/500\n",
      "1782/1782 [==============================] - 0s 99us/sample - loss: 6.9512 - val_loss: 6.9893\n",
      "Epoch 27/500\n",
      "1782/1782 [==============================] - 0s 106us/sample - loss: 6.9452 - val_loss: 6.9870\n",
      "Epoch 28/500\n",
      "1782/1782 [==============================] - 0s 115us/sample - loss: 6.9442 - val_loss: 6.9882\n",
      "Epoch 29/500\n",
      "1782/1782 [==============================] - 0s 102us/sample - loss: 6.9391 - val_loss: 6.9869\n",
      "Epoch 30/500\n",
      "1782/1782 [==============================] - 0s 115us/sample - loss: 6.9339 - val_loss: 6.9824\n",
      "Epoch 31/500\n",
      "1782/1782 [==============================] - 0s 119us/sample - loss: 6.9288 - val_loss: 6.9841\n",
      "Epoch 32/500\n",
      "1782/1782 [==============================] - 0s 104us/sample - loss: 6.9281 - val_loss: 6.9891\n"
     ]
    }
   ],
   "source": [
    "tensorboard_cb = keras.callbacks.TensorBoard(run_logdir)\n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint(\"my_keras_model.h5\", save_best_only=True)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(646, activation=\"relu\", input_shape=[13]),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mae\", optimizer=keras.optimizers.SGD(lr=0.01239829637839909))\n",
    "history = model.fit(X_train, y_train, epochs=500, validation_data=(X_valid, y_valid), callbacks=[keras.callbacks.EarlyStopping(patience=10), checkpoint_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.DataFrame(history.history))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2534 entries, 3040 to 1701\n",
      "Data columns (total 16 columns):\n",
      "portrait                 2534 non-null int64\n",
      "residents                2492 non-null float64\n",
      "householdType            2494 non-null category\n",
      "guarantorExist           2534 non-null int64\n",
      "furtherInformation       2534 non-null int64\n",
      "professionType           2448 non-null category\n",
      "income                   2486 non-null float64\n",
      "age                      2366 non-null float64\n",
      "WB_CERTIFICATE           2534 non-null int64\n",
      "CREDIT_REPORT            2534 non-null int64\n",
      "INCOME_STATEMENT         2534 non-null int64\n",
      "wbs                      2497 non-null float64\n",
      "animals                  2455 non-null float64\n",
      "days_waiting             2534 non-null int64\n",
      "noRentArrears            708 non-null float64\n",
      "noTenancyLawConflicts    702 non-null float64\n",
      "dtypes: category(2), float64(7), int64(7)\n",
      "memory usage: 302.5 KB\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVAAAAK9CAYAAABy2jQYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3df3Rf913f8dfn+0txSIOJouAmmRtil6ZZtdmpjozo8NQ6yA0brY6900KdI06bxhUrabOuVepBmAcHuySczSPQIblOV4+WDZCX1YE0bUxEAlIS3CjDlK5Qp6sb3ILqYRJKY0lfffaHdG/u937v99db35/S83HO9yS+3x/33q/klz+/P857LwBA7VKtvgAA6FQEKAAYEaAAYESAAoARAQoARplmnOTqq6/2N9xwQzNOBQB198UvfvHb3vue+PGmBOgNN9yg06dPN+NUAFB3zrmvJx2nCg8ARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoGipmZkZHT58WDMzM62+FKBmmVZfANavmZkZ7dq1S/Pz88rlcjp16pQGBgZafVlA1RpWAnXO7XfOnXbOnZ6bm2vUadDBpqamND8/r3w+r/n5eU1NTbX6koCaNCxAvfcT3vs+731fT09Po06DDjY4OKhcLqd0Oq1cLqfBwcFWXxJQE6rwaJmBgQGdOnVKU1NTGhwcpPqOjkOAoqUGBgYITnQseuEBwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAo4YFqHNuv3PutHPu9NzcXKNOAwAt07AA9d5PeO/7vPd9PT09jToNALQMVXgAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMGhagzrn9zrnTzrnTc3NzjToNALRMwwLUez/hve/z3vf19PQ06jQA0DJU4QHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAqGEB6pzb75w77Zw7PTc316jTAEDLNCxAvfcT3vs+731fT09Po04DAC1DFR4AjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADCqOUCdc5c55/6Vc+4e59zGlWNbnHNX1f/yAKB9ZWp5sXNuq6QvSHqVpI2SfkfSRUk/vfLn99b7AgGgXdVaAj2i5QD9fknfjRz/rKQ31+uiAKAT1FQClfTDkn7Ie593zkWPn5N0bd2uCgA6gKUTKZtwbLOkv1vltQBAR6k1QD8v6UORP3vn3JWS/oOk36vbVQFAB6i1Cv8hSY87574i6TJJ/0PSVkl/Lekddb42AGhrNQWo9/68c26bpJ+UdIuWS7ATkj7tvf9u2TcDwBpTawlUK0H54MoDANatmgPUObdJy73x1yjWhuq9/3idrgsA2l6tA+lvl/QJSU7S30rykae9JAIUwLpRawn0lyTdJ+kXvPeLDbgeAOgYtQ5julLSfyU8AaD2AP20pH/RiAsBgE5jGQf6kHNul6QzkhaiT3rvf6FeFwYA7a7WAH2fpLdK+raWB9DHO5EIUADrRq0Beq+kf+u9/0+NuBgA6CS1toGmtbx0HQCse7UG6Ccl7WvEhQBAp6m1Cn+5pPc653ZL+lMVdyJ9oF4XBgDtrtYAfb2k2ZX/vyn2nBcArCO1rsbEth0AsKLmxUSk5Z059cowprPe+5cTXrNf0n5J2rx582quEQDaUk2dSM65rHPufi0vJPK/tTyY/m+dc/c55wq2+vDeT3jv+7z3fT09PfW7YgBoE7WWQH9Zy4spj0r6o5VjPyLpsJbD+MP1uzQAaG+1Bui7JL3He//7kWNnnXNzWl7mjgAFsG7UOg70eyWdTTh+VtLG1V8OAHSOWgP0f0tKGuv5QUnPrf5yAKBz1FqFH5P0+865H5U0o+Ve+AFJ10q6rc7XBgBtraYSqPf+CUmvk/Q7kq7Q8gLLvyPpdd77Pyr3XgBYayy7cv6VpJ9twLUAQEepdRzoz6xsLBc/frtz7l/X77IAoP3V2ol0t6RvJBz/v5L+zaqvBgA6SK0Ber2kryccf2HlOQBYN2oN0G9J2pZw/BYtb/MBAOtGrZ1In5H0q86570iaWjn2ZklHtLxjJwCsG7UG6L+X9AOSHpWUXzmW0vJQpnvreF0A0PZqXQ90QdJPOud+XtL2lcPPeu+/WvcrA4A2Z1oP1Hv/l5L+ss7XAgAdpeYAdc69U9IuSdco1gnlvX9bna4LANpeTQG6spjy3ZIel3Re7IMEYB2rtQQ6Iuknvfe/24iLAYBOUus40JRYtg4AJNUeoBOSiubCA8B6VGsVfqOkd62sB/qnkhaiT3rvkxZbBoA1qdYAvVmvVOFvqvO1AEBHqXUg/ZsbdSEA0GkqBqhz7rOSbvfev7jy/6V47/3b63dpANDeqimBXtAr4z0vNPBaAKCjVAxQ7/27k/4fANa7WocxAQBWEKAAYESAAoARAQoARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGDUsAB1zu13zp12zp2em5tr1GkAoGUaFqDe+wnvfZ/3vq+np6dRpwGAlqEKDwBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoABgRIACgBEBCgBGBCgAGBGgAGBEgAKAEQEKAEYEKAAYEaAAYESAAoARAQoARgQoABgRoE0wMTGh3bt3a2JiIjy2e/duXX755dq9e3fie2ZmZnT48GHNzMyYz5v0GfX4XCn5niyfXe01Jp3P8jlAXXnvG/544xvf6Ner8fFxLyl8jI+P+6GhoYJjQ0NDBe+Znp72GzZs8Ol02m/YsMFPT0/XfN74Z4yPj/vR0VGfy+Wq/tzp6Wl/6NChotcl3ZPlmpPek3Qs6XyWzwGsJJ32CdmWaVQwO+f2S9ovSZs3b27Uadre5ORk0Z+ffPLJgmPxP09NTWl+fl75fF7z8/OamprSwMBATeeNfsalS5f0Mz/zM1pcXNTy74Iqfu7MzIx27dql+fl55XI5nTp1Knxt0j1duHCh5mtOus/g2qLHguPR8+3fv7/mz6n1OwQqaVgV3ns/4b3v89739fT0NOo0bW/v3r1Ff/6RH/mRgmPxPw8ODiqXyymdTiuXy2lwcLDm80Y/I5VKKZ/Ph+HpnKv4uaVCqdQ9Wa456T1Jx5LOF/+cTCYj55wymUzJzwHqLqlYWu/Heq7Ce+/Danu06jk0NOQ3bNhQVH0PlKo+1yL4jPHxcZ/L5bxzzmezWT86OlpV9b1cFTjpnizXnPSepGNJ54u+Pri/XC4Xvq8e3yHgfekqPAG6DkxPT/uuri7vnPNdXV1VB0qnBNChQ4d8Op32knw6nfaHDh1q9SVhjSkVoA1rA0X7mJqaCts/FxcXq24PHBgY6Ih2w6C6HrTXUl1HsxCgdTYzM6OpqSkNDg62Tfis9YAZGBjQqVOn2u57x9rn/ErHQiP19fX506dPN/w8rVau57rV2jHYgU7hnPui974vfpwSaB3VY/hRo3RKdRzoJMxEqiOGzgDrCyXQOqItDlhfCNA6q1dVmTbLQnwfaEdtG6Dr+S+MpTNqLX9f8e/jyJEjunDhwpq8V3SWtgzQdu7NboZaO6PW+vcVn9f//ve/X977NXmv6Cxt2YlUbh72elBrZ1S7fF+NWj4u+n2k02ktLS2t+l5Z6g710JYl0LU+8Dsqqepda2dUO3xfjSwFR7+P7u5u3X333au617VeYkfztGWArpfe7HJ/kWvpjGqH76vRY2Cj30dvb++q7rWdx+uis7RlgErrY+B3Pf8it/r7amYpeLX32g4ldqwNbRug60En/0WONz20Qym4WgMDAzpy5IgmJye1d+/etr5WtDfmwrdYJw4/6vQ2xE6/fjRfqbnwbdkLv54MDAzowIEDGhgYqNumbI3WLr3+Vp1+/WgfVOHbhHXwfCtKUp3c9CB1/vWjfRCgbcLSodSq3uROau9M0unXj/ZBgLYJS6molSWpVvf6r1anXz/aA51IbSTaoSSpqhJSJ3ZCAZ2mVCcSAdqG6CUG2gu98G2mXO85vcRAZ6ANtAUqlTDpJQY6AwHaApV6z+klBjoDAdoC1ZQwy/US03FUG74vNAoB2gKrKWHSwVQbvi80EgHaItZxiCzFVhu+LzQSvfAdhq2Ta8P3hUaiBNph1msHk7Udc71+X2gOBtKj7bErJ1qt1EB6SqBoe9F2THblRDuhDRQNVY/1ShuxKydQD5RA0TD1GkJU7105gXohQNEwjdo0b7W7cgL1QoCiYRo1p5+1PNEuCFA0TDOHEDFdE61AgKKhmlFaZLomWoVeeHQ81k9FqxCgLdaKbYk7RbXfDdM10SpU4VuIqmdptXw3TNdEqxCgLcRKQaXV+t3QM49WoArfQlQ9S+O7QSegBNpCVD1L47tBJ2A1JgCogG2NAaDOCFAAMCJAW6xe40CbNZ601vMwzhVrmve+4Y83vvGNHsWmp6f9hg0bfDqd9hs2bPDT09Mt/Zx6n6dZ1wU0mqTTPiHbKIG2UL2mIDZrKmOt52GKJdY6ArSJ4tXZeo11bNaYyUrnadT9Ae2KYUxNUmpqYr2WYWvWcm6lztPo+wNaiU3lWqzU1MR6TUFs1lTGUudp9P0B7YgqfJOs9epsPe/P0nNPbz9agSp8EwTV2O7u7pbtZ26pStf6ntVU16PfUXTTuGpWqKL5AI1WqgrPMKYGa4ehPJZraOZ1R8+VzWZ9KpXyknw6nfaHDh2q+P5Dhw75dDpd8J52+N6xdohhTK3RiKE8tVZXLdfQzCFI0XPl83mlUqmamgKSmg8YQoVmoBOpweq9M6VlEWbLNTRqR81qznXkyJGamjpKrdyUyWS0tLSkTCaz5tqc0R4I0Aar97JslkWYLdfQzOXk6nGupN5+v9K+H/wXqDcCtAnqOZQnXlrr7u7W4cOHKwaP5RqaOQSp3ueamppSPp+X9175fJ7V/tEQBGiHiZbWaumxXm890s1sgsD6RYB2oKC0dvjw4aqq8+tx8zpWtEczEKAdrNpSlqXddLXaocTLLCg0GgHawaotZTW7OrseS7xYnwjQDldNKavZ1dlWlHiBViBA14lqq7P1qHpXKvG2Q/UeqAcCFKF6Vb3LlXip3mMtIUARqmfVu9Zl74BOxFx4hJqx5N5aX9YP6wsl0CaKtv2dOXNGk5OT2rt3r/bv31/0fFAqix6TVPL5ixcv6rnnntPevXvV29tb1euC8wYGBgZ05MiR8Lok6fDhwxWX4ctkMsrn80qn01pcXCz7HcTPkXSfSee45557dOLECe3Zs0dbtmwp+u5WYzVL/bVyiUK0gaQlmur9WM/L2QXiS7ZJCh/j4+OJy69Fj+VyOd/V1ZX4vHOu4PMymUxVrxsfHy95jV1dXT6Xy4VLy6VSqcRl4YJl5IJHOp2u+ntIus+kc4yNjRWco9w9rObnUutSf5W+G6wdavZyds65/c65086503Nzc406TceItv0tLCwUPHf//ffr+PHjBW2Dx48f18GDB3Xp0qXwPfG2w+AzfWyxjMXFxapeNzk5WfIa5+fntbCwoKWlJUnS0tJS4rJw+Xy+7J+jZmZmCu4pfn3xpeeCZfs+85nPlPzMY8eOlXyuGpZl74L3VPpusPY1rArvvZ+QNCEtr0jfqPN0iujQnlQqVRCiZ8+e1blz55TJLP840um0jh07psXFxeV/5VIpZTIZOee0uLhY0HaYy+X08ssvF4RjJpOR977i67Zt21awEEn0GoPPWFxc1NLSklKpVGKbZTqdLgjNdDqdeP9B7/ulS5cKPq+7u1uzs7PhvQfniPbWl3PttdeW/+IrWM1Sf/F7oT13/aENtEniQ3vOnDmj+++/X2fPng1XDLrzzju1efNmPfPMM3rooYfC9/b19enIkSOSittAg8+s1AYaf922bdv0wAMPFA0nil/j5OSktm3bpo0bNya28y0uLlbVBhottaVSKd16663au3dvuBhKOp3WnXfeqZGRkaJ5/ul0Wjt37tT58+e1Y8cO/fZv/7YWFhaUzWY1NjZW159LrUv90Qa6ziXV6+v9oA00Wan2t9HR0YJ2vtHR0bqfO2kbjGquzSrp88pdQ7nzB++lzRHNohJtoJRAG6Sant1SpZ+RkRE9+OCDYSlrZGSk7tfV3d1dtupa7/Gape611DWUKxmySAjaBQHaADMzMxocHAwDsFz4JIXBwMBA2LlSqWpYLqjjz8Wv64EHHihZ/SzVNriaaZjxe2XJOXS8pGJpvR/rrQrfjCq498tV2Vwu551zPpfLFVVz41XgWq8rXlVu1U6dDBFCq4ldOdeeYOiT9z4c+hSwDM+JGxgY0IEDB8KSYT0+s5T4TqONPBdQLwRoA4yMjKirq0vOOXV1dZVtw6x1i+JqzMzM6Ny5c0qn0wVTJrdv317wuiuvvLKmc0enYabTaZ07d67gvdZ7CYYs3Xvvvdq1a1fY1MCUT7S9pGJpvR/rrQrvfXU9xavtaZ6envZdXV3eOee7urqKZvVks1nf398fztY5dOhQOHvGOeez2WzNVeSgKaDUrChLlbtUb3z0O6DnHa2kElV4ArSFygVHdErl6OhoyXCNB0v0M4OgTAq5TCZTMBVxaGio6nBKuu5Kw6LKqRS+tIei1QjQNlSqE6jaECwXNtF570mluvHxcfN8bst89krGx8f90NBQ4tz21YTzekNJvTFKBSjDmFrMOVfwX+mVtsZg6qVf6SQKOlKSxmdGhxedOnVKx48f1yc/+cmiqZ/RoUS9vb06ePCgHnvssYL53NYtQqxDkmZmZsIZSU8++aR6e3sL3m+ZbrkesVh18xGgTRQfQzk1NRXOd19cXNTx48eLQvATn/hEOJ0xCI5MJqOlpSVlMpmieeO5XE5HjhzR5s2b9cEPfjCc3hn8RZqYmAiXguvt7dWNN96obDZbFLRR0fcEy8eVGr9q+Qs7NTUVziu/dOlSUYjHA1sqXmYv+JxSSwE2azuT1VrNNdR78gOqkFQsrfeDKnzlam+wfFz8+aROomi1P6j6BlX2oHMoqWo+Pj6euOxdLpcL21njVen4e1a7fFySWs6RtJRcuaX+qm1SaId21tVeQzvcw1olqvCtlVQ6OHDgQFiyOnfunI4ePVo07jFaQg2O5fP58Nj73//+8M+SwuPBn6NV8/hYyujCH5s3b9aZM2f0vve9T5L0+c9/XlLxkneTk5N1WcQ46sKFC0qlUuFCIxcuXCj52uiiJNLy/QUrW/kqmjoqfW4rS2+rvQZmdjUfAdokpdrxgmrvzMyMPvWpTxU9n/SedDqtpaUlOee0tLQUhqW03JYarI4UXzbu8ssvL7im+LJ3Bw8eLHg+qLYHYSopXKm+ntXdwcFBdXV1VdXGmbSUXLml/qptN22HdtZ6XAPrBDSXi/7la5S+vj5/+vTphp+n3VUKnaTtO+LLpc3MzOjNb35zuGZnEBxBmHR1demuu+4Kl6zbuHGjuru7w06aVCql7du364477pCkgrbNiYmJsAQqSePj4+Hx6Otqmetfr+8m6bXNaANtdrtoO7TDophz7ove+76iJ5Lq9fV+0AZam3JtWfEhPaOjo+GwpOC/8XbTpGFApdpkM5lM2D5aqg2tWXP9W402RQTEXPjWq3aqY7l54PEpjiMjIzpw4IB6e3slSY888oguXbok770uXbqku+++O1y6LjotMukcU1NTBW2p8TbT4B6effbZun0nFo2Y/pqk3M8BkGgDbZpqxuglrdWZSqX00EMPqbu7W/v379fAwIDuuuuucIfK+DJ10fGkkvTMM89odnZW73jHO/T0009rx44d4Tmibannzp3T9u3bw2PRYVPR67rrrrvCbTacc2GIl7vvelZJo99jJpPRu9/97nAV+3prh3ZRtLmkYmm9H1Tha18Bfnx83A8PDxcN70ka8hOvUld6BEOgstlsOPwplUr5rq6u8FjS3Pr4Dpz9/f3muf71+B6De2lk9ZqZPfCeYUwtV6k0E68uXrhwQf/wD/9Q8Jr4kKLg2I033ljTtXjvtbCwUNB7Hwx3Cp4PBvY///zzYY93vHR7yy23NG1oULx0njRLqxGlUHq1UQ4B2iSVxugNDg4WVZ+7u7sThxBFj/X09OiRRx6p+Xqcc0XDn3K5nPL5vPL5vJxz+uQnPxlubZxKpcIZS/l8PtxFc2ZmpuSIgmBJPUnhUKroLqClJK2kH59pNTs7qwcffFD5fF65XE4XL17U7t27C2ZLlfq8WtArjrKSiqX1flCFryxp1lGpGTpjY2N+69atfmhoqGJVfevWrX54eLhgcZGkR7DsXTabDav08dWaxsfHw1lQwfFKqycFq0kFi5eUWwQlushJNZvPBc+NjY2VnMm0mmYEeuEREFX49ja1Mh9cUri6/GOPPVbwmmPHjml2djbcM/75558v+5mZTCZcpT7onS/llltu0ezsbDirJygJp9NpZTIZ3XjjjZqdnS2Y9VRqAZJo1V1anuV04cKFktX5aAkzlUqFM6mCefHVNH9EBbOlZmZmdPDgwbAJopaq/mrea0FJtzMRoG3iS1/6Uvj/3nsdPXo0nK4YmJ2d1Z/8yZ8UDDUqZ2FhQWfOnFFvb2/F127fvr2oKaC3t1e5XE7PPvusjh49Goap975gllM80EoFXqkQDP7xWFpaKphZtbS0pO7u7sTmj2joxttm9+7dGz4fnbFUbU/6at5rwSpKnYsAbRNPP/10wZ+D0ptzTlu2bNEb3vAGnTx5smIQxn34wx/WgQMHws8rZXZ2Vps2bSo4dubMmaKponfeeac2b95cNEMqqtbl7rq7u8N/LKLnis6Lj3fmREu56XRaO3fu1Pnz57Vnzx7t379fhw8fDufMp1Ip3XrrrTp48GBVwRR8tuW9FvXsbENzEaAtEq+y7dmzR/fdd1/4fNChlMlkdOutt2r79u06efJkzed56aWXqhoAPjk5qXe/+91Kp9NhJ1I0PKNjPq1/uUv1aF+4cCHs1HLOKZ1OF8zRl4q/r2gpN5PJ6KmnnlI+n9eRI0f04osvFoxpzWQyYQBWU1WOl6AbGZ5J52O8aQdJahit94NOpEKlOif27dvnr7rqKj80NFTUWRMfg9nsx/DwcFVLwpXqCCon3lk2NDTkt27d6sfGxsp+X8HSe8PDw0VjQyuNaa10Xc0e/8l40/YmOpHaR6kpgidOnND8/Lwef/zxos6aVnLOqb+/v+LQo2hHULAaVDVV0uhydtIrw7Tuu+8+bdmyJT/c4YUAABnrSURBVLEDSlK4QEomkwlLm8EvdnxMa/CeaqvKzR7/yXjTzsRc+CaIz92Oz2ePz00PqtBB50gqlSrqKAkE4ywbyXuvX/qlX9Ltt9+ue+65R6997Wt1zz33FLwm6AjK5/NaXFxUKpWqekviwcHBcGWp+H1OTk4WPB+swh/9vhYXF/We97xH73vf+9TV1RWeN5vNFlxD9HvPZDJF2zIDtaIE2mCleliTOlSCdrBoaSqTyei9732vrrzyyoI20kClzqF6+c53vqNPf/rT4Z/vu+8+PfXUU/rYxz4maXnOfbQj6EMf+lC4lF5Q+jtz5kzR1iCB6D8W0XsKJg8EpXHvvc6cOVM0SD9omx0ZGQm/V6l4ibtgq5QHH3xQR48e1ac+9SkdOXKkZIdYp2E4VJMl1evr/VjPbaC17CgZtIPF58CPjo7WPN+9msfQ0NCq21aD7TSiA/VTqVTRknnBAP3gER3sHv2OogP4s9ls0UD6VCoVbkWStOVzrT+TVCrls9lsRw6Wj7ebMvC/ccRydq0RTNEMqqfxauPExIR2796tiYmJkp/x8MMP66mnnqr7tT322GNlS7CpVOVfj4WFBc3Pzxf01nd1denixYsaGRnRyy+/rHw+Hw7QD9x///0FTRpJVfilpaWwNBV9fmlpKfzMSpMJkkSr8kGJN5/P69KlSzp48GBdq/WNWnovqNnce++92rVrV1jyZPm9JktK1Xo/1nMJNDpFUyq/yVtQEoqX6Jr52LBhg9+wYUM4dfP1r399wfNJ15XJZLxzzmcyGd/f3+/37dtX9Jp4STe+132wkHNw//FpoPHng1JqsLJUvGd+fHw8sWc7Ov1zaGjIj42Nlfz51ONnX830Vcu5ql0kG/WhEiVQArTB4suvRX/h+/v7E0OsVeEZf0SXuyv3SKVSBQFU7fUH30O8eWJ4eNiPjo6Gu5TGv7/h4eGi7y4I2lL/IEXn40fn+Hd1dYXhHL+uev7s45/ZqB04GQ7VGKUClE6kBguqi/FpgRcvXtTXvva1xPf4lepwq8Wr3fEVnALRYVa1DLkKVp0K5usHNm3apM2bN4d7PcVt2rRJmzZt0jPPPFNwPL7cX3D9+Xxev/EbvxEO0I/u6BkMd4reY70Gs5cbIL/a2UelOiIZDlVaIzrY2FSuCeKboF28eDGxR73dlQrQ+GsymUxR+CbJZrP6wz/8Q0kKN8rL5XJ6/PHHC7ZYll6ZmRU8X817kkRDNFiiz3sfLtFX7xXuS/2lZf57c632+y61qRwl0CaIlwp2797dwquxq+Yf2y1btugjH/mInnjiCZ04cULf/e53JS0H69vf/nadPn1aL7zwgqTlEuJ9992n/v5+/eqv/mrBUKJ4qfRNb3qTLrvsMu3duzf8Lh9//PGCcAqOT05O6hvf+Ia+/OUvF13fm970Jr31rW+tuKNnvZQqEbKHe3M1ar0BArQF4nutd7poyfSrX/2qfvqnf7qo6p3L5XTbbbfp/PnzYYBK0smTJ3Xy5Eml02m95z3vCY9/61vfKnj/k08+KUlhifXChQvq7u4On4+W9JK2aA7cfPPNOnDgQNHxUvtTNTLcqG43T8PWG0hqGK33Yz13IiWJd3Z08iOpk6fU6yqNLoj2zJcb95pOpwt64bPZbNjhFJ8r39/f79PpdFFvffznEfTce894yrVqNR1sWu+dSM2aoRFv7xwcHAxn4PT09Ghubk5/8Rd/0bDzN1t8ubtSgrnx5V7r/SuLKI+MjOjo0aOJ41Sjx7z3Be2t0epZb2+vhoeHdccddxRU1w8fPpzYHh3UCsot/hxXr98rZhA1XkNK/EmpWu9Hq0ugzSpRBOeJDpOJz8BZz49qZz2NjY3VXEoPVqyKji2N/8yTfj7B/wePoaGhqn9f6vV7RYm3/Wk9l0CbtWBtdCFeSeEK6+vR1q1b9fLLL+v8+fNaWlpSNpvVr/3ar+kXf/EXC9pAk0xNTem5556r6Xxve9vb1N/fH869P3fuXOKsnGA4maTEnUaDTqpqOnjq9Xu12s+h9No66yJAm7VgbdKYz3Q6XdWQnrUkm83qIx/5SLh/k/deqVRKvb29ete73lUwhKu/v19f+tKX9J3vfCc8Nj8/XzFk437wB39Q586d08///M+Hq9QHO4cGP/Nghf2Ac65o8ZKzZ89Wdb6kXUdLLf5cyWp+P2dmZgqGc8VHM6DBkoql9X60ugrvffNmaEQXFU7aMXKtP7Zu3RrO+Il2GJWadRR08JT7zGqej1fFpeUZS9GfeXyRlptvvtn39PQUHLv++uv99PR0uKB1UsdT0q6jq13Qw/r7mfR90hRQf+rkKnw9qijNGjISP8+OHTsafs528oY3vEGzs7MFC4xICtfxjI/vrKYTqtLzwefEbdq0qWDI0vnz5wuev+KKK3T11Vdrbm4uPHbjjTfq+PHj4QylYIfU+H5M0U3woguaWKvj1t/P+HCvoDTN3krN0fYBGq+iPP744x3xSxGE/mWXXdbqS2m4XC6na665Rt/85jd18uTJgpWTvPcF40Rfeukl0zlSqVT4GfFATQrYrq4ujYyMFBy74447CqZ/3nHHHZKkJ554Ijw2NzdXtHJSPKTim+B94Qtf0JNPPqlTp06VrI5PTEyUXAu1lGoKDvGNAJOaFNBAScXSej9WU4WPV1FGR0fNn9Us5dbBbKdHUrW3Xp8b/+ygCr9169ay781kMuEKSdHj11xzjT906JB/zWteU/H8r3nNaxKrr9PT0+HPI7rWaKXvIf47lzRGNbpYSLw6Hh9REF0LtZrfoVLV8WC8bLAaVi6XC5uOqL7XlzqtCh/86xv/17/dzczM6ODBg+EUxmatGG9RaYRAdJ+iWjjnCu47ukBHpXUAFhcX9dRTT2nDhg26dOlSePymm27SgQMH9LnPfU5f//rXC94T7CQaeOGFF3Tw4EE9+uijBa+bmpoKX5fP58PSXTabLThXVCaTKSrJJt1vtMQXr47HFzk5duxYxY6eaDNBMDa21Fz6YNeCes7hR5WSUrXej1pLoPFG+ui/sO38L2tw3WqD0mU9HpZl9fr7+/3OnTsLjvX09BSUuoLdR0st5xd/pFKp8OceL/319/eX7KgbGhoq+PkklQSja5FGH0HnVrCjZ/znHMyqymazYSdSqY6g+HmDFfXLdfRUKrXWstMBVk+dVAKNNsRL0p133qnNmze3/dCM4LrXCl9F5430yn5GmUxGt9xyS1GtYW5uTh/4wAfU29sr6ZXdR8+cOaOxsTE9/PDD+vM///OSnx8MR5KkkZERHTt2TAsLC+H5XnzxxcTS8h/8wR8U/Dm6+2cqldKFCxd0/PhxLS4uFrwuaG/1/pUdPaO/dwMDA0ULmZRb7Wf//v06e/asTpw4oWuvvVZ//Md/XLGTKelao5o1NA/ltWWAxn85OqVqElx3UH1fL2666Sa99NJL+uY3v6mjR48qnU4rm80WjH+9dOmSjh8/rs2bNxdUTTdu3Kjbb79dP/dzPxcObI8Hdz6f1/Hjx8MpskEH1eLiYrjOZ7DcXVQ2my348+DgoLq6ugpCJz4qIBDshFopnM6cORMO3C9V5Z6ZmdEDDzyg+fl5nTt3rmh8apKka42qZTUnBto3UFKxtN4PSydSp66sPT09XTTecL09nHN+eHjYX3fddQXHh4eHi76boBod7TAZGxvz/f39YedOdJuPWjrl+vv7S27pER23Ge+w0kr1f+vWrX7fvn3h66NjfCtN2Y1vmhc0hzjn/OjoaMXrKnWs1O9c8DoWRmkMsaVH86zVAE1qEy3Vg500QD5oy45+XrU919EAqvZ64/PjS5meni7bHhu0vwchnslkiu7bOVewrUm0TTLeRjs2NlZ0fmvIVdr5lLbS+igVoOzKWWczMzNaq6vv+1jVOpPJaMuWLYmvzefzRa9fXFwsOOa918WLF3X48GFJ0oEDB8L2xPvvv7/gvc65cHfTWq43n8/r5Zdf1sjIiCYmJky7ZHrvw91Hg1Wlgh09JYXbtGSz2XAKaXT31fi8/qmpqYJriLb5V9oZNH790ffGpwxPTk6GzUrpdJq20kZIStV6P1Zbhe+U6nyp6uB6fFSz8lLQix3f+C2XyxW9NqhKx0uK3d3dfmxsLCx9pVIpf/311/uhoaHEc8Z7wOMrNAWfEb/OXC4XbrLX1dUV7uq5b9++gl1AR0dHw5JqNbuvltrsrtQunqVWmApKxtHzBCXdTvn7087USVX4+DCmpMVy21G5RYDXyiNYoHi1nxNsgxwNK+dcyc8OBrPHB+Jv3bo1nLseDcBKg+OD6mzSrqm5XK5g2+Og3TOYHx8s4JwUeKWqzEHb5PDwcMH5gkWkg+ej7b7x6napzw7OG2866oRJJ52iVIC2ZRU+Pp94YWGhaFkytMa1116rV73qVTW95+qrr9a2bdsKjl1++eV65zvfqa6urrBa7r2vOHA/vrbAjh07NDU1VTAUqdwygsEKWUF1NqjiRpsG8vm8Nm7cqEcffVTDw8OSpNnZ2bBZYnFxUQsLC0W7e370ox/Vxz/+cUkqqjLv379fjz76qMbGxgrO573X/Py8Lly4oIMHD6qrq6tkdbtUdXxgYEAHDhwomtaJJkhK1Xo/1ksJdC1t1VHq0d3dXfMU0CuvvNJv27Yt8bl9+/b5/v7+sFqbVALNZrNhh0i8lB+UEqu5jnQ6nTjVMah6x3/PSv0eBv8f3VYkft07d+4s2aNe6nzx1yUp93x0gH/SBADYqZOq8N53ZhtoNfOqeRQ/ggDq7+/3+/btK3o+k8mE7XtJAZv0nUd7xYM/V5rJFv89i/48U6lUwfCj+Dz0+Pmvu+66gs9N6mVvxO91p/xd6TQdF6CdiE6k1T8a+Q9QrcN4aplOGX/s3Lkz8XWWoUSEYuuVCtC2nIkU10kzKZa/ayTNKEo6FmfdAqWahU/S6bS6u7t1+PDhqmbvTE5OhtdcaTplOp3W4uJiOMTpYx/7WOLrLCvOl5oiijaQlKr1fqymBNpJ7TrlSiTlHkG7Wq3va+dHtSXJepQ4g2Xc4r3Q8R7+Utsfx8WHNpUaVuT9K73rY2NjFVext5QiGQjfHtSpVfhOWg80+ItX6ypGV155pd+0aVPLQ6+eD8tKTpbH9ddfH1at422W8X/Mou2i5dbvjIZWKpUKd+qM/6yjHUHRIVn1DLp6TsWkKcCOAG2S6enpouXc1lvHUiqVMpWor7rqqoJB8dFHuV76pF7zbDZbVAJNGtFRaXB6uQHt0X8kgvnwjRgtUo/gY0786nRsgAaDpDthPdBAfLZMs0pjtT42bdrkr7nmmsRrTafTfmxsrGDgermB7vHHzp07iz57586dJWcISSpYAGNoaKhgbnnQA540UympNBnM7olv/FautFmuVBoVb6qJDoavR9A1opRIU8DqdGyAet95VY94CbRRj2p2tFzNZ4+OjhaNVxwbG/M33HBDxffHZwMFW2jES0LBjJ94D3e5ElOpKZNx1fzeWIYYxceHRnflXI1GlhIpga5ORwdop0naarae1figRBaUssq9tpZSY/R6o6sPxedsB21+1113XcVV5ZPaEKv9B3E1g8prEf+casKmEf+oN7qU2GkFkXZCgDZRfORA0FMbXZItaC/LZrPhthTRbSKS2gHj+5wH5xodHQ3/4mWz2aJ53KOjo1WXVHfu3Bm+J/6XOekveNL8/2p7u9tVq6q7lBLbFwHaZJVKNUlV16TpftXuB1VNlTNaCg4WzIguXBxUs5Out1TnStIeRZ00eyxJK4Osk7+3taxUgHbEQPpOFGz10N3drbvvvlvPPvusrr76al1xxRXasWOHfuVXfkVLS0t67LHH1Nvbq4GBAT300EM6ceKELl68qC1btuj555/XW97yFj3//PPas2ePJOnw4cO6ePGinnvuuYI9xqM7QQYTD6Kv27Nnjx555BH19fWFi2hI0saNG3XHHXcU7RI5MDCgI0eOhHuZB8eDbSS6u7s1NTWl7du3K5PJaHFxUel0Wrfcckvi9xD97KSJEbVMlii3x3o99l+vZruMWid3VPv6+I6elutHEyWlar0f660EWuuiItu2batqQYxgPcrosVKdL+Wq7GNjY1UP1SnViRPtRIleVyqVCttPkwaiW4YNlftuo/ffqP3XV/seOoc6n5q9nJ1zbr9z7rRz7vTc3FyjTtOW4vuAV/L888/rxIkTFV+3sLCw3O5S5lzBUoDx10WdOHGiaMnA+DKB5Z6PPxddaX5paSlcvT2+3NvU1FTi51a6lnL3G/1zuedKqeXc1vdYzlGtRn42KmtYgHrvJ7z3fd77vp6enkadpi3t3bu3ptf/+I//eFhFLyebzYbbSJQ6VzDvOv66qD179lTc6qHc8/HnoteVSqWUzWYLriHY8iK6/mbSmpzVbDsRv9/on8s9V4ply4ta39PIbTXYsqO1XLmSSr309fX5tbpPUCnRtrhjx47p2Wef1XXXXafXve512rt3r5544gk98sgjuu222/Sbv/mbkqR77rlHJ06c0J49e7RlyxZNTk6qp6dHc3Nz2rt3r3p7e4vaNpPa+ZLaQIN9yffs2aNf/uVfLnidpZ0v+pyksF00aEtNOtYpbaCNeE8j2ylpA20859wXvfd9RccJUAAor1SAtuWWHgDQCQhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQAHAiAAFACMCFACMCFAAMCJAAcCIAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADBy3vvGn8S5OUlfN7z1aknfrvPltAr30n7Wyn1I3EujvcZ73xM/2JQAtXLOnfbe97X6OuqBe2k/a+U+JO6lVajCA4ARAQoARu0eoBOtvoA64l7az1q5D4l7aYm2bgMFgHbW7iVQAGhbBCgAGLVlgDrn3uqc+4pz7qvOuY+2+npq4Zz7R865x51zX3bOfck598GV41c5577gnPvLlf9+X6uvtVrOubRzbtY59/DKnzvyXpxzG51zv+uc+z8rP5+BTrwX59y/Wfnd+jPn3G855y7rlPtwzj3onPsb59yfRY6VvHbn3IGVHPiKc253a666tLYLUOdcWtKvS7pN0s2SftI5d3Nrr6omi5L+rff+9ZJ+SNL7V67/o5JOee9fK+nUyp87xQclfTny5069l/8s6XPe+5sk/VMt31NH3Ytz7jpJH5DU571/g6S0pJ9Q59zHf5X01tixxGtf+XvzE5L+8cp7Pr6SD+3De99WD0kDkh6N/PmApAOtvq5V3M//kvSjkr4i6dUrx14t6SutvrYqr/96Lf9Sv0XSwyvHOu5eJF0p6Wta6TiNHO+oe5F0naRvSLpKUkbSw5KGOuk+JN0g6c8q/Qzif/clPSppoNXXH320XQlUr/yCBF5YOdZxnHM3SNou6WlJ3++9/6Ykrfz3mtZdWU2OSBqTtBQ51on3cqOkOUmfXGmO+IRz7nvUYffivf8rSb8i6Zykb0r6O+/959Vh9xFT6trbPgvaMUBdwrGOG2vlnLtC0qSku733L7b6eiycc/9S0t9477/Y6mupg4ykWyT9F+/9dknfUftWc0taaR98u6QfkHStpO9xzt3e2qtqmLbPgnYM0Bck/aPIn6+XdL5F12LinMtqOTw/7b0/sXL4r51zr155/tWS/qZV11eDN0l6m3Pu/0r675Le4pz7TXXmvbwg6QXv/dMrf/5dLQdqp93LrZK+5r2f894vSDoh6YfVefcRVera2z4L2jFA/0TSa51zP+Ccy2m5EfmzLb6mqjnnnKRjkr7svf+Pkac+K+mnVv7/p7TcNtrWvPcHvPfXe+9v0PLP4Q+897erM+/lW5K+4Zx73cqhXZL+XJ13L+ck/ZBz7vKV37VdWu4M67T7iCp17Z+V9BPOuS7n3A9Ieq2kZ1pwfaW1uhG2RCPzj0n6C0lnJf1sq6+nxmv/Z1quZvyppOdWHj8mqVvLnTF/ufLfq1p9rTXe16Be6UTqyHuRtE3S6ZWfzUOSvq8T70XSf5D0fyT9maT/JqmrU+5D0m9pue12QcslzDvKXbukn13Jga9Iuq3V1x9/MJUTAIzasQoPAB2BAAUAIwIUAIwIUAAwIkABwIgABQAjAhQAjAhQADAiQNGWVhbVftI597fOuf/nnHvUOff6yPM7nHPPOudeXlld6cecc945Nxh5zc3Oud9zzr20sojvbznnNrXkhrAmEaBoV9+j5aX0+rU8jfTvJJ10zuVWVrp6WMvTGd+o5eX27o++eWVRiie0PN2xX8uLcFwh6bPOOX7vURdM5URHWFm780VJ/1zLK5QflnSd9/67K8+/S9KnJb3Zez/lnPsFSW/y3u+KfMb3Sfp/knZ479trUQp0JP4lRltyzm1xzn3GOXfWOfeipL/W8u/rZkk3aXlF8+9G3vJ07CPeKGmnc+7vg4deWZx3S6OvH+tDptUXAJRwUtJfSXrfyn8Xtbz8XE7LC+1WqjqlJP2epA8nPPfX9btMrGcEKNqOc65b0uslvd97//jKsVv0yu/rlyWNOOc2REqh/bGPeVbSOyR93S8vPAzUHVV4tKO/lfRtSXc657Y65/65pN/QcilUWm7rzEs6utLTfqukf7fyXFAy/XVJ3yvpf6z02N/onLvVOTfhnHtV824FaxkBirbjvV+S9E5J/0TLvei/LuleSZdWnv97ST+u5c6kWS33wB9cefvLK685r+UtSZYkfU7Sl1Y+51LwOcBq0QuPNcE593ZJ/1PSNd77b7f6erA+0AaKjuSc+ylJz2u5Z/0NWh4zepLwRDMRoOhU36/lvYFeLelbWu5xv6elV4R1hyo8ABjRiQQARgQoABgRoABgRIACgBEBCgBG/x9IroUwqq3sAgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "dataFrame.info()\n",
    "\n",
    "dataFrameCopy = dataFrame.copy()\n",
    "dataFrameCopy[\"income_per_resident\"] = dataFrame[\"income\"] / dataFrame[\"residents\"]\n",
    "X = dataFrameCopy\n",
    "\n",
    "Y = days_labels\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.scatter(X[\"age\"],X[\"income_per_resident\"], c=\"k\", marker=\".\")\n",
    "plt.xlabel(\"age\", fontsize=14)\n",
    "plt.ylabel(\"income\", fontsize=14)\n",
    "plt.tick_params(labelleft=False)\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
